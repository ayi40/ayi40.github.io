<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AWS Service</title>
    <url>/2024/05/23/AWS/</url>
    <content><![CDATA[<p>Some simple knowledge of PyG</p>
<span id="more"></span>
<h1 id="iam--identity-and-access-management">IAM- Identity and Access
Management</h1>
<p>创建用户，分组以及分配权限</p>
<h2 id="iam-policies">IAM Policies</h2>
<h2 id="iam-mfa">IAM MFA</h2>
<h2 id="access-aws">Access AWS</h2>
<p>在AWS（Amazon Web Services）中，CLI、SDK和Management
Console是三种不同的方式来管理和与AWS服务进行交互。以下是它们的区别和用途：</p>
<ul>
<li><p>AWS CLI（Command Line
Interface）：一个统一的工具，允许用户通过命令行界面与AWS服务进行交互。<strong>CLI</strong>
更加适合脚本和自动化任务。Protected by access keys</p></li>
<li><p>AWS SDK（Software Development Kit）：
提供了多种编程语言的库和工具包，使开发人员可以在代码中直接与AWS服务进行交互。<strong>SDK</strong>
适合开发人员在应用程序中集成AWS服务。Protected by access keys</p></li>
<li><p>AWS Management Console：
AWS提供的基于Web的用户界面，用于管理AWS资源。<strong>Management
Console</strong>
适合管理和监控任务，提供可视化的管理界面，适合不熟悉代码的人操作。Protected
by password and + MFA, generate access keys.</p></li>
</ul>
<h2 id="iam-roles">IAM Roles</h2>
<p>与IAM user类似，但是不是给人用的，是给AWS Service用的</p>
<p>E.g. 现在有一个EC2
Instance启动需要用到某些AWS功能，我们需要给它分配IAM Roles管理其权限</p>
<h1 id="ec2">EC2</h1>
<ul>
<li>EC2 User Data (runs with the root user)
<ul>
<li>lt is possible to bootstrap our instances using an EC2 Wser data
script</li>
<li>bootstrapping means launching commands when a machine starts</li>
<li>That script is only run once at the instance first start</li>
<li>EC2 user data is used to automate boot tasks such as:
<ul>
<li>Installing updates</li>
<li>Installing software</li>
<li>Downloading common files from the internet</li>
<li>Anything you can think of</li>
</ul></li>
</ul></li>
</ul>
<h2 id="ec2-1">EC2</h2>
<h2 id="ebs">EBS</h2>
<h2 id="elb">ELB</h2>
<h2 id="asg">ASG</h2>
]]></content>
      <categories>
        <category>AWS</category>
      </categories>
  </entry>
  <entry>
    <title>算法</title>
    <url>/2023/02/14/Algorithm_example/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="动态规划">动态规划</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">有一排深渊法师，他们的护盾值用数组 a 表示；</span><br><span class="line">你可以对深渊法师这样破盾：</span><br><span class="line">1) 用重击破盾，每消耗1MP破1点护盾</span><br><span class="line">2) 如果有两个相邻的深渊法师他们的元素不同，且护盾都不为0，你可以对他们俩使用高天之歌，消耗xMP破所有护盾</span><br><span class="line">问最少消耗的MP？</span><br><span class="line">下面输入的 els 表示深渊法师的元素，I 表示冰，W 表示水，F 表示火</span><br><span class="line"></span><br><span class="line">输入：</span><br><span class="line">a = [4, 8, 10, 2, 15, 2]</span><br><span class="line">x = 9</span><br><span class="line">els = WIFFII</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i]=min(dp[i-1]+a[i],dp[i-2]+x) if 能使用高天之歌 else dp[i-1]+a[i]</span><br></pre></td></tr></table></figure>
<h1 id="找规律题目">找规律题目</h1>
<h2 id="找规律后拼接">找规律后拼接</h2>
<h3 id="构建长度为n的字符串">构建长度为n的字符串</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A希望你构造一个长度为n的数组，满足以下条件：</span><br><span class="line">1. 所有元素绝对值不大于3</span><br><span class="line">2. 相邻两个元素乘积小于0，且和不为0</span><br><span class="line">3. 所有元素之和=0</span><br><span class="line">input: 2 output:no answer</span><br><span class="line">input: 3 output: -1 2 -1</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">根据题目信息：</span><br><span class="line">1. 数组的元素在&#123;1,2,3&#125;里挑选</span><br><span class="line">2. 数组相邻元素一个为正一个为负，且互不相等，正号组和负号组可以互换。</span><br><span class="line">3. 正负号数值和相同，且可拼接！！！因为0+0=0</span><br><span class="line"></span><br><span class="line">考虑拼接条件：只要首尾元素不相同就可以拼接！！</span><br><span class="line"></span><br><span class="line">开始找规律以及能用于拼接的元素：</span><br><span class="line">input: 2 output:no answer</span><br><span class="line">input: 3 output: -1 3 -2（这个可以用于拼接，首位元素不同） -1 2 -1（这个不可以）</span><br><span class="line">input: 4 output: -1 2 -3 2（这个可以用于拼接，首位元素不同）</span><br><span class="line">input: 5 output: no answer</span><br><span class="line">我们发现所以大于5的数都可以由若干个3和若干个4相加得到，且3、4中有答案可以随意拼接，所以我们能利用3、4的答案拼接出n&gt;5的满足条件的数组</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="拼接mhy字符串">拼接mhy字符串</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">如果不能定义：字符串的“权重”是字符串中出现的字符种类数量，比如 mmm 权重为1，mmh 为 2，mhy 为 3</span><br><span class="line">输入：x, y, z 三个变量</span><br><span class="line">输出：一个长度为 x + y + z + 2 的字符串，这个字符串只能由 m h y 三种字符组成，这个字符串一共有 x + y + z 个长度为 3 的子串，其中有 x 个权重为 1 的子串，y 个权重为 2 的子串，z 个权重为 3 的子串。</span><br><span class="line">只用输出一种情况，若无法组成，输出-1</span><br><span class="line"></span><br><span class="line">范例输入：x = 2, y = 1, z = 1</span><br><span class="line">范例输出：mmmmhy</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 找规律，发现权重3字符串后只能接权重2或权重3的字符串，不能跟权重1；所以如果x,z&gt;0,y=0这种情况无解</span><br><span class="line">2. 我们可以先拼接权重3字符串（若有）mhymhy...</span><br><span class="line">3. 然后拼接权重2，mhymhyhyhy...；如果无权重三直接拼接权重2,hyhyh....</span><br><span class="line">4. 只剩下一个权重2没拼时，拼一个可以接权重1的权重2，mhymhyhyhyy</span><br><span class="line">5. 拼接权重1：mhymhyhyhyyyyyyy</span><br></pre></td></tr></table></figure>
<h2 id="找规律后计算">找规律后计算</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A拿到了3元无限长字符串&#123;1,2,3；4,5,6；7,8,9；....&#125;</span><br><span class="line">其中3的倍数后用；分割，其他用逗号</span><br><span class="line">求l个字符到r个字符之间有几个逗号和分号。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 求l到r字符之间有几个逗号分号——》r前逗号分号-l前逗号分号</span><br><span class="line">2. 难点：数字为1-9时，每个数字只占1个字符，为10-99，每个数字就占两个字符了。</span><br><span class="line">	开始找规律！</span><br><span class="line">	1-9			每6个字符为一组&#123;1,2,3;&#125;			这样的组有3个</span><br><span class="line">	10-99		每9个字符为一组&#123;10,11,12;&#125;			这样的组有30个</span><br><span class="line">	100-999		每12个字符为一组&#123;100,111,112;&#125;		这样的组有300个</span><br><span class="line">	以此类推</span><br><span class="line">	</span><br></pre></td></tr></table></figure>
<h1 id="审题题">审题题</h1>
<h2 id="交换字母使字典序尽可能大">交换字母使字典序尽可能大</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A拿到一个仅有小写字母组成的字符串，她准备进行恰好一次操作：交换连个相邻字母，在操作结束后使字符串的字典序尽可能大。</span><br><span class="line"></span><br><span class="line">input: ba</span><br><span class="line">output: ab</span><br><span class="line">2&lt;=len(input)&lt;=200000</span><br></pre></td></tr></table></figure>
<p>知识点：</p>
<ol type="1">
<li><p>字典序，就是按照字典排列顺序，英文字母按下面方式排列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ABCDEFG HIJKLMN OPQRST UVWXYZ</span><br><span class="line">abcdefg hijklmn opqrst uvwxyz</span><br></pre></td></tr></table></figure></li>
<li><p>题目说的是<strong>恰好一次</strong>操作！！！！就算交换之后会让原来字符串字典序减小也需要进行操作！</p></li>
</ol>
<h1 id="寻找用例">寻找用例</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。</span><br><span class="line"></span><br><span class="line">计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。</span><br><span class="line"></span><br><span class="line">你可以认为每种硬币的数量是无限的。</span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>找正例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：coins = [1, 2, 5], amount = 11</span><br><span class="line">输出：3 </span><br></pre></td></tr></table></figure></li>
<li><p>找负例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：coins = [2], amount = 3</span><br><span class="line">输出：-1</span><br></pre></td></tr></table></figure></li>
<li><p>找边界条件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：coins = [1], amount = 0</span><br><span class="line">输出：0</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>Hadoop</title>
    <url>/2024/04/15/BDC-Hadoop/</url>
    <content><![CDATA[<p>Hadoop</p>
<span id="more"></span>
<p>Hadoop = HDFS + MapReduce</p>
<p>HDFS为海量数据提供了<strong>存储</strong>，而MapReduce为海量数据提供了<strong>计算框架</strong>。</p>
<h1 id="基本概念">基本概念</h1>
<h2 id="hdfs">HDFS</h2>
<ul>
<li>NameNode
:是Master节点（主节点），可以看作是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的Meta-data存储在内存中，这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。</li>
<li>DataNode :
是Slave节点（从节点），是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。</li>
<li>Client :
切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。 </li>
</ul>
<p><strong>Block</strong>:Block是HDFS中的基本读写单元；HDFS中的文件都是被切割为block（块）进行存储的；这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。</p>
<h3 id="写入流程">写入流程</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240415144017291.png"
alt="image-20240415144017291" />
<figcaption aria-hidden="true">image-20240415144017291</figcaption>
</figure>
<p>1 用户向Client（客户机）提出请求。例如，需要写入200MB的数据。</p>
<p>2
Client制定计划：将数据按照64MB为块，进行切割；所有的块都保存三份。</p>
<p>3 Client将大文件切分成块（block）。</p>
<p>4
针对第一个块，Client告诉NameNode（主控节点），请帮助我，将64MB的块复制三份。</p>
<p>5
NameNode告诉Client三个DataNode（数据节点）的地址，并且将它们根据到Client的距离，进行了排序。</p>
<p>6 Client把数据和清单发给第一个DataNode。</p>
<p>7 第一个DataNode将数据复制给第二个DataNode。</p>
<p>8 第二个DataNode将数据复制给第三个DataNode。</p>
<p>9 如果某一个块的所有数据都已写入，就会向NameNode反馈已完成。</p>
<p>10 对第二个Block，也进行相同的操作。</p>
<p>11 所有Block都完成后，关闭文件。NameNode会将数据持久化到磁盘上。</p>
<h3 id="读出流程">读出流程</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240415144359467.png"
alt="image-20240415144359467" />
<figcaption aria-hidden="true">image-20240415144359467</figcaption>
</figure>
<p>1 用户向Client提出读取请求。</p>
<p>2 Client向NameNode请求这个文件的所有信息。</p>
<p>3
NameNode将给Client这个文件的块列表，以及存储各个块的数据节点清单（按照和客户端的距离排序）。</p>
<p>4 Client从距离最近的数据节点下载所需的块。</p>
<h2 id="mapreduce">MapReduce</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240416113031092.png"
alt="image-20240416113031092" />
<figcaption aria-hidden="true">image-20240416113031092</figcaption>
</figure>
<ul>
<li>Map映射：
把计算作业拆分成若干个<strong>Map任务</strong>，然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分</li>
<li>Reduce归约 ： 把前面若干a 个Map的输出汇总到一起并输出。</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240415144901036.png"
alt="image-20240415144901036" />
<figcaption aria-hidden="true">image-20240415144901036</figcaption>
</figure>
<ul>
<li>JobTRacker: 用于调度和管理其它的TaskTracker,
可以运行于集群中任一台计算机上。</li>
<li>TaskTracker: 负责执行任务，必须运行于 DataNode 上。</li>
</ul>
<h2 id="yarn">YARN</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240506120131953.png"
alt="image-20240506120131953" />
<figcaption aria-hidden="true">image-20240506120131953</figcaption>
</figure>
<ul>
<li><p><strong>ResourceManager</strong>（RM）：整个集群资源（内存、CPU等）的管理者</p></li>
<li><p><strong>NodeManager</strong>（NM）：单个节点服务器的管理者</p></li>
<li><p><strong>ApplicationMaster</strong>（AM）：单个任务运行的负责人</p></li>
<li><p><strong>Container</strong>：容器，相当于一台独立的服务器，里面封装了任务运行所需要的资源（内存、CPU、磁盘、网络）</p></li>
<li><p>注意</p></li>
<li><ul>
<li>客户端可以有多个</li>
<li>集群上可以运行多个 ApplicationMaster</li>
<li>每个 NodeManager 上可以有多个 Container</li>
</ul></li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240506120252480.png"
alt="image-20240506120252480" />
<figcaption aria-hidden="true">image-20240506120252480</figcaption>
</figure>
<h2 id="三者关系">三者关系</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240506144828981.png"
alt="image-20240506144828981" />
<figcaption aria-hidden="true">image-20240506144828981</figcaption>
</figure>
<h1 id="实战">实战</h1>
<p><a
href="https://blog.csdn.net/weixin_42837961/article/details/105493561">Hadoop
入门教程（超详细）_hadoop教程-CSDN博客</a></p>
]]></content>
      <categories>
        <category>ML</category>
        <category>BDC</category>
      </categories>
  </entry>
  <entry>
    <title>Spark</title>
    <url>/2024/05/13/BDC-Spark/</url>
    <content><![CDATA[<p>Spark</p>
<span id="more"></span>
<h1 id="搭建环境">搭建环境</h1>
<p><a href="https://www.sundog-education.com/spark-python/">Taming Big
Data with Apache Spark and Python - Getting Started - Sundog Education
with Frank Kane (sundog-education.com)</a></p>
<p><strong>Note</strong>：Step12使用<code>pyspark</code>指令前记得先进入anaconda中的环境。</p>
<h1 id="introduction">Introduction</h1>
<h2 id="overview">Overview</h2>
<p>TBC</p>
<h1 id="resilient-distributed-data-setrdd弹性分布式数据集">Resilient
Distributed Data Set（RDD）弹性分布式数据集</h1>
<p>RDD是数据集，我们通常对一个RDD做一些操作去获得另外一个RDD。我们需要实例化一个对象<code>SparkContext</code>来执行这些操作。</p>
<h2 id="basic-operation">Basic Operation</h2>
<h3 id="transforming-rdd">Transforming RDD</h3>
<ul>
<li>map</li>
<li>flatmap</li>
<li>filter: removing information potentially that you don't care
about</li>
<li>distinct</li>
<li>sample</li>
<li>union, intersection, subtract, cartesian</li>
</ul>
<h3 id="rdd-action">RDD Action</h3>
<ul>
<li>collect</li>
<li>count： 统计RDD中value出现的次数</li>
<li>countByValue</li>
<li>take</li>
<li>top</li>
<li>reduce</li>
<li>... and more ...</li>
</ul>
<h3
id="example统计user对movie的评分">Example：统计user对movie的评分</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="comment"># setMaster指定在单个主机(local)还是在集群(cluster)中运行，这里我们暂时使用单线程</span></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;RatingsHistogram&quot;</span>)</span><br><span class="line"><span class="comment"># 创建SparkContext</span></span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用sc.textFile创建RDD，text中每一行（整行文本）对应RDD中一个值</span></span><br><span class="line"><span class="comment"># exp：</span></span><br><span class="line"><span class="comment">#user_id movie_id rating timestep</span></span><br><span class="line"><span class="comment">#196 242 4 991232423</span></span><br><span class="line"><span class="comment">#186 302 3 984927391</span></span><br><span class="line"><span class="comment">#......</span></span><br><span class="line">lines = sc.textFile(<span class="string">&quot;file:///SparkCourse/ml-100k/u.data&quot;</span>)</span><br><span class="line"><span class="comment"># 使用map与lambda对RDD进行transform</span></span><br><span class="line">ratings = lines.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split()[<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 对新的RDD进行action</span></span><br><span class="line">result = ratings.countByValue()</span><br><span class="line"></span><br><span class="line">sortedResults = collections.OrderedDict(<span class="built_in">sorted</span>(result.items()))</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> sortedResults.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s %i&quot;</span> % (key, value))</span><br></pre></td></tr></table></figure>
<h2 id="key-value-rdd">Key-Value RDD</h2>
<h3 id="create-key-value-rdd">Create Key-Value RDD</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">totalsByAge = rdd.map(lambda x:(x,1))</span><br></pre></td></tr></table></figure>
<p>键值对的value不一定非得是一个值，也可以是列表</p>
<h3 id="special-action">Special Action</h3>
<ul>
<li><p>reduceByKey(): combine values with the same key using some
function.</p>
<p>exp: use <code>rdd.reduceByKey(lambda x,y:x+y)</code> to adds values
up</p></li>
<li><p>groupByKey(): Group values with the same key</p></li>
<li><p>sortByKey(): Sort RDD by key values</p></li>
<li><p>keys(), values(): create an RDD of just the keys, or just the
values</p></li>
</ul>
<h3 id="example-统计一定年龄段的朋友有多少">Example:
统计一定年龄段的朋友有多少</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># datasets</span></span><br><span class="line"><span class="comment"># indexd name age friends_num</span></span><br><span class="line"><span class="comment"># 0 Will 33 385</span></span><br><span class="line"><span class="comment"># 1 Jean 33 2</span></span><br><span class="line"><span class="comment"># 2 Huge 55 221</span></span><br><span class="line"><span class="comment"># 3 Luke 40 465</span></span><br><span class="line"><span class="comment">#...</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;FriendsByAge&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform to key-value RDD</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parseLine</span>(<span class="params">line</span>):</span><br><span class="line">    fields = line.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    age = <span class="built_in">int</span>(fields[<span class="number">2</span>])</span><br><span class="line">    numFriends = <span class="built_in">int</span>(fields[<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> (age, numFriends)</span><br><span class="line"></span><br><span class="line">lines = sc.textFile(<span class="string">&quot;file:///SparkCourse/fakefriends.csv&quot;</span>)</span><br><span class="line">rdd = lines.<span class="built_in">map</span>(parseLine)</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform (33,385) to (33, (385, 1)),and them sum up respectively, 385用来计算总朋友数，1用来计算人头数用于求平均</span></span><br><span class="line">totalsByAge = rdd.mapValues(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> x, y: (x[<span class="number">0</span>] + y[<span class="number">0</span>], x[<span class="number">1</span>] + y[<span class="number">1</span>]))</span><br><span class="line">averagesByAge = totalsByAge.mapValues(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] / x[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">results = averagesByAge.collect()</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="filtering-rdd">Filtering RDD</h2>
<p>map：对RDD处理，input和output始终是一对一关系</p>
<p>flatmap： 可以从一个value生成多个values</p>
<p>e.g. (The quick red fox ...) ——》 lines.flatmap(lambda x:x.split())
——》 (The) (quick) (red) (fox)...</p>
<h3 id="example-找出气候站一年的最低温低">Example:
找出气候站一年的最低温低</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dataset</span></span><br><span class="line"><span class="comment"># wether sation code, date, type, temp, other</span></span><br><span class="line"><span class="comment"># ITE00100554, 18000101, TMAX, -75,,,E </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;MinTemperatures&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parseLine</span>(<span class="params">line</span>):</span><br><span class="line">    fields = line.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    stationID = fields[<span class="number">0</span>]</span><br><span class="line">    entryType = fields[<span class="number">2</span>]</span><br><span class="line">    temperature = <span class="built_in">float</span>(fields[<span class="number">3</span>]) * <span class="number">0.1</span> * (<span class="number">9.0</span> / <span class="number">5.0</span>) + <span class="number">32.0</span></span><br><span class="line">    <span class="keyword">return</span> (stationID, entryType, temperature)</span><br><span class="line"></span><br><span class="line">lines = sc.textFile(<span class="string">&quot;file:///SparkCourse/1800.csv&quot;</span>)</span><br><span class="line">parsedLines = lines.<span class="built_in">map</span>(parseLine)</span><br><span class="line">minTemps = parsedLines.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: <span class="string">&quot;TMIN&quot;</span> <span class="keyword">in</span> x[<span class="number">1</span>])</span><br><span class="line">stationTemps = minTemps.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">2</span>]))</span><br><span class="line">minTemps = stationTemps.reduceByKey(<span class="keyword">lambda</span> x, y: <span class="built_in">min</span>(x,y))</span><br><span class="line">results = minTemps.collect();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(result[<span class="number">0</span>] + <span class="string">&quot;\t&#123;:.2f&#125;F&quot;</span>.<span class="built_in">format</span>(result[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<h2 id="flatmap">Flatmap</h2>
<h3 id="example-统计文本中词汇出现次数">Example：
统计文本中词汇出现次数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = sc.textFile(<span class="string">&quot;file:///sparkcourse/book.txt&quot;</span>)</span><br><span class="line">words = <span class="built_in">input</span>.flatMap(<span class="keyword">lambda</span> x: x.split())</span><br><span class="line">wordCounts = words.countByValue()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word, count <span class="keyword">in</span> wordCounts.items():</span><br><span class="line">    cleanWord = word.encode(<span class="string">&#x27;ascii&#x27;</span>, <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> (cleanWord):</span><br><span class="line">        <span class="built_in">print</span>(cleanWord.decode() + <span class="string">&quot; &quot;</span> + <span class="built_in">str</span>(count))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面代码只通过空格分解，会出现<code>spark,</code>这种情况，我们下面用正则表达式改进一下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalizeWords</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> re.<span class="built_in">compile</span>(<span class="string">r&#x27;\W+&#x27;</span>, re.UNICODE).split(text.lower())</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = sc.textFile(<span class="string">&quot;file:///sparkcourse/book.txt&quot;</span>)</span><br><span class="line">words = <span class="built_in">input</span>.flatMap(normalizeWords)</span><br><span class="line">wordCounts = words.countByValue()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word, count <span class="keyword">in</span> wordCounts.items():</span><br><span class="line">    cleanWord = word.encode(<span class="string">&#x27;ascii&#x27;</span>, <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> (cleanWord):</span><br><span class="line">        <span class="built_in">print</span>(cleanWord.decode() + <span class="string">&quot; &quot;</span> + <span class="built_in">str</span>(count))</span><br></pre></td></tr></table></figure>
<p>加上排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalizeWords</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> re.<span class="built_in">compile</span>(<span class="string">r&#x27;\W+&#x27;</span>, re.UNICODE).split(text.lower())</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = sc.textFile(<span class="string">&quot;file:///sparkcourse/book.txt&quot;</span>)</span><br><span class="line">words = <span class="built_in">input</span>.flatMap(normalizeWords)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用另外一种方法实现词频统计</span></span><br><span class="line">wordCounts = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> x, y: x + y)</span><br><span class="line"><span class="comment"># key，value转换，然后用sordbykey方法</span></span><br><span class="line">wordCountsSorted = wordCounts.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">1</span>], x[<span class="number">0</span>])).sortByKey()</span><br><span class="line">results = wordCountsSorted.collect()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    count = <span class="built_in">str</span>(result[<span class="number">0</span>])</span><br><span class="line">    word = result[<span class="number">1</span>].encode(<span class="string">&#x27;ascii&#x27;</span>, <span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> (word):</span><br><span class="line">        <span class="built_in">print</span>(word.decode() + <span class="string">&quot;:\t\t&quot;</span> + count)</span><br></pre></td></tr></table></figure>
<h1 id="spark-sql">Spark SQL</h1>
<p>一种dataframe，可以用sql语句查询，可以与rdd互相转换</p>
<h2 id="example将rdd转为sparksql">Example：将RDD转为SparkSQL</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a SparkSessiony用于操作SparkSQL</span></span><br><span class="line"><span class="comment"># spark.getOrCreate()与spark.close()相对应</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;SparkSQL&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mapper</span>(<span class="params">line</span>):</span><br><span class="line">    fields = line.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> Row(ID=<span class="built_in">int</span>(fields[<span class="number">0</span>]), name=<span class="built_in">str</span>(fields[<span class="number">1</span>].encode(<span class="string">&quot;utf-8&quot;</span>)), \</span><br><span class="line">               age=<span class="built_in">int</span>(fields[<span class="number">2</span>]), numFriends=<span class="built_in">int</span>(fields[<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个value是Row的RDD</span></span><br><span class="line">lines = spark.sparkContext.textFile(<span class="string">&quot;fakefriends.csv&quot;</span>)</span><br><span class="line">people = lines.<span class="built_in">map</span>(mapper)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用RDD创建DataFrame</span></span><br><span class="line"><span class="comment"># Infer the schema, and register the DataFrame as a table.</span></span><br><span class="line"><span class="comment"># cache是将这个表存入内存里</span></span><br><span class="line">schemaPeople = spark.createDataFrame(people).cache()</span><br><span class="line"><span class="comment"># 要对DataFrame进行操作，需要创建一个临时View（如果View已经存在则替换）</span></span><br><span class="line">schemaPeople.createOrReplaceTempView(<span class="string">&quot;people&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL can be run over DataFrames that have been registered as a table.</span></span><br><span class="line"><span class="comment"># return a dataframe</span></span><br><span class="line"><span class="comment"># 这里people对应View的名字，age对于创建Row是给的名字</span></span><br><span class="line">teenagers = spark.sql(<span class="string">&quot;SELECT * FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The results of SQL queries are RDDs and support all the normal RDD operations.</span></span><br><span class="line"><span class="keyword">for</span> teen <span class="keyword">in</span> teenagers.collect():</span><br><span class="line">  <span class="built_in">print</span>(teen)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can also use functions instead of SQL queries:</span></span><br><span class="line">schemaPeople.groupBy(<span class="string">&quot;age&quot;</span>).count().orderBy(<span class="string">&quot;age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2
id="example直接打开dataframe用执行代码处理数据">Example：直接打开DataFrame+用执行代码处理数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;SparkSQL&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取csv文件</span></span><br><span class="line"><span class="comment"># option(&quot;header&quot;, &quot;true&quot;)表明这个csv文件有header</span></span><br><span class="line"><span class="comment"># option(&quot;inferSchema&quot;, &quot;true&quot;)要求推理检测模式</span></span><br><span class="line">people = spark.read.option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>).option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)\</span><br><span class="line">    .csv(<span class="string">&quot;file:///SparkCourse/fakefriends-header.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print属性名与属性类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Here is our inferred schema:&quot;</span>)</span><br><span class="line">people.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s display the name column:&quot;</span>)</span><br><span class="line">people.select(<span class="string">&quot;name&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Filter out anyone over 21:&quot;</span>)</span><br><span class="line">people.<span class="built_in">filter</span>(people.age &lt; <span class="number">21</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Group by age&quot;</span>)</span><br><span class="line">people.groupBy(<span class="string">&quot;age&quot;</span>).count().show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Make everyone 10 years older:&quot;</span>)</span><br><span class="line">people.select(people.name, people.age + <span class="number">10</span>).show()</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2
id="example计算某个年龄平均有几个朋友">Example：计算某个年龄平均有几个朋友</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;FriendsByAge&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">lines = spark.read.option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>).option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>).csv(<span class="string">&quot;file:///SparkCourse/fakefriends-header.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select only age and numFriends columns</span></span><br><span class="line">friendsByAge = lines.select(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;friends&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># From friendsByAge we group by &quot;age&quot; and then compute average</span></span><br><span class="line">friendsByAge.groupBy(<span class="string">&quot;age&quot;</span>).avg(<span class="string">&quot;friends&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sorted</span></span><br><span class="line">friendsByAge.groupBy(<span class="string">&quot;age&quot;</span>).avg(<span class="string">&quot;friends&quot;</span>).sort(<span class="string">&quot;age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Formatted more nicely</span></span><br><span class="line"><span class="comment"># agg()聚合多个命令，func.round()取小数点后几位</span></span><br><span class="line">friendsByAge.groupBy(<span class="string">&quot;age&quot;</span>).agg(func.<span class="built_in">round</span>(func.avg(<span class="string">&quot;friends&quot;</span>), <span class="number">2</span>)).sort(<span class="string">&quot;age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># With a custom column name</span></span><br><span class="line"><span class="comment"># alias()可以自定义列的名字</span></span><br><span class="line">friendsByAge.groupBy(<span class="string">&quot;age&quot;</span>).agg(func.<span class="built_in">round</span>(func.avg(<span class="string">&quot;friends&quot;</span>), <span class="number">2</span>)</span><br><span class="line">  .alias(<span class="string">&quot;friends_avg&quot;</span>)).sort(<span class="string">&quot;age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="func">func</h2>
<p>Passing columns as parameters</p>
<ul>
<li>func.explode(): similar to flatmap</li>
<li>func.split()</li>
<li>func.lower()</li>
</ul>
<h3 id="example-wordcounting处理非结构数据">Example:
WordCounting处理非结构数据</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;WordCount&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read each line of my book into a dataframe</span></span><br><span class="line">inputDF = spark.read.text(<span class="string">&quot;file:///SparkCourse/book.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split using a regular expression that extracts words</span></span><br><span class="line">words = inputDF.select(func.explode(func.split(inputDF.value, <span class="string">&quot;\\W+&quot;</span>)).alias(<span class="string">&quot;word&quot;</span>))</span><br><span class="line">wordsWithoutEmptyString = words.<span class="built_in">filter</span>(words.word != <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize everything to lowercase</span></span><br><span class="line">lowercaseWords = wordsWithoutEmptyString.select(func.lower(wordsWithoutEmptyString.word).alias(<span class="string">&quot;word&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Count up the occurrences of each word</span></span><br><span class="line">wordCounts = lowercaseWords.groupBy(<span class="string">&quot;word&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sort by counts</span></span><br><span class="line">wordCountsSorted = wordCounts.sort(<span class="string">&quot;count&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the results.</span></span><br><span class="line">wordCountsSorted.show(wordCountsSorted.count())</span><br></pre></td></tr></table></figure>
<h3 id="example-找最大最小温度">Example: 找最大最小温度</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;MinTemperatures&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the schema</span></span><br><span class="line"><span class="comment"># 根据列顺序分配</span></span><br><span class="line">schema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;stationID&quot;</span>, StringType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;date&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;measure_type&quot;</span>, StringType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;temperature&quot;</span>, FloatType(), <span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># // Read the file as dataframe</span></span><br><span class="line">df = spark.read.schema(schema).csv(<span class="string">&quot;file:///SparkCourse/1800.csv&quot;</span>)</span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter out all but TMIN entries</span></span><br><span class="line">minTemps = df.<span class="built_in">filter</span>(df.measure_type == <span class="string">&quot;TMIN&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select only stationID and temperature</span></span><br><span class="line">stationTemps = minTemps.select(<span class="string">&quot;stationID&quot;</span>, <span class="string">&quot;temperature&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Aggregate to find minimum temperature for every station</span></span><br><span class="line">minTempsByStation = stationTemps.groupBy(<span class="string">&quot;stationID&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;temperature&quot;</span>)</span><br><span class="line"><span class="comment"># 当有show()等action才会开始真正执行上面的代码</span></span><br><span class="line">minTempsByStation.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert temperature to fahrenheit and sort the dataset</span></span><br><span class="line"><span class="comment"># withColumn()新建一列名为“temperature&quot;,value是第二个参数</span></span><br><span class="line"><span class="comment"># 创建好新列后再进行select</span></span><br><span class="line">minTempsByStationF = minTempsByStation.withColumn(<span class="string">&quot;temperature&quot;</span>,</span><br><span class="line">                                                  func.<span class="built_in">round</span>(func.col(<span class="string">&quot;min(temperature)&quot;</span>) * <span class="number">0.1</span> * (<span class="number">9.0</span> / <span class="number">5.0</span>) + <span class="number">32.0</span>, <span class="number">2</span>))\</span><br><span class="line">                                                  .select(<span class="string">&quot;stationID&quot;</span>, <span class="string">&quot;temperature&quot;</span>).sort(<span class="string">&quot;temperature&quot;</span>)</span><br><span class="line">                                                  </span><br><span class="line"><span class="comment"># Collect, format, and print the results</span></span><br><span class="line">results = minTempsByStationF.collect()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(result[<span class="number">0</span>] + <span class="string">&quot;\t&#123;:.2f&#125;F&quot;</span>.<span class="built_in">format</span>(result[<span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>
<h3 id="exercisecustomer_order">Exercise：customer_order</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;TotalSpentByCustomer&quot;</span>).master(<span class="string">&quot;local[*]&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create schema when reading customer-orders</span></span><br><span class="line">customerOrderSchema = StructType([ \</span><br><span class="line">                                  StructField(<span class="string">&quot;cust_id&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">                                  StructField(<span class="string">&quot;item_id&quot;</span>, IntegerType(), <span class="literal">True</span>),</span><br><span class="line">                                  StructField(<span class="string">&quot;amount_spent&quot;</span>, FloatType(), <span class="literal">True</span>)</span><br><span class="line">                                  ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load up the data into spark dataset</span></span><br><span class="line">customersDF = spark.read.schema(customerOrderSchema).csv(<span class="string">&quot;file:///SparkCourse/customer-orders.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">totalByCustomer = customersDF.groupBy(<span class="string">&quot;cust_id&quot;</span>).agg(func.<span class="built_in">round</span>(func.<span class="built_in">sum</span>(<span class="string">&quot;amount_spent&quot;</span>), <span class="number">2</span>) \</span><br><span class="line">                                      .alias(<span class="string">&quot;total_spent&quot;</span>))</span><br><span class="line"></span><br><span class="line">totalByCustomerSorted = totalByCustomer.sort(<span class="string">&quot;total_spent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># totalByCustomerSorted.count()算出整个table一共多少行，这是为了输出整个表</span></span><br><span class="line">totalByCustomerSorted.show(totalByCustomerSorted.count())</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>
<h2 id="advanced-example">Advanced Example</h2>
<h3
id="找出最受欢迎的电影-最多评分数的电影">找出最受欢迎的电影-最多评分数的电影</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create schema when reading u.data</span></span><br><span class="line">schema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load up movie data as dataframe</span></span><br><span class="line"><span class="comment"># option(&quot;sep&quot;, &quot;\t&quot;)说明以&quot;\t&quot;为分割符</span></span><br><span class="line">moviesDF = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;file:///SparkCourse/ml-100k/u.data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Some SQL-style magic to sort all movies by popularity in one line!</span></span><br><span class="line">topMovieIDs = moviesDF.groupBy(<span class="string">&quot;movieID&quot;</span>).count().orderBy(func.desc(<span class="string">&quot;count&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Grab the top 10</span></span><br><span class="line">topMovieIDs.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stop the session</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure>
<h3 id="broadcast">Broadcast</h3>
<p>将一个变量分发到cluster上每个点</p>
<p>example：给电影ID找对于的电影名字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, LongType</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadMovieNames</span>():</span><br><span class="line">    movieNames = &#123;&#125;</span><br><span class="line">    <span class="comment"># CHANGE THIS TO THE PATH TO YOUR u.ITEM FILE:</span></span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(<span class="string">&quot;E:/SparkCourse/ml-100k/u.ITEM&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;ISO-8859-1&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            fields = line.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">            movieNames[<span class="built_in">int</span>(fields[<span class="number">0</span>])] = fields[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> movieNames</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;PopularMovies&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将loadMovieNames方法return的字典分发到cluster上所有节点</span></span><br><span class="line">nameDict = spark.sparkContext.broadcast(loadMovieNames())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create schema when reading u.data</span></span><br><span class="line">schema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load up movie data as dataframe</span></span><br><span class="line">moviesDF = spark.read.option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>).schema(schema).csv(<span class="string">&quot;file:///SparkCourse/ml-100k/u.data&quot;</span>)</span><br><span class="line"></span><br><span class="line">movieCounts = moviesDF.groupBy(<span class="string">&quot;movieID&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a user-defined function to look up movie names from our broadcasted dictionary</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lookupName</span>(<span class="params">movieID</span>):</span><br><span class="line">    <span class="keyword">return</span> nameDict.value[movieID]</span><br><span class="line">lookupNameUDF = func.udf(lookupName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a movieTitle column using our new udf</span></span><br><span class="line">moviesWithNames = movieCounts.withColumn(<span class="string">&quot;movieTitle&quot;</span>, lookupNameUDF(func.col(<span class="string">&quot;movieID&quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sort the results</span></span><br><span class="line"><span class="comment"># 新的一种排序方法</span></span><br><span class="line">sortedMoviesWithNames = moviesWithNames.orderBy(func.desc(<span class="string">&quot;count&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Grab the top 10</span></span><br><span class="line">sortedMoviesWithNames.show(<span class="number">10</span>, <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stop the session</span></span><br><span class="line">spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="example-find-the-most-popular-superhero">Example: find the most
popular superhero</h2>
<p>数据集：</p>
<ul>
<li><p>Marvel-graph.txt</p>
<p>4395 7483 9475 7483</p>
<p>4802 3939 ...</p>
<p>每行第一个ID是superhero
ID，后面跟着的是在漫画中和这个superhero同时出现过的superhero ID</p>
<p>一个超级英雄可能多次在每一行的第一个出现</p></li>
<li><p>Marvel-names.txt</p>
<p>superhero ID与名字的映射</p></li>
</ul>
<h3
id="mission1找出最受欢迎的superhero">Mission1：找出最受欢迎的superhero</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, StringType</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;MostPopularSuperhero&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">schema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;id&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;name&quot;</span>, StringType(), <span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line">names = spark.read.schema(schema).option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot; &quot;</span>).csv(<span class="string">&quot;file:///SparkCourse/Marvel-names.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂时不在意这个datafram的schema</span></span><br><span class="line">lines = spark.read.text(<span class="string">&quot;file:///SparkCourse/Marvel-graph.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Small tweak vs. what&#x27;s shown in the video: we trim each line of whitespace as that could</span></span><br><span class="line"><span class="comment"># throw off the counts.</span></span><br><span class="line">connections = lines.withColumn(<span class="string">&quot;id&quot;</span>, func.split(func.trim(func.col(<span class="string">&quot;value&quot;</span>)), <span class="string">&quot; &quot;</span>)[<span class="number">0</span>]) \</span><br><span class="line">    .withColumn(<span class="string">&quot;connections&quot;</span>, func.size(func.split(func.trim(func.col(<span class="string">&quot;value&quot;</span>)), <span class="string">&quot; &quot;</span>)) - <span class="number">1</span>) \</span><br><span class="line">    .groupBy(<span class="string">&quot;id&quot;</span>).agg(func.<span class="built_in">sum</span>(<span class="string">&quot;connections&quot;</span>).alias(<span class="string">&quot;connections&quot;</span>))</span><br><span class="line">    </span><br><span class="line">mostPopular = connections.sort(func.col(<span class="string">&quot;connections&quot;</span>).desc()).first()</span><br><span class="line"></span><br><span class="line">mostPopularName = names.<span class="built_in">filter</span>(func.col(<span class="string">&quot;id&quot;</span>) == mostPopular[<span class="number">0</span>]).select(<span class="string">&quot;name&quot;</span>).first()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(mostPopularName[<span class="number">0</span>] + <span class="string">&quot; is the most popular superhero with &quot;</span> + <span class="built_in">str</span>(mostPopular[<span class="number">1</span>]) + <span class="string">&quot; co-appearances.&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3
id="mission2找出最不起眼的superhero">Mission2：找出最不起眼的superhero</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, StringType</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;MostObscureSuperheroes&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">schema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;id&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;name&quot;</span>, StringType(), <span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line">names = spark.read.schema(schema).option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot; &quot;</span>).csv(<span class="string">&quot;file:///SparkCourse/Marvel-names.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">lines = spark.read.text(<span class="string">&quot;file:///SparkCourse/Marvel-graph.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Small tweak vs. what&#x27;s shown in the video: we trim whitespace from each line as this</span></span><br><span class="line"><span class="comment"># could throw the counts off by one.</span></span><br><span class="line">connections = lines.withColumn(<span class="string">&quot;id&quot;</span>, func.split(func.trim(func.col(<span class="string">&quot;value&quot;</span>)), <span class="string">&quot; &quot;</span>)[<span class="number">0</span>]) \</span><br><span class="line">    .withColumn(<span class="string">&quot;connections&quot;</span>, func.size(func.split(func.trim(func.col(<span class="string">&quot;value&quot;</span>)), <span class="string">&quot; &quot;</span>)) - <span class="number">1</span>) \</span><br><span class="line">    .groupBy(<span class="string">&quot;id&quot;</span>).agg(func.<span class="built_in">sum</span>(<span class="string">&quot;connections&quot;</span>).alias(<span class="string">&quot;connections&quot;</span>))</span><br><span class="line">    </span><br><span class="line">minConnectionCount = connections.agg(func.<span class="built_in">min</span>(<span class="string">&quot;connections&quot;</span>)).first()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">minConnections = connections.<span class="built_in">filter</span>(func.col(<span class="string">&quot;connections&quot;</span>) == minConnectionCount)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用join方法联合两个表</span></span><br><span class="line">minConnectionsWithNames = minConnections.join(names, <span class="string">&quot;id&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The following characters have only &quot;</span> + <span class="built_in">str</span>(minConnectionCount) + <span class="string">&quot; connection(s):&quot;</span>)</span><br><span class="line"></span><br><span class="line">minConnectionsWithNames.select(<span class="string">&quot;name&quot;</span>).show()</span><br></pre></td></tr></table></figure>
<h3 id="mission-3-找到两个超级英雄的分离度">Mission 3
找到两个超级英雄的分离度</h3>
<p>分离度的意思就是再图中的距离</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Boilerplate stuff:</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;DegreesOfSeparation&quot;</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The characters we wish to find the degree of separation between:</span></span><br><span class="line">startCharacterID = <span class="number">5306</span> <span class="comment">#SpiderMan</span></span><br><span class="line">targetCharacterID = <span class="number">14</span>  <span class="comment">#ADAM 3,031 (who?)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Our accumulator, used to signal when we find the target character during</span></span><br><span class="line"><span class="comment"># our BFS traversal.</span></span><br><span class="line">hitCounter = sc.accumulator(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convertToBFS</span>(<span class="params">line</span>):</span><br><span class="line">    fields = line.split()</span><br><span class="line">    heroID = <span class="built_in">int</span>(fields[<span class="number">0</span>])</span><br><span class="line">    connections = []</span><br><span class="line">    <span class="keyword">for</span> connection <span class="keyword">in</span> fields[<span class="number">1</span>:]:</span><br><span class="line">        connections.append(<span class="built_in">int</span>(connection))</span><br><span class="line"></span><br><span class="line">    color = <span class="string">&#x27;WHITE&#x27;</span></span><br><span class="line">    distance = <span class="number">9999</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (heroID == startCharacterID):</span><br><span class="line">        color = <span class="string">&#x27;GRAY&#x27;</span></span><br><span class="line">        distance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (heroID, (connections, distance, color))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createStartingRdd</span>():</span><br><span class="line">    inputFile = sc.textFile(<span class="string">&quot;file:///sparkcourse/marvel-graph.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> inputFile.<span class="built_in">map</span>(convertToBFS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在原有rdd基础上加上新数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bfsMap</span>(<span class="params">node</span>):</span><br><span class="line">    characterID = node[<span class="number">0</span>]</span><br><span class="line">    data = node[<span class="number">1</span>]</span><br><span class="line">    connections = data[<span class="number">0</span>]</span><br><span class="line">    distance = data[<span class="number">1</span>]</span><br><span class="line">    color = data[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line"></span><br><span class="line">    <span class="comment">#If this node needs to be expanded...</span></span><br><span class="line">    <span class="keyword">if</span> (color == <span class="string">&#x27;GRAY&#x27;</span>):</span><br><span class="line">        <span class="keyword">for</span> connection <span class="keyword">in</span> connections:</span><br><span class="line">            newCharacterID = connection</span><br><span class="line">            newDistance = distance + <span class="number">1</span></span><br><span class="line">            newColor = <span class="string">&#x27;GRAY&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> (targetCharacterID == connection):</span><br><span class="line">                hitCounter.add(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            newEntry = (newCharacterID, ([], newDistance, newColor))</span><br><span class="line">            results.append(newEntry)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#We&#x27;ve processed this node, so color it black</span></span><br><span class="line">        color = <span class="string">&#x27;BLACK&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#Emit the input node so we don&#x27;t lose it.</span></span><br><span class="line">    results.append( (characterID, (connections, distance, color)) )</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="comment">#去除rdd冗余数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bfsReduce</span>(<span class="params">data1, data2</span>):</span><br><span class="line">    edges1 = data1[<span class="number">0</span>]</span><br><span class="line">    edges2 = data2[<span class="number">0</span>]</span><br><span class="line">    distance1 = data1[<span class="number">1</span>]</span><br><span class="line">    distance2 = data2[<span class="number">1</span>]</span><br><span class="line">    color1 = data1[<span class="number">2</span>]</span><br><span class="line">    color2 = data2[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    distance = <span class="number">9999</span></span><br><span class="line">    color = color1</span><br><span class="line">    edges = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># See if one is the original node with its connections.</span></span><br><span class="line">    <span class="comment"># If so preserve them.</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(edges1) &gt; <span class="number">0</span>):</span><br><span class="line">        edges.extend(edges1)</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(edges2) &gt; <span class="number">0</span>):</span><br><span class="line">        edges.extend(edges2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Preserve minimum distance</span></span><br><span class="line">    <span class="keyword">if</span> (distance1 &lt; distance):</span><br><span class="line">        distance = distance1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (distance2 &lt; distance):</span><br><span class="line">        distance = distance2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Preserve darkest color</span></span><br><span class="line">    <span class="keyword">if</span> (color1 == <span class="string">&#x27;WHITE&#x27;</span> <span class="keyword">and</span> (color2 == <span class="string">&#x27;GRAY&#x27;</span> <span class="keyword">or</span> color2 == <span class="string">&#x27;BLACK&#x27;</span>)):</span><br><span class="line">        color = color2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (color1 == <span class="string">&#x27;GRAY&#x27;</span> <span class="keyword">and</span> color2 == <span class="string">&#x27;BLACK&#x27;</span>):</span><br><span class="line">        color = color2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (color2 == <span class="string">&#x27;WHITE&#x27;</span> <span class="keyword">and</span> (color1 == <span class="string">&#x27;GRAY&#x27;</span> <span class="keyword">or</span> color1 == <span class="string">&#x27;BLACK&#x27;</span>)):</span><br><span class="line">        color = color1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (color2 == <span class="string">&#x27;GRAY&#x27;</span> <span class="keyword">and</span> color1 == <span class="string">&#x27;BLACK&#x27;</span>):</span><br><span class="line">        color = color1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (edges, distance, color)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Main program here:</span></span><br><span class="line">iterationRdd = createStartingRdd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Running BFS iteration# &quot;</span> + <span class="built_in">str</span>(iteration+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create new vertices as needed to darken or reduce distances in the</span></span><br><span class="line">    <span class="comment"># reduce stage. If we encounter the node we&#x27;re looking for as a GRAY</span></span><br><span class="line">    <span class="comment"># node, increment our accumulator to signal that we&#x27;re done.</span></span><br><span class="line">    mapped = iterationRdd.flatMap(bfsMap)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note that mapped.count() action here forces the RDD to be evaluated, and</span></span><br><span class="line">    <span class="comment"># that&#x27;s the only reason our accumulator is actually updated.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Processing &quot;</span> + <span class="built_in">str</span>(mapped.count()) + <span class="string">&quot; values.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (hitCounter.value &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Hit the target character! From &quot;</span> + <span class="built_in">str</span>(hitCounter.value) \</span><br><span class="line">            + <span class="string">&quot; different direction(s).&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reducer combines data for each character ID, preserving the darkest</span></span><br><span class="line">    <span class="comment"># color and shortest path.</span></span><br><span class="line">    iterationRdd = mapped.reduceByKey(bfsReduce)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="item-based-cf">Item-Based CF</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> func</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computeCosineSimilarity</span>(<span class="params">spark, data</span>):</span><br><span class="line">    <span class="comment"># Compute xx, xy and yy columns</span></span><br><span class="line">    pairScores = data \</span><br><span class="line">      .withColumn(<span class="string">&quot;xx&quot;</span>, func.col(<span class="string">&quot;rating1&quot;</span>) * func.col(<span class="string">&quot;rating1&quot;</span>)) \</span><br><span class="line">      .withColumn(<span class="string">&quot;yy&quot;</span>, func.col(<span class="string">&quot;rating2&quot;</span>) * func.col(<span class="string">&quot;rating2&quot;</span>)) \</span><br><span class="line">      .withColumn(<span class="string">&quot;xy&quot;</span>, func.col(<span class="string">&quot;rating1&quot;</span>) * func.col(<span class="string">&quot;rating2&quot;</span>)) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute numerator, denominator and numPairs columns</span></span><br><span class="line">    calculateSimilarity = pairScores \</span><br><span class="line">      .groupBy(<span class="string">&quot;movie1&quot;</span>, <span class="string">&quot;movie2&quot;</span>) \</span><br><span class="line">      .agg( \</span><br><span class="line">        func.<span class="built_in">sum</span>(func.col(<span class="string">&quot;xy&quot;</span>)).alias(<span class="string">&quot;numerator&quot;</span>), \</span><br><span class="line">        (func.sqrt(func.<span class="built_in">sum</span>(func.col(<span class="string">&quot;xx&quot;</span>))) * func.sqrt(func.<span class="built_in">sum</span>(func.col(<span class="string">&quot;yy&quot;</span>)))).alias(<span class="string">&quot;denominator&quot;</span>), \</span><br><span class="line">        func.count(func.col(<span class="string">&quot;xy&quot;</span>)).alias(<span class="string">&quot;numPairs&quot;</span>)</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate score and select only needed columns (movie1, movie2, score, numPairs)</span></span><br><span class="line">    result = calculateSimilarity \</span><br><span class="line">      .withColumn(<span class="string">&quot;score&quot;</span>, \</span><br><span class="line">        func.when(func.col(<span class="string">&quot;denominator&quot;</span>) != <span class="number">0</span>, func.col(<span class="string">&quot;numerator&quot;</span>) / func.col(<span class="string">&quot;denominator&quot;</span>)) \</span><br><span class="line">          .otherwise(<span class="number">0</span>) \</span><br><span class="line">      ).select(<span class="string">&quot;movie1&quot;</span>, <span class="string">&quot;movie2&quot;</span>, <span class="string">&quot;score&quot;</span>, <span class="string">&quot;numPairs&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get movie name by given movie id </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getMovieName</span>(<span class="params">movieNames, movieId</span>):</span><br><span class="line">    result = movieNames.<span class="built_in">filter</span>(func.col(<span class="string">&quot;movieID&quot;</span>) == movieId) \</span><br><span class="line">        .select(<span class="string">&quot;movieTitle&quot;</span>).collect()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;MovieSimilarities&quot;</span>).master(<span class="string">&quot;local[*]&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">movieNamesSchema = StructType([ \</span><br><span class="line">                               StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                               StructField(<span class="string">&quot;movieTitle&quot;</span>, StringType(), <span class="literal">True</span>) \</span><br><span class="line">                               ])</span><br><span class="line">    </span><br><span class="line">moviesSchema = StructType([ \</span><br><span class="line">                     StructField(<span class="string">&quot;userID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;movieID&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;rating&quot;</span>, IntegerType(), <span class="literal">True</span>), \</span><br><span class="line">                     StructField(<span class="string">&quot;timestamp&quot;</span>, LongType(), <span class="literal">True</span>)])</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># Create a broadcast dataset of movieID and movieTitle.</span></span><br><span class="line"><span class="comment"># Apply ISO-885901 charset</span></span><br><span class="line">movieNames = spark.read \</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;|&quot;</span>) \</span><br><span class="line">      .option(<span class="string">&quot;charset&quot;</span>, <span class="string">&quot;ISO-8859-1&quot;</span>) \</span><br><span class="line">      .schema(movieNamesSchema) \</span><br><span class="line">      .csv(<span class="string">&quot;file:///SparkCourse/ml-100k/u.item&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load up movie data as dataset</span></span><br><span class="line">movies = spark.read \</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) \</span><br><span class="line">      .schema(moviesSchema) \</span><br><span class="line">      .csv(<span class="string">&quot;file:///SparkCourse/ml-100k/u.data&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ratings = movies.select(<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Emit every movie rated together by the same user.</span></span><br><span class="line"><span class="comment"># Self-join to find every combination.</span></span><br><span class="line"><span class="comment"># Select movie pairs and rating pairs</span></span><br><span class="line">moviePairs = ratings.alias(<span class="string">&quot;ratings1&quot;</span>) \</span><br><span class="line">      .join(ratings.alias(<span class="string">&quot;ratings2&quot;</span>), (func.col(<span class="string">&quot;ratings1.userId&quot;</span>) == func.col(<span class="string">&quot;ratings2.userId&quot;</span>)) \</span><br><span class="line">            &amp; (func.col(<span class="string">&quot;ratings1.movieId&quot;</span>) &lt; func.col(<span class="string">&quot;ratings2.movieId&quot;</span>))) \</span><br><span class="line">      .select(func.col(<span class="string">&quot;ratings1.movieId&quot;</span>).alias(<span class="string">&quot;movie1&quot;</span>), \</span><br><span class="line">        func.col(<span class="string">&quot;ratings2.movieId&quot;</span>).alias(<span class="string">&quot;movie2&quot;</span>), \</span><br><span class="line">        func.col(<span class="string">&quot;ratings1.rating&quot;</span>).alias(<span class="string">&quot;rating1&quot;</span>), \</span><br><span class="line">        func.col(<span class="string">&quot;ratings2.rating&quot;</span>).alias(<span class="string">&quot;rating2&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">moviePairSimilarities = computeCosineSimilarity(spark, moviePairs).cache()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">len</span>(sys.argv) &gt; <span class="number">1</span>):</span><br><span class="line">    scoreThreshold = <span class="number">0.97</span></span><br><span class="line">    coOccurrenceThreshold = <span class="number">50.0</span></span><br><span class="line"></span><br><span class="line">    movieID = <span class="built_in">int</span>(sys.argv[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Filter for movies with this sim that are &quot;good&quot; as defined by</span></span><br><span class="line">    <span class="comment"># our quality thresholds above</span></span><br><span class="line">    filteredResults = moviePairSimilarities.<span class="built_in">filter</span>( \</span><br><span class="line">        ((func.col(<span class="string">&quot;movie1&quot;</span>) == movieID) | (func.col(<span class="string">&quot;movie2&quot;</span>) == movieID)) &amp; \</span><br><span class="line">          (func.col(<span class="string">&quot;score&quot;</span>) &gt; scoreThreshold) &amp; (func.col(<span class="string">&quot;numPairs&quot;</span>) &gt; coOccurrenceThreshold))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sort by quality score.</span></span><br><span class="line">    results = filteredResults.sort(func.col(<span class="string">&quot;score&quot;</span>).desc()).take(<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Top 10 similar movies for &quot;</span> + getMovieName(movieNames, movieID))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        <span class="comment"># Display the similarity result that isn&#x27;t the movie we&#x27;re looking at</span></span><br><span class="line">        similarMovieID = result.movie1</span><br><span class="line">        <span class="keyword">if</span> (similarMovieID == movieID):</span><br><span class="line">          similarMovieID = result.movie2</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(getMovieName(movieNames, similarMovieID) + <span class="string">&quot;\tscore: &quot;</span> \</span><br><span class="line">              + <span class="built_in">str</span>(result.score) + <span class="string">&quot;\tstrength: &quot;</span> + <span class="built_in">str</span>(result.numPairs))</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ML</category>
        <category>BDC</category>
      </categories>
  </entry>
  <entry>
    <title>CV项目准备</title>
    <url>/2023/08/30/CVProject/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="linksee">Linksee</h1>
<h2 id="multinet分类模型">MultiNet分类模型</h2>
<h1 id="other-point">Other point</h1>
<h2 id="multimodel-learning-多模态">MultiModel Learning 多模态</h2>
<p><strong>相较于图像、语音、文本等多媒体(Multi-media)数据划分形式，“模态”是一个更为细粒度的概念，同一媒介下可存在不同的模态。</strong>
比如我们可以把两种不同的语言当做是两种模态，甚至在两种不同情况下采集到的数据集，亦可认为是两种模态。</p>
<p><strong>多模态机器学习</strong>是从多种模态的数据中学习并且提升自身的算法，它不是某一个具体的算法，它是一类算法的总称。</p>
]]></content>
      <categories>
        <category>CV</category>
      </categories>
  </entry>
  <entry>
    <title>Classical Deep Learning Method</title>
    <url>/2023/07/25/ClassicalDLMethod/</url>
    <content><![CDATA[<p>经典深度学习模型</p>
<span id="more"></span>
<h1 id="residual-network">Residual Network</h1>
<h1 id="transformer">Transformer</h1>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>DHGCN(2HRDR)</title>
    <url>/2023/06/21/DHGCN/</url>
    <content><![CDATA[<p>propose DHGCN,2HRDR</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>task:
基于知识图谱的问答系统，在知识图谱中检索与问题相关的多个元组</p>
<p>contribution: propose a convolutional network for directed
hypergraph</p>
<h1 id="dhgcn">DHGCN</h1>
<h2 id="hgcn">HGCN</h2>
<p>given a hypergraph <span class="math inline">\(G=(V,E,W)\)</span>, as
well as the incidence matrix <span class="math inline">\(H\in
R^{|V|\times |E|}\)</span></p>
<p>the edge and vertex degrees:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621153922205.png"
alt="image-20230621153922205" />
<figcaption aria-hidden="true">image-20230621153922205</figcaption>
</figure>
<p>while the hypergraph convolutional networks is:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621155931211.png"
alt="image-20230621155931211" />
<figcaption aria-hidden="true">image-20230621155931211</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/IMG_0183(20230621-201655).JPG"
alt="IMG_0183(20230621-201655)" />
<figcaption aria-hidden="true">IMG_0183(20230621-201655)</figcaption>
</figure>
<h2 id="dhgcn-1">DHGCN</h2>
<p>the directed hypergraph can be denoted by two incidence matrices
<span class="math inline">\(H^{head}\)</span> and <span
class="math inline">\(H^{tail}\)</span></p>
<p>the degree:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621160733846.png"
alt="image-20230621160733846" />
<figcaption aria-hidden="true">image-20230621160733846</figcaption>
</figure>
<p>the directed hypergraph convolutional networks is:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621160751671.png"
alt="image-20230621160751671" />
<figcaption aria-hidden="true">image-20230621160751671</figcaption>
</figure>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/IMG_0184(20230621-202928).JPG" alt="IMG_0184(20230621-202928)" style="zoom:50%;" /></p>
<h1 id="hrdr">2HRDR</h1>
<h2 id="task-definition">Task Definition</h2>
<p>given a knowledge graph <span
class="math inline">\(K=(V,E,T)\)</span> and <span
class="math inline">\(q=(w_1,w_2,\cdots ,w_{|q|})\)</span>.</p>
<p>the task aims to pick the answers from <em>V</em>.</p>
<h2 id="method">Method</h2>
<h3 id="directed-hypergraph-retrieval-and-construction"><strong>Directed
Hypergraph Retrieval and</strong> <strong>Construction</strong></h3>
<p>find subgraph</p>
<ol type="1">
<li>obtain seed entities from the question by entity linking</li>
<li>get the entities set within L hops to form a subgraph</li>
<li>get <span class="math inline">\(H^{head}\)</span> and <span
class="math inline">\(H^{tail}\)</span></li>
</ol>
<h3 id="input-encoder">Input Encoder</h3>
<ol type="1">
<li><p>apply a bi-LSTM to encode question and obtain hidden states <span
class="math inline">\(H\in R^{|q|\times h}\)</span>,we assume
h=d</p></li>
<li><p>employ co-attention to learn query-aware entity
representation</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621170223607.png"
alt="image-20230621170223607" />
<figcaption aria-hidden="true">image-20230621170223607</figcaption>
</figure></li>
</ol>
<h3 id="reasoning-over-hypergraph">Reasoning over Hypergraph</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621163315446.png"
alt="image-20230621163315446" />
<figcaption aria-hidden="true">image-20230621163315446</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621172646592.png"
alt="image-20230621172646592" />
<figcaption aria-hidden="true">image-20230621172646592</figcaption>
</figure>
<ol type="1">
<li><p>Learn Relation Representation Explicitly</p>
<ol type="1">
<li><p>combine entity embedding and co-attention</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621173702999.png"
alt="image-20230621173702999" />
<figcaption aria-hidden="true">image-20230621173702999</figcaption>
</figure></li>
<li><p>propagation</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621173728920.png"
alt="image-20230621173728920" />
<figcaption aria-hidden="true">image-20230621173728920</figcaption>
</figure></li>
<li><p>aggregation</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621173815550.png"
alt="image-20230621173815550" />
<figcaption aria-hidden="true">image-20230621173815550</figcaption>
</figure></li>
</ol></li>
<li><p>Allocate Relation Weights Dynamically(dynamically allocated
hop-by-hop)</p>
<ol type="1">
<li><p>use co-attention to cal <span
class="math inline">\(R_{co\_attn}\)</span></p></li>
<li><p>compute the weight of edge</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621174053983.png"
alt="image-20230621174053983" />
<figcaption aria-hidden="true">image-20230621174053983</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621174101797.png"
alt="image-20230621174101797" />
<figcaption aria-hidden="true">image-20230621174101797</figcaption>
</figure></li>
</ol></li>
<li><p>Update Entity Adaptively</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230621174229381.png"
alt="image-20230621174229381" />
<figcaption aria-hidden="true">image-20230621174229381</figcaption>
</figure></li>
</ol>
]]></content>
      <categories>
        <category>GNN</category>
        <category>hypergraph</category>
      </categories>
  </entry>
  <entry>
    <title>DHT-Relation Work</title>
    <url>/2023/05/26/DHT-relation/</url>
    <content><![CDATA[<p>Relation work of DHT</p>
<span id="more"></span>
<h1 id="edgeformers">Edgeformers</h1>
<p>EDGEFORMERS: G RAPH-E MPOWERED TRANSFORMERS FOR REPRESENTATION L
EARNING ON T EXTUALE DGE NETWORKS</p>
<h2 id="background">Background</h2>
<ol type="1">
<li><p>Edge-aware GNNs:</p>
<p>studies assume the information carried by edges can be directly
described as an attribute vector.</p>
<ol type="1">
<li>This assumption holds well when edge features are categorical</li>
<li>cannot fully capture contextualized text semantic</li>
</ol></li>
<li><p>PLM-GNN</p>
<p>text information is first encoded by a PLM and then aggregated by a
GNN</p>
<ol type="1">
<li>such architectures process text and graph signals one after the
other, and fail to simultaneously model the deep interactions</li>
</ol></li>
<li><p>GNN-nested PLM</p>
<p>inject network information into the text encoding process</p>
<ol type="1">
<li>cannot be easily adapted to handle text-rich edges</li>
</ol></li>
</ol>
<h2 id="proposed-method">Proposed method</h2>
<ol type="1">
<li>we conduct edge representation learning by jointly considering text
and network information via a Transformer-based architecture
(Edgeformer-E).</li>
<li>perform node representation learning using the edge representation
learning module as building blocks (Edgeformer-N)</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230602122224210.png"
alt="image-20230602122224210" />
<figcaption aria-hidden="true">image-20230602122224210</figcaption>
</figure>
<h3
id="network-aware-edge-text-encoding-with-virtual-node-tokens">Network-aware
Edge Text Encoding with Virtual Node Tokens</h3>
<p>Given an edge <span
class="math inline">\(e_{ij}=(v_i,v_j)\)</span></p>
<p>Use a transformer to deal with text</p>
<p>introduce two virtual node tokens to represent $ v_i$ and <span
class="math inline">\(v_j\)</span> to transformer</p>
<p>$ v_i$ 和 <span class="math inline">\(v_j\)</span>
是连接边两个node的embedding]</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230602122208124.png"
alt="image-20230602122208124" />
<figcaption aria-hidden="true">image-20230602122208124</figcaption>
</figure>
<h3 id="text-a-ware-node-representation-learning-edgeformer-n">TEXT-A
WARE NODE REPRESENTATION LEARNING (EDGEFORMER-N)</h3>
<h4 id="node-aggregating-edge-representations">node-Aggregating Edge
Representations</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230602122457727.png"
alt="image-20230602122457727" />
<figcaption aria-hidden="true">image-20230602122457727</figcaption>
</figure>
<h3
id="enhancing-edge-representations-with-the-nodes-local-network-structure">Enhancing
Edge Representations with the Node’s Local Network Structure</h3>
<p>add one more virtual node in edge learning
:获取与边节点连接的邻居边的信息</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230602122540378.png"
alt="image-20230602122540378" />
<figcaption aria-hidden="true">image-20230602122540378</figcaption>
</figure>
<p>邻居边的embedding经过一个新tranformer，获取<cls>节点的embedding，作为参加edge
learning的虚拟节点</p>
<h1 id="gratis">GRATIS</h1>
<p>Paper：GRATIS: Deep Learning <strong>G</strong>raph
<strong>R</strong>epresentation with T<strong>a</strong>sk-specifific
<strong>T</strong>opology and Mult<strong>i</strong>-dimensional Edge
Feature<strong>s</strong></p>
<p>总结：计算一个全局representation-X，X经过MLP和reshape、softmax等操作变成和邻接矩阵大小相同的权重矩阵，然后得到一个edge出现的概率矩阵，概率大于一定阈值就补全边。</p>
<p>edge用向量表示而不是一个一维数（一维权重）。</p>
<h2 id="methology">Methology</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617164254419.png"
alt="image-20230617164254419" />
<figcaption aria-hidden="true">image-20230617164254419</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617164314513.png"
alt="image-20230617164314513" />
<figcaption aria-hidden="true">image-20230617164314513</figcaption>
</figure>
<h3 id="backbone">Backbone</h3>
<p>反正就是各种方法得到一个全局表示X</p>
<h3 id="graph-definition">Graph Definition</h3>
<p>采用图原来的点和边</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617164457095.png"
alt="image-20230617164457095" />
<figcaption aria-hidden="true">image-20230617164457095</figcaption>
</figure>
<h3 id="task-specific-topology-prediction">Task-specific Topology
Prediction</h3>
<p>用X计算出一个概率矩阵</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617164752154.png"
alt="image-20230617164752154" />
<figcaption aria-hidden="true">image-20230617164752154</figcaption>
</figure>
<p>h（x）为mlp</p>
<p>如果概率大于某个阈值，增加新边</p>
<h3
id="multi-dimensional-edge-feature-generation"><strong>Multi-dimensional
Edge Feature Generation</strong></h3>
<p>根据边两端的节点计算边</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617165302836.png"
alt="image-20230617165302836" />
<figcaption aria-hidden="true">image-20230617165302836</figcaption>
</figure>
<p><strong>VCR</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617165318193.png"
alt="image-20230617165318193" />
<figcaption aria-hidden="true">image-20230617165318193</figcaption>
</figure>
<p><strong>VVR</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617165420670.png"
alt="image-20230617165420670" />
<figcaption aria-hidden="true">image-20230617165420670</figcaption>
</figure>
<p>fifinally employ either a pooling layer or a fully-connected layer,
to flatten <span class="math inline">\(F_{i,x,j}\)</span> and <span
class="math inline">\(F_{ *j,x,i*}\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617165554284.png"
alt="image-20230617165554284" />
<figcaption aria-hidden="true">image-20230617165554284</figcaption>
</figure>
<h1 id="surge">SURGE</h1>
<p>Paper： Knowledge-Consistent Dialogue Generation with Knowledge
Graphs</p>
<p>总结：在KG大图中检索与文本相关的子图，用GCN计算node
representation，用ENGNN计算 edge representation。然后用在后面的任务</p>
]]></content>
      <categories>
        <category>GNN</category>
        <category>EdgeLearning</category>
      </categories>
  </entry>
  <entry>
    <title>DHT</title>
    <url>/2023/03/20/DHT/</url>
    <content><![CDATA[<p>DHT, which transforms the edges of a graph into the nodes of a
hypergraph.</p>
<p>ENGNN, use hypergraph after DHT to propagation</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>Before methods only capture edge information implicitly, e.g. used as
weight.</p>
<h1 id="contribute">Contribute</h1>
<ol type="1">
<li>propose DHT, Dual Hypergraph Transformation</li>
<li>propose a novel edge representation learning scheme ENGNN by using
DHT.</li>
<li>propose novel edge pooling methods.</li>
</ol>
<h1 id="method">Method</h1>
<h2 id="dht-how-to-transfer-graph-to-hypergraph">DHT： how to transfer
graph to hypergraph</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230320171020430.png"
alt="image-20230320171020430" />
<figcaption aria-hidden="true">image-20230320171020430</figcaption>
</figure>
<h3 id="step1-get-origin-graph-representation">Step1: Get origin graph
representation</h3>
<p>Firstly, we get the initial node feature and edge feature. <span
class="math display">\[
node \space  feature: X\in R^{n\times d}
\]</span></p>
<p><span class="math display">\[
edge\space feature: E\in R^{m\times d&#39;}
\]</span></p>
<p>Than we use an incidence matrix M rather than an adjacency matrix to
represent graph structure. <span class="math display">\[
incidence\space matrix: M\in \{0,1\}^{n\times m}
\]</span> So the origin graph is <span class="math display">\[
G=(X,M,E)
\]</span></p>
<h3 id="step-2-use-dht-to-get-hypergraph-g">Step 2: Use DHT to get
hypergraph <span class="math inline">\(G^*\)</span></h3>
<p>The hypergraph represent <span class="math display">\[
G^*=(X^*,M^*,E^*)
\]</span></p>
<p><span class="math display">\[
X^*=E
\]</span></p>
<p><span class="math display">\[
M^*=M^T
\]</span></p>
<p><span class="math display">\[
E^*=X
\]</span></p>
<p><span class="math display">\[
DHT:G=(X,M,E)-&gt;G^*=(E,M^T,X)
\]</span></p>
<p>While DHT is a bijective transformation: <span
class="math display">\[
DHT:G^*=(E,M^T,X)-&gt;G=(X,M,E)
\]</span></p>
<h2
id="ehgnn-an-edge-representation-learning-framework-using-dht">EHGNN: an
edge representation learning framework using DHT</h2>
<p><span class="math display">\[
E^{(l+1)}=ENGNN(X^{(l)},M,E^{(l)})=GNN(DHT(X^{(l)},M,E^{(l)}))
\]</span></p>
<p>So ENGNN consists of DHT and GNN, while GNN can be any GNN
function.</p>
<p>After ENGNN, EHGNN, <span class="math inline">\(E^{(L)}\)</span> is
returned to the original graph by applying DHT to dual hypergraph <span
class="math inline">\(G^∗\)</span>. Then, the remaining step is how to
make use of these edge-wise representations to finish the task.</p>
<h2 id="pooling">Pooling</h2>
<p>To be continue...</p>
<h1 id="advantage">Advantage</h1>
<h2 id="dht">DHT</h2>
<ol type="1">
<li>low time complexity</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230320165122363.png"
alt="image-20230320165122363" />
<figcaption aria-hidden="true">image-20230320165122363</figcaption>
</figure>
]]></content>
      <categories>
        <category>GNN</category>
        <category>EdgeLearning</category>
      </categories>
  </entry>
  <entry>
    <title>Data Structure and algorithms</title>
    <url>/2023/04/14/DataStructure/</url>
    <content><![CDATA[<ol type="1">
<li>Complexity</li>
<li>Linear structures</li>
<li>Tree structures</li>
<li>Other common data structures</li>
<li>Search algorithms</li>
<li>Sorting algorithms</li>
</ol>
<span id="more"></span>
<h1 id="complexity">Complexity</h1>
<h1 id="array">Array</h1>
<p>fixed length, indexable, should shift after insertions and
deletions</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230419185630699.png"
alt="image-20230419185630699" />
<figcaption aria-hidden="true">image-20230419185630699</figcaption>
</figure>
<h2 id="array-operation">Array Operation</h2>
<h3 id="insertion-on">Insertion O(n)</h3>
<ol type="1">
<li>insert an element in the specified index</li>
<li>shift the subsequent item to the right</li>
</ol>
<h3 id="deletion-on">Deletion O(n)</h3>
<ol type="1">
<li>delete the specified element</li>
<li>shift the subsequent item to the left</li>
</ol>
<h3 id="searching-in-a-sorted-array">Searching in a sorted array</h3>
<h4 id="linear-search">Linear search</h4>
<p>Best case-O(1)</p>
<p>Worst case-O(n)</p>
<p>Average case-O(n/2)-&gt;O(n)</p>
<h4 id="binary-search-ologn">Binary search O(logn)</h4>
<h3 id="sorting-array">Sorting array</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230419191311851.png"
alt="image-20230419191311851" />
<figcaption aria-hidden="true">image-20230419191311851</figcaption>
</figure>
<h1 id="stack">Stack</h1>
<p>Last In First Out</p>
<h2 id="stack-operation">Stack Operation</h2>
<p>Push(S,x): insert x to the top of the stack S</p>
<p>Pop(S): extract the top of the stack S</p>
<p>Top(s): return the topmost element of stack S without removing it</p>
<p>isEmpty(s): return whether the stack S is empty</p>
<h2 id="implementation">Implementation</h2>
<h3 id="array-1">Array</h3>
<h4 id="push-o1">Push() O(1)</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if s.top=s.len</span><br><span class="line">	error &#x27;full&#x27;</span><br><span class="line">else</span><br><span class="line">	s.top=s.top+1</span><br><span class="line">	s[s.top]=x</span><br></pre></td></tr></table></figure>
<h4 id="pop-o1">Pop() O(1)</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if isEmpty(s)</span><br><span class="line">	error &#x27;empty&#x27;</span><br><span class="line">else</span><br><span class="line">	s.top=s.top-1</span><br><span class="line">	return s[s.top+1]</span><br></pre></td></tr></table></figure>
<h4 id="top-o1">Top() O(1)</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if isEmpty(s)</span><br><span class="line">	error &#x27;empty&#x27;</span><br><span class="line">else</span><br><span class="line">	return s[s.top]</span><br></pre></td></tr></table></figure>
<h4 id="isempty-o1">isEmpty() O(1)</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if s.len=0</span><br><span class="line">	return true</span><br><span class="line">else</span><br><span class="line">	return false</span><br></pre></td></tr></table></figure>
<h4 id="search-on">Search O(n)</h4>
<h2 id="use-stack-implements-a-simple-calculator">Use stack implements a
simple calculator</h2>
<ol type="1">
<li>transfer to postfix notation</li>
</ol>
<p>3-2-1&gt;&gt;32-1-</p>
<p>3-2*1&gt;&gt;321*-</p>
<ol start="2" type="1">
<li>use stack to calculate</li>
</ol>
<p>3-2-1&gt;&gt;32-1-</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">push(3)</span><br><span class="line">push(2)</span><br><span class="line">Meet(-);Pop;Pop;Push(3-2=1)</span><br><span class="line">Push(1)</span><br><span class="line">Meet(-);Pop;Pop;Push(1-1=0)</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>exercise</li>
</ol>
<p>10 + (44 − 1) * 3 + 9 / 2</p>
<p>((1 - 2) - 5) + (6 / 5)</p>
<p>(((22 / 7) + 4) * (6 - 2))</p>
<h1 id="queue">Queue</h1>
<p>First In First Out</p>
<h2 id="operation">Operation</h2>
<p>Enqueue(Q,x): put an element x at the end of queue Q</p>
<p>Dequeue(Q): extract the first element from queue Q</p>
<h2 id="implementation-1">Implementation</h2>
<h3 id="array-1-1">Array 1</h3>
<p>Enqueue in the tail -O(1)</p>
<p>Dequeue in the position0 -O(n)</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230419194745117.png"
alt="image-20230419194745117" />
<figcaption aria-hidden="true">image-20230419194745117</figcaption>
</figure>
<h3 id="array-2">Array 2</h3>
<p>Enqueue in the position0 -O(n)</p>
<p>Dequeue in the tail -O(1)</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230419195104009.png"
alt="image-20230419195104009" />
<figcaption aria-hidden="true">image-20230419195104009</figcaption>
</figure>
<h3 id="array-3--circular-queue">Array 3 -Circular queue</h3>
<p>Enqueue: O(1)</p>
<p>Dequeue: O(1)</p>
<p>Peeking (get the front item without removing it) O(1)</p>
<p>isFull: O(1)</p>
<p>isEmpty: O(1)</p>
<p>search: O(n)</p>
<h4 id="algorithm-implement">algorithm implement</h4>
<p>Data members:</p>
<p>• Q: an array of items • Q.len: length of array • Q.front: position
of the front item • Q.rear: rear item position + 1 (not an item)</p>
<h5 id="enqueue">Enqueue</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if isFull(Q)</span><br><span class="line">	error &#x27;full&#x27;</span><br><span class="line">else</span><br><span class="line">	Q[Q.rear] = x</span><br><span class="line">	if Q.rear==Q.len:</span><br><span class="line">		Q.rear=1</span><br><span class="line">	else</span><br><span class="line">		Q.rear=Q.rear+1</span><br></pre></td></tr></table></figure>
<h5 id="dequeue">Dequeue</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if isEmpty(W)</span><br><span class="line">	error &#x27;Empty&#x27;</span><br><span class="line">else</span><br><span class="line">	x=Q[Q.front]</span><br><span class="line">	if Q.front==Q.len</span><br><span class="line">		Q.front=1</span><br><span class="line">	else</span><br><span class="line">		Q.front=Q.front+1</span><br></pre></td></tr></table></figure>
<h5 id="isfull-and-isempty">isFull and isEmpty</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230419201711632.png"
alt="image-20230419201711632" />
<figcaption aria-hidden="true">image-20230419201711632</figcaption>
</figure>
<h1 id="linked-list">Linked List</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230420110345241.png"
alt="image-20230420110345241" />
<figcaption aria-hidden="true">image-20230420110345241</figcaption>
</figure>
<p>Node: An object containing data and pointer(s) Pointer: Reference to
another node Head: The first node in a linked list Tail: The last node
in a linked list</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230420112447328.png"
alt="image-20230420112447328" />
<figcaption aria-hidden="true">image-20230420112447328</figcaption>
</figure>
<p>No limited to size</p>
<p>require more space per element</p>
<h2 id="initial">Initial</h2>
<p>...</p>
<h2 id="operation-1">Operation</h2>
<ol type="1">
<li><p>print</p></li>
<li><p>insert</p></li>
<li><p>Delete</p></li>
</ol>
<h1 id="hash-table">Hash table</h1>
<p>Dictionary ADT</p>
<p>key:value</p>
<h2 id="implement-of-adt">implement of ADT</h2>
<h3 id="array-3">array</h3>
<p>Space usage: O(n)</p>
<p>Search usage: O(n)</p>
<table>
<thead>
<tr class="header">
<th>Array index</th>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>3</td>
<td>Coffee</td>
</tr>
<tr class="even">
<td>1</td>
<td>15</td>
<td>Bread</td>
</tr>
<tr class="odd">
<td>2</td>
<td>8</td>
<td>Tea</td>
</tr>
</tbody>
</table>
<h3 id="large-array">Large array</h3>
<p>Space usage: O(U)-max key</p>
<p>Search usage: O(1)</p>
<table>
<thead>
<tr class="header">
<th>Array index</th>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>3</td>
<td>3</td>
<td>Coffee</td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>8</td>
<td>8</td>
<td>Tea</td>
</tr>
<tr class="odd">
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td>15</td>
<td>15</td>
<td>Bread</td>
</tr>
</tbody>
</table>
<h3 id="hash-table-1">Hash table</h3>
<p>Converts a key (of a large range) to a hash value (of a small range).
e.g. k mod m</p>
<p>Space usage: O(n)</p>
<p>Search usage: O(1)</p>
<h4 id="collision-solution">Collision solution</h4>
<p>collision: different keys have the same hash value</p>
<h5 id="chaining">Chaining</h5>
<h6 id="use-a-linked-list">use a linked list</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230422183421651.png"
alt="image-20230422183421651" />
<figcaption aria-hidden="true">image-20230422183421651</figcaption>
</figure>
<h6 id="load-factor">load factor</h6>
<p><span class="math display">\[
\lambda = \frac{n}{m}
\]</span></p>
<p>n is the number of keys, m is the total number of buckets.</p>
<p>Measures how full the hash table is</p>
<p>it is suggested to keep <span class="math inline">\(\lambda\)</span>
&lt; 1</p>
<h6 id="cost">cost</h6>
<ol type="1">
<li><p>time</p>
<p>cost of search: O(1)+O(l), l is the length of the linked list</p>
<p>worst case: O(1)+O(n)</p>
<p>Average case: O(1)+O(<span
class="math inline">\(\lambda\)</span>)</p></li>
<li><p>space</p>
<p>requires additional space to store the pointers in linked lists of
entries.</p>
<p>Worst case: n-1 additional space</p>
<p>Average case: <span class="math inline">\(\lambda\)</span>-1
additional space</p></li>
</ol>
<h5 id="opening-addressing-probing">Opening addressing: probing</h5>
<h6 id="insert">Insert</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230422185347171.png"
alt="image-20230422185347171" />
<figcaption aria-hidden="true">image-20230422185347171</figcaption>
</figure>
<h6 id="search">Search</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230422185455352.png"
alt="image-20230422185455352" />
<figcaption aria-hidden="true">image-20230422185455352</figcaption>
</figure>
<h6 id="delete">Delete</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230422190114349.png"
alt="image-20230422190114349" />
<figcaption aria-hidden="true">image-20230422190114349</figcaption>
</figure>
<h6 id="load-factor-1">Load factor</h6>
<p>must <span class="math inline">\(\lambda &lt; 1\)</span></p>
<p>How to deal with the hash table when ! becomes large?</p>
<ol type="1">
<li>Make a large hash table and move all elements into it.</li>
<li>Simply add an additional hash table</li>
</ol>
<h6 id="probing-type">probing type</h6>
<ol type="1">
<li><p>Linear probing</p>
<p><span class="math display">\[
H(k,i) = (H_0(k) + i)\space mod \space m
\]</span> have clustering problem, multiple keys are hashed to
consecutive slots.</p>
<p>performance degrade significantly when <span
class="math inline">\(\lambda\)</span>&gt; 0.5.</p></li>
<li><p>Quadratic probing <span class="math display">\[
H(k,i) = (H_0(k) + a\cdot i+b\cdot i^2)\space mod \space m
\]</span> reduces the clustering problem.</p></li>
</ol>
<h3 id="string-key">string key</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230422191105400.png"
alt="image-20230422191105400" />
<figcaption aria-hidden="true">image-20230422191105400</figcaption>
</figure>
<h1 id="tree">Tree</h1>
<p>a tree is an abstract model of a hierarchical structure consists of a
set of nodes and a set of edges.</p>
<p>Every node except the root has exactly one parent node.</p>
<h2 id="definition">Definition</h2>
<ol type="1">
<li><p>Length of a path： The number of edges in the path.</p></li>
<li><p>The height of a node：</p>
<p>The largest path length from that node to any leaf node (not
including ancestors).</p>
<p>Each leaf node has the height 0.</p></li>
<li><p>The height of a tree: The maximum level of a node in a tree is
the tree’s height.</p></li>
<li><p>The depth of a node:</p>
<p>The node's level (depth) of a node is the length of the path from
that node to the root.</p>
<p>The depth of the root is zero.</p></li>
</ol>
<h2 id="binary-tree">Binary Tree</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230424201038461.png"
alt="image-20230424201038461" />
<figcaption aria-hidden="true">image-20230424201038461</figcaption>
</figure>
<h3 id="full-binary-tree">Full Binary Tree</h3>
<p>Every node has either 0 or 2 children.</p>
<h3 id="complete-binary-tree">Complete Binary Tree</h3>
<p>Every level, except the last level, is completely filled, and all
nodes in the last level are as far left as possible (left
justified).</p>
<h3 id="perfect-binary-tree">Perfect Binary Tree</h3>
<p>Every node except the leaf nodes have two children and every level is
completely filled.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230424201302544.png"
alt="image-20230424201302544" />
<figcaption aria-hidden="true">image-20230424201302544</figcaption>
</figure>
<p>list representation: [Root, left-sub-tree, right-sub-tree]</p>
<h3 id="binary-search-tree">Binary Search Tree</h3>
<p>Insertion - O(h)</p>
<p>Search - O(h)</p>
<p>Deletion: O(h)</p>
<p>ℎ is O(log⁡n) if tree is balanced.</p>
<p>all is O(n) in worst case</p>
<p>左小右大</p>
<h4 id="search-operation">Search Operation</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Algorithm SearcℎBST(t, target)</span><br><span class="line">  Input: the BST t <span class="keyword">and</span> the target</span><br><span class="line"></span><br><span class="line">  p = t.root</span><br><span class="line">  <span class="keyword">while</span> p≠null do</span><br><span class="line">      <span class="keyword">if</span> target=p.value do</span><br><span class="line">          <span class="keyword">return</span> p</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> target&lt;p.value do</span><br><span class="line">          p=p.left</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">          p=p.rigℎt</span><br><span class="line">  end</span><br><span class="line">  <span class="keyword">return</span> null</span><br></pre></td></tr></table></figure>
<h4 id="insert-1">Insert</h4>
<p>average case: O(n) = logn</p>
<p>worst case: O(n) = n</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Algorithm Insert(t, node)</span><br><span class="line">  Input: the BST t <span class="keyword">and</span> the node</span><br><span class="line"></span><br><span class="line">  p = t.root</span><br><span class="line">  <span class="keyword">if</span> p=null do</span><br><span class="line">      t.root=node</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  end</span><br><span class="line">  <span class="keyword">while</span> p≠null do</span><br><span class="line">      prev=p</span><br><span class="line">      <span class="keyword">if</span> node.value&lt;p.value do</span><br><span class="line">          p=p.left</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> node.value&gt;p.value do</span><br><span class="line">          p=p.rigℎt</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line">  end</span><br><span class="line">  <span class="keyword">if</span> node.value&lt;prev do</span><br><span class="line">      prev.left=node</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      prev.rigℎt=node</span><br></pre></td></tr></table></figure>
<h4 id="find-minimun">find minimun</h4>
<p>O(h)-ℎ is the depth of the tree</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Algorithm Minimum(t)</span><br><span class="line">  Input: the BST t</span><br><span class="line"></span><br><span class="line">  p = t.root</span><br><span class="line">  <span class="keyword">while</span> p.left≠null do</span><br><span class="line">      p=p.left</span><br><span class="line">  end</span><br><span class="line">  <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure>
<h4 id="deletion-in-bst">Deletion in BST</h4>
<ol type="1">
<li><p>has no child</p>
<p>delete the node</p></li>
<li><p>has one child</p>
<p>use the child to replace z</p></li>
<li><p>has two children</p>
<p>delete the minimum node x of the right subtree of z (i.e., x is the
successor of z), then replace z by x.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230424233325065.png"
alt="image-20230424233325065" />
<figcaption aria-hidden="true">image-20230424233325065</figcaption>
</figure></li>
</ol>
<h3 id="tree-traversal">Tree Traversal</h3>
<h4 id="depth-first-tree-traversal">Depth-first Tree Traversal</h4>
<h5 id="implement-stack">implement: stack</h5>
<h6 id="preorder-前序">preorder 前序</h6>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preorder</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> </span><br><span class="line">    <span class="built_in">print</span>(root.val)</span><br><span class="line">    preorder(root.left)</span><br><span class="line">    preorder(root.right)</span><br></pre></td></tr></table></figure>
<h6 id="postorder-后序">postorder 后序</h6>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">postorder</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> </span><br><span class="line">    preorder(root.left)</span><br><span class="line">    preorder(root.right)</span><br><span class="line">    <span class="built_in">print</span>(root.val)</span><br></pre></td></tr></table></figure>
<h6 id="inorder-中序">inorder 中序</h6>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inorder</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> </span><br><span class="line">    preorder(root.left)</span><br><span class="line">    <span class="built_in">print</span>(root.val)</span><br><span class="line">    preorder(root.right)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<h4 id="breadth-first-tree-traversal">Breadth-first Tree Traversal</h4>
<h5 id="implement-queue">implement: queue</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bfs</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> roor: <span class="keyword">return</span></span><br><span class="line">    q=[root]</span><br><span class="line">    result=[]</span><br><span class="line">    <span class="keyword">while</span> q:</span><br><span class="line">        child=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> q:</span><br><span class="line">            result.append(i)</span><br><span class="line">            <span class="keyword">if</span> i.left:</span><br><span class="line">                child.append(i.left)</span><br><span class="line">            <span class="keyword">if</span> i.right:</span><br><span class="line">                child.append(i.right)</span><br><span class="line">        q=child</span><br><span class="line">     <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h1 id="sorting">Sorting</h1>
<p>stable, unstable, inplace, outplace</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425140502996.png"
alt="image-20230425140502996" />
<figcaption aria-hidden="true">image-20230425140502996</figcaption>
</figure>
<h2 id="selection-sort">Selection sort</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425130213964.png"
alt="image-20230425130213964" />
<figcaption aria-hidden="true">image-20230425130213964</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425130244294.png"
alt="image-20230425130244294" />
<figcaption aria-hidden="true">image-20230425130244294</figcaption>
</figure>
<p>time-<span class="math inline">\(O(n^2)\)</span></p>
<p>in-place</p>
<p>unstable</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">selection_sort</span>(<span class="params">arr</span>):</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)-<span class="number">1</span>):</span><br><span class="line">		min_ind = i</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, <span class="built_in">len</span>(arr)):</span><br><span class="line">            <span class="keyword">if</span> arr[j]&lt;arr[min_ind]:</span><br><span class="line">                min_index=j</span><br><span class="line">        <span class="keyword">if</span> i!=min_ind:</span><br><span class="line">            arr[min_ind],arr[i]=arr[i],arr[min_index]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<h2 id="insertion-sort">Insertion Sort</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425130404747.png"
alt="image-20230425130404747" />
<figcaption aria-hidden="true">image-20230425130404747</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425130733053.png"
alt="image-20230425130733053" />
<figcaption aria-hidden="true">image-20230425130733053</figcaption>
</figure>
<p>time -<span class="math inline">\(O(n^2)\)</span></p>
<p>in-place</p>
<p>stable</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def insertionSort(arr): </span><br><span class="line">    for i in range(1, len(arr)): </span><br><span class="line">        key = arr[i] </span><br><span class="line">        j = i-1</span><br><span class="line">        while j &gt;=0 and key &lt; arr[j] : </span><br><span class="line">                arr[j+1] = arr[j] </span><br><span class="line">                j -= 1</span><br><span class="line">        arr[j+1] = key </span><br></pre></td></tr></table></figure>
<h2 id="merge-sort">Merge Sort</h2>
<p>time - O(nlogn)</p>
<p>not in-place</p>
<p>stable</p>
<ol type="1">
<li>Divide: divide the array A into two sub-arrays (L and R) of n/2
numbers each.</li>
<li>Conquer: sort two sub-arrays recursively.</li>
<li>Combine: merge two sorted sub-arrays into a sorted array.</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230425141231598.png"
alt="image-20230425141231598" />
<figcaption aria-hidden="true">image-20230425141231598</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Algorithm MergeSort(A, n)</span><br><span class="line">  Input: the n-size array A</span><br><span class="line"></span><br><span class="line">  if n=1 then</span><br><span class="line">      return A</span><br><span class="line">  (L,R)=A</span><br><span class="line">  L’=MergeSort(L)</span><br><span class="line">  R’=MergeSort(R)</span><br><span class="line">  return Merge(L’, R’)</span><br></pre></td></tr></table></figure>
<h3 id="merge-function---on">Merge function - O(n)</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Algorithm Merge(A, n_A,B,n_B,C)</span><br><span class="line">  Input: the n_A-size array A and n_B-size array B</span><br><span class="line">  Output: the (n_A+n_B−1)-size array C</span><br><span class="line"></span><br><span class="line">  i=0,j=0,k=0</span><br><span class="line">  while i&lt;n_A and j&lt;n_B do</span><br><span class="line">      if A[i]≤B[j] then</span><br><span class="line">          C[k]=A[i], i=i+1</span><br><span class="line">      else</span><br><span class="line">          C[k]=B[j], j=j+1</span><br><span class="line">      end</span><br><span class="line">      k=k+1</span><br><span class="line">  end</span><br><span class="line">  if i=n_A then</span><br><span class="line">      C[k,⋯]=B[j,⋯]</span><br><span class="line">  else</span><br><span class="line">      C[k,⋯]=A[i,⋯]</span><br><span class="line">  end</span><br></pre></td></tr></table></figure>
<h2 id="quick-sort">Quick Sort</h2>
<p>O(nlogn)</p>
<p>in-place</p>
]]></content>
      <categories>
        <category>DS</category>
      </categories>
  </entry>
  <entry>
    <title>分布式训练</title>
    <url>/2024/05/08/DistributeTraining/</url>
    <content><![CDATA[<p>分布式训练</p>
<span id="more"></span>
<p>参考文章：</p>
<p><a href="https://zhuanlan.zhihu.com/p/394064174">Optimizer state
sharding (ZeRO) - 知乎 (zhihu.com)</a>写的很好很详细</p>
<h1 id="模型训练流程">模型训练流程</h1>
<p>1、正向传播计算出output</p>
<p>2、反向传播计算梯度</p>
<p>3、得到梯度后，用optimizer优化参数</p>
<h1 id="数据并行">数据并行</h1>
<h2 id="dp">DP</h2>
<p>DP只能在一个主机上多个GPU间进行分布式训练。</p>
<figure>
<img
src="https://pic2.zhimg.com/v2-040f702b1af9554c769c7b1ae7e4ef39_r.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>流程：</p>
<ul>
<li>将 inputs 从主 GPU 分发到所有 GPU 上。</li>
<li>将 model 从主 GPU 分发到所有 GPU 上。</li>
<li>每个 GPU 分别独立进行前向传播，得到 outputs。</li>
<li>将每个 GPU 的 outputs 发回主 GPU。</li>
<li>在主 GPU 上，通过 loss function 计算出 loss，对 loss function
求导，求出损失梯度。</li>
<li>计算得到的梯度分发到所有 GPU 上。</li>
<li>反向传播计算参数梯度。</li>
<li>将所有梯度回传到主 GPU，通过梯度更新模型权重。</li>
<li>不断重复上面的过程</li>
</ul>
<h2 id="ddp">DDP</h2>
<p>可以在不同主机的GPU进行分布式训练</p>
<figure>
<img
src="https://pic1.zhimg.com/v2-d0347bc4f3f85e0944b39c5e18864af0_r.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>下面rank代表一个worker</p>
<ul>
<li>首先将 rank=0 进程中的模型参数广播到进程组中的其他进程；</li>
<li>然后，每个 DDP 进程都会创建一个 <strong>local Reducer</strong>
来负责梯度同步。</li>
<li>在训练过程中，每个进程从磁盘加载 batch 数据，并将它们传递到其
GPU。独立完成向前传播，计算出loss。</li>
<li>反向传播过程中，梯度在各个 GPUs 间进行 All-Reduce，每个 GPU
都收到其他 GPU
的梯度，从而可以独自进行反向传播和参数更新。同时，每一层的梯度不依赖于前一层，所以<strong>梯度的
All-Reduce 和后向过程同时计算</strong>，以进一步缓解网络瓶颈。</li>
<li>用optimizer更新参数：每个节点都得到了平均梯度，原参数也是相同的，这样各个
GPU 中的模型参数保持同步 。</li>
</ul>
<h2 id="zero">ZeRO</h2>
<p>数据并行因其易用性，得到了最为广泛的应用。然而，数据并行会产生大量冗余
Model States 的空间占用。ZeRO
的本质，是在数据并行的基础上，对冗余空间占用进行深度优化。</p>
<p>Model State的组成：</p>
<ol type="1">
<li>Optimizer States: <strong><code>Optimizer States</code></strong> 是
<strong>Optimizer</strong> 在进行梯度更新时所需要用到的数据，例如 SGD
中的<code>Momentum</code>以及使用混合精度训练时的<code>Float32 Master Parameters</code>。</li>
<li>Gradient：
在反向传播后所产生的梯度信息，其决定了参数的更新方向。</li>
<li>Model Parameter:
模型参数，也就是我们在整个过程中通过数据“学习”的信息。</li>
</ol>
<p>在传统数据并行下，每个进程都使用同样参数来进行训练。每个进程也会持有对<code>Optimizer States</code>的完整拷贝，同样占用了大量显存。在混合精度场景下，以参数量为<code>Ψ</code>的模型和Adam
optimzier为例，Adam需要保存： -
Float16的<code>参数</code>和<code>梯度</code>的备份。这两项分别消耗了2Ψ和2Ψ
Bytes内存；（1 Float16 = 2 Bytes） -
Float32的<code>参数</code>，<code>Momentum</code>，<code>Variance</code>备份，对应到
3 份<code>4Ψ</code>的内存占用。（1 Float32 = 4 Bytes）</p>
<p>最终需要<code>2Ψ + 2Ψ + KΨ = 16Ψ bytes</code>的显存。一个7.5B参数量的模型，就需要至少
120 GB
的显存空间才能装下这些<code>Model States</code>。当数据并行时，这些重复的<code>Model States</code>会在N个GPU上复制N份[1]。</p>
<p>有三个级别的ZeRO：</p>
<figure>
<img
src="https://pic3.zhimg.com/v2-8c87dd82df3b817be6342a15091660f6_r.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="zero-1">ZeRO-1</h3>
<p>Optimizer
在进行梯度更新时，会使用<code>参数</code>与<code>Optimizer States</code>计算新的<code>参数</code>。而在正向或反向传播中，<code>Optimizer States</code>并不会参与其中的计算。
（算完反向传播梯度就不用关心每个GPU数据不同问题了，梯度已经统一了）因此，我们完全可以让每个进程只持有<strong>一小段</strong><code>Optimizer States</code>，利用这<strong>一小段</strong><code>Optimizer States</code>更新完与之对应的<strong>一小段</strong><code>参数</code>后，再把各个小段拼起来合为完整的模型参数。<strong>ZeRO-1</strong>
中正是这么做的：</p>
<ol type="1">
<li>forward过程由每个rank的GPU独自完整的完成，然后进行backward过程。在backward过程中，梯度通过allReduce进行同步。</li>
<li>Optimizer state
使用贪心策略基于参数量进行分片，以此确保每个rank几乎拥有相同大小的优化器内存。</li>
<li>每个rank只负责更新当前优化器分片的部分，由于每个rank只有分片的优化器state，所以当前rank忽略其余的state。</li>
<li>在更新过后，通过广播或者allGather的方式确保所有的rank都收到最新更新过后的模型参数。</li>
</ol>
<p>ZeRO-1
非常适合使用类似Adam进行优化的模型训练，因为Adam拥有额外的参数m（momentum）与v（variance），特别是FP16混合精度训练。ZeRO-1
不适合使用SGD类似的优化器进行模型训练，因为SGD只有较少的参数内存，并且由于需要更新模型参数，导致额外的通讯成本。ZeRO-1只是解决了Optimizer
state的冗余。</p>
<h3 id="zero-2">ZeRO-2</h3>
<p>ZeRO-1将<code>Optimizer States</code>分<strong>小段</strong>储存在了多个进程中，所以在计算时，这<strong>一小段</strong>的<code>Optimizer States</code>也只需要得到进程所需的对应<strong>一小段</strong><code>Gradient</code>就可以。遵循这种原理，和<code>Optimizer States</code>一样，ZeRO-2也将<code>Gradient</code>进行了<strong>切片</strong>：</p>
<p>在一个Layer的<code>Gradient</code>都被计算出来后： -
<code>Gradient</code>通过<code>AllReduce</code>进行聚合。 （类似于DDP）
-
聚合后的梯度只会被某一个进程用来更新参数，因此其它进程上的这段<code>Gradient</code>不再被需要，可以立马释放掉。（按需保留）</p>
<p>这样就在<strong>ZeRO-1</strong>的基础上实现了对<code>Gradient</code>的切分。</p>
<h3 id="zero-3">ZeRO-3</h3>
<p>ZeRO-3
通过对<code>Optimizer States</code>，<code>Gradient</code>和<code>Model Parameter</code>三方面的分割，从而使<strong>所有进程共同协作，只储存一份完整
Model
States</strong>。其核心思路就是<strong>精细化通讯</strong>，按照计算需求做到参数的收集和释放。</p>
<h4 id="宏观做法">宏观做法</h4>
<ul>
<li><p>初始化：一个模型由多个<code>Submodule</code>组成。在初始化时，ZeRO-3
会将<strong>每个</strong><code>Submodule Parameter Tensor</code>下的数据按照
GPU
的数量，<strong>分摊切割</strong>成多个小<code>ds_tensor</code>储存在在不同
GPU
进程中。因为<code>ds_tensor</code>可以共同组合出完整数据，所以原始<code>param</code>下的数据变为冗余信息，会被释放掉。</p></li>
<li><p>训练中：在训练过程中，ZeRO-3
会按照<code>Submodule</code>的计算需求进行参数的收集和释放：
在当前<code>Submodule</code>正向/反向传播<strong>计算前</strong>，ZeRO-3
通过<code>All-gather</code>拿到分摊储存在不同进程中的<code>ds_tensor</code>，重建原始的<code>param</code>。重建之后的参数就可以参与计算。</p></li>
<li><p>计算后：在当前<code>Submodule</code>正向/反向传播计算后，<code>param</code>下的数据并没有发生变更，与
ds_tensor
相同，造成了冗余。因此，<code>param</code>会再次被释放。</p></li>
</ul>
<p>经过 ZeRO-3, 一套完整的 model states 就被分布式储存在了多个 GPU
进程中。通过按照计算需求的数据收集和释放，实现储存空间有限的情况下超大规模模型的训练。</p>
<h4 id="代码详解">代码详解</h4>
<p>TBC <a href="https://zhuanlan.zhihu.com/p/394064174">Optimizer state
sharding (ZeRO) - 知乎 (zhihu.com)</a></p>
<h2 id="hdfs">HDFS</h2>
<h3 id="计算流程">计算流程</h3>
<p>Pytorch
的FSDP是一种数据并行的训练方法，<strong>它实际上就是ZeRO-3</strong>.</p>
<figure>
<img src="https://pytorch.org/tutorials/_images/fsdp_workflow.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>这里，All-Reduce操作被分为All-gather和Reduce-Scatter操作</p>
<figure>
<img src="https://pytorch.org/tutorials/_images/fsdp_sharding.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="代码实现">代码实现</h3>
<h1 id="模型并行">模型并行</h1>
<h1 id="流水线并行">流水线并行</h1>
]]></content>
      <categories>
        <category>ML</category>
        <category>BDC</category>
      </categories>
  </entry>
  <entry>
    <title>GeneralReading</title>
    <url>/2023/03/29/GeneralReading/</url>
    <content><![CDATA[<p>MKR,RKGE,HAGERec,entity2rec,HAKG</p>
<span id="more"></span>
<h1 id="mkr">MKR</h1>
<h2 id="framework">Framework</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230329182212440.png"
alt="image-20230329182212440" />
<figcaption aria-hidden="true">image-20230329182212440</figcaption>
</figure>
<p>The framework of MKR is illustrated in Figure 1a.</p>
<p>MKR consists of three main components: recommendation module, KGE
module, and cross&amp;compress units.</p>
<ol type="1">
<li><p>The recommendation module on the left takes a user and an item as
input, and uses a multi-layer perceptron (MLP) and cross&amp;compress
units to extract short and dense features for the user and the item,
respectively. The extracted features are then fed into another MLP
together to output the predicted probability.</p></li>
<li><p>Similar to the left part, the KGE module in the right part also
uses multiple layers to extract features from the head and relation of a
knowledge triple, and outputs the representation of the predicted tail
under the supervision of a score function f and the real tail.</p></li>
<li><p>The recommendation module and the KGE module are bridged by
specially designed cross&amp;compress units. The proposed unit can
automatically learn high-order feature interactions of items in
recommender systems and entities in the knowledge graph.</p></li>
</ol>
<p>u: MLP to update</p>
<p>v: cross&amp;compress units</p>
<p>r: MLP to update</p>
<p>h: cross&amp;compress units</p>
<h2 id="loss-function">Loss function</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230329184018259.png"
alt="image-20230329184018259" />
<figcaption aria-hidden="true">image-20230329184018259</figcaption>
</figure>
<h1 id="rkge">RKGE</h1>
<p>RKGE first automatically mines all qualified paths between entity
pairs from the KG, which are then encoded via a batch of recurrent
networks, with each path modeled by a single recurrent network.</p>
<p>It then employs a pooling operation to discriminate the importance of
different paths for characterizing user preferences towards items.</p>
<h2 id="framework-1">framework</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230329205324109.png"
alt="image-20230329205324109" />
<figcaption aria-hidden="true">image-20230329205324109</figcaption>
</figure>
<h3 id="semantic-path-mining">Semantic Path Mining</h3>
<p>Strategy</p>
<ol type="1">
<li>We only consider user-to-item paths <span
class="math inline">\(P(u_i,v_j)\)</span> that connect <span
class="math inline">\(u, i\)</span> with all her rated items.</li>
<li>We enumerate paths with a length constraint.</li>
</ol>
<h3 id="encode-path">Encode path</h3>
<p>use recurrent networks</p>
<h4 id="embedding-layer">Embedding layer</h4>
<p>generate the embedding of entities</p>
<h4 id="attention-gated-hidden-layer">Attention-Gated Hidden Layer</h4>
<p>就是一个RNN网络的变种</p>
<h1 id="hagerec">HAGERec</h1>
<h2 id="framework-2">Framework</h2>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230330191130895.png"
alt="image-20230330191130895" />
<figcaption aria-hidden="true">image-20230330191130895</figcaption>
</figure>
<p>four components:</p>
<ol type="1">
<li><p>Flatten and embedding layer: flatten complex high-order relations
and embedding the entities and relations as vectors.</p></li>
<li><p>GCN learning layer: uses GCN model to propagate and update user’s
and item’s embedding via a bi-directional entity propagation
strategy</p></li>
<li><p>Interaction signals unit: preserves interaction signals structure
of an entity and its neighbor network to give a more complete picture
for user’s and item’s representation.</p></li>
<li><p>Prediction layer: utilizes the user’s and item’s aggregated
representation with prediction-level attention to output the predicted
score.</p></li>
</ol>
<h3 id="flatten-and-embedding">Flatten and embedding</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330193624700.png"
alt="image-20230330193624700" />
<figcaption aria-hidden="true">image-20230330193624700</figcaption>
</figure>
<p>flatten high-order connection to the path: <span
class="math inline">\(u\rightarrow^{r1}v\rightarrow^{r2}e_{u1}\rightarrow^{r3}e_{v3}\)</span></p>
<p>embedding: initialized embedding vectors.</p>
<h3 id="gcn-learning-unit">GCN learning unit</h3>
<p>user and item use the same propagation and aggregate strategy.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330200154040.png"
alt="image-20230330200154040" />
<figcaption aria-hidden="true">image-20230330200154040</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330200204043.png"
alt="image-20230330200204043" />
<figcaption aria-hidden="true">image-20230330200204043</figcaption>
</figure>
<p><span class="math inline">\(h^T, W, b\)</span>: learned
parameters</p>
<p>neighbor sample(only get fixed number neighbor): <span
class="math inline">\(\alpha_{e_v,e_{nv}}\)</span> would be regarded as
the similarity of each neighbor entity and central entity. Through this
evidence, those neighbors with lower similarity would be filtered.</p>
<h3 id="interaction-signals-unit">Interaction signals unit</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330201306937.png"
alt="image-20230330201306937" />
<figcaption aria-hidden="true">image-20230330201306937</figcaption>
</figure>
<p>区别：上面是相加，下面事相乘</p>
<p>so GCN unit + interaction unit =</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330201407720.png"
alt="image-20230330201407720" />
<figcaption aria-hidden="true">image-20230330201407720</figcaption>
</figure>
<h3 id="predict">Predict</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230330201630216.png"
alt="image-20230330201630216" />
<figcaption aria-hidden="true">image-20230330201630216</figcaption>
</figure>
<h1 id="entity2rec">Entity2rec</h1>
<h2 id="framework-3">Framework</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331170104462.png"
alt="image-20230331170104462" />
<figcaption aria-hidden="true">image-20230331170104462</figcaption>
</figure>
<h3 id="node2vec">node2vec</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331165454743.png"
alt="image-20230331165454743" />
<figcaption aria-hidden="true">image-20230331165454743</figcaption>
</figure>
<p>将图用random walk转化为word格式，用词袋模型计算vector。</p>
<h3 id="property-specific-knowledge-graph-embedding">Property-specific
knowledge graph embedding</h3>
<p>在node2vec基础上加上relation embedding，基于p子图在p空间上优化node
vector</p>
<p>maximize the dot product between vectors of the same neighborhood</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331170246301.png"
alt="image-20230331170246301" />
<figcaption aria-hidden="true">image-20230331170246301</figcaption>
</figure>
<p>Ze-negative sampling</p>
<p>N(e): neighbor of entity</p>
<h3 id="subgraph">subgraph</h3>
<h4 id="collaborative-content-subgraphs">Collaborative-content
subgraphs</h4>
<p>只保留单一relation，但连接性很差，对random walk效果不好</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331170405382.png"
alt="image-20230331170405382" />
<figcaption aria-hidden="true">image-20230331170405382</figcaption>
</figure>
<p>所有子图可以分成两张类型：feedback子图(user-item图)和其他子图</p>
<p>用下面方法来计算推荐分数：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331170819790.png"
alt="image-20230331170819790" />
<figcaption aria-hidden="true">image-20230331170819790</figcaption>
</figure>
<p>R+(u) denotes a set of items liked by the user u in the past.</p>
<p>s(x): similarity socre</p>
<h4 id="hybrid-subgraphs">Hybrid subgraphs</h4>
<p><span class="math inline">\(K_p^+=K_p \cup(u,feedback,i)\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331171032188.png"
alt="image-20230331171032188" />
<figcaption aria-hidden="true">image-20230331171032188</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230331171139039.png"
alt="image-20230331171139039" />
<figcaption aria-hidden="true">image-20230331171139039</figcaption>
</figure>
<h1 id="hakg">HAKG</h1>
<p>总结：抽取u，i子图，进行正常的propagation之后，得到自图中所有entity的embedding，包括user和item。用self-attention提取entity相互影响信息，得到矩阵g（u，i），再用use
embedding，item
embedding和g（u，i）进行预测，充分利用了子图中的所有信息。</p>
<h2 id="framework-4">Framework</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230401160018626.png"
alt="image-20230401160018626" />
<figcaption aria-hidden="true">image-20230401160018626</figcaption>
</figure>
<ol type="1">
<li>Subgraph Construction ：it automatically constructs the expressive
subgraph that links the user-item pair to represent their
connectivity;</li>
<li>Hierarchical Attentive Subgraph Encoding ： the subgraph is further
encoded via a hierarchical attentive embedding learning procedure, which
first learns embeddings for entities in the subgraph with a layer-wise
propagation mechanism, and then attentively aggregates the entity
embeddings to derive the holistic subgraph embedding;</li>
<li>Preference Prediction ： with the well-learned embeddings of the
user-item pair and their subgraph connectivity, it uses non-linear
layers to predict the user’s preference towards the item.</li>
</ol>
<h3 id="subgraph-construction">Subgraph Construction</h3>
<p>path sampling and then reconstructs the subgraphs by assembling the
sampled paths between user-item pairs</p>
<h4 id="path-sampling">path sampling</h4>
<p>use random walk get path from u to i and length&lt;=6, uniformly
sample K paths</p>
<h4 id="path-assembling">Path Assembling</h4>
<p>just assemb the K paths</p>
<h3 id="hierarchical-attentive-subgraph-encoding">Hierarchical attentive
subgraph encoding</h3>
<h4 id="entity-embedding-learning">entity embedding learning</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230401173559684.png"
alt="image-20230401173559684" />
<figcaption aria-hidden="true">image-20230401173559684</figcaption>
</figure>
<h5 id="embedding-initialization">Embedding Initialization</h5>
<ol type="1">
<li>initial</li>
<li><span class="math inline">\(e_h^{(0)}=MLP(e_h \space concatenation
\space t_h)\)</span></li>
</ol>
<h5 id="semantics-propagation">Semantics Propagation</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230401173656033.png"
alt="image-20230401173656033" />
<figcaption aria-hidden="true">image-20230401173656033</figcaption>
</figure>
<h5 id="semantics-aggregation">Semantics Aggregation</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230401173801411.png"
alt="image-20230401173801411" />
<figcaption aria-hidden="true">image-20230401173801411</figcaption>
</figure>
<p>final entity embedding is <span
class="math inline">\(e_h^{(L)}\)</span></p>
<p>constitute an entity embedding matrix H(u,i) for the whole subgraph
:</p>
<p><span
class="math inline">\(H_{(u,i)}=[e_1,e_2,\cdots,e_n]\)</span></p>
<h4 id="sub-graph-embedding-learning">sub-graph embedding learning</h4>
<p>use self-attention mechanism optimize the entities embeding of
subgraph</p>
<p>Than use pooling method to get subgraph embedding</p>
<h3 id="prediction">Prediction</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230401175552413.png"
alt="image-20230401175552413" />
<figcaption aria-hidden="true">image-20230401175552413</figcaption>
</figure>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>HyperGraph</title>
    <url>/2023/05/26/HyperGraph/</url>
    <content><![CDATA[<p>Hypergraph</p>
<span id="more"></span>
<h1 id="hgnn">HGNN</h1>
<p>use the matrix to represent hypergraph</p>
<p>a hyperedge convolution operation is designed</p>
<p>can incorporate with multi-modal data and complicated data
correlations(use below figure2 method to combine different data type
)</p>
<h2 id="hypergraph-and-adjacency-matrix">Hypergraph and adjacency
matrix</h2>
<p>hypergraph-一条边可以同时连接多个点</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230605145232861.png"
alt="image-20230605145232861" />
<figcaption aria-hidden="true">image-20230605145232861</figcaption>
</figure>
<p>adjacency matrix:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230605145324681.png"
alt="image-20230605145324681" />
<figcaption aria-hidden="true">image-20230605145324681</figcaption>
</figure>
<h2 id="method">Method</h2>
<h3 id="hypergraph-learning-statement">hypergraph learning
statement</h3>
<p>hypergraph defined as <span class="math inline">\(G = (V,\varepsilon,
W)\)</span></p>
<p>the degree of vertex <span class="math inline">\(v\)</span> defined
as <span class="math inline">\(d(v)=\sum_{e\in
\varepsilon}h(v,e)\)</span>——一个点与多少条边相连</p>
<p>the degree of hyperedge defined as <span class="math inline">\(\delta
(v)=\sum_{v\in V}h(v,e)\)</span>——一条边与多少个点相连</p>
<p><span class="math inline">\(D_e\)</span> and <span
class="math inline">\(D_v\)</span> denote the diagonal matrices of the
edge degrees and the vertex degrees, respectively</p>
<p>example:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230605153837827.png"
alt="image-20230605153837827" />
<figcaption aria-hidden="true">image-20230605153837827</figcaption>
</figure>
<h3 id="spectral-convolution-on-hypergraph">Spectral convolution on
hypergraph</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230605155756968.png"
alt="image-20230605155756968" />
<figcaption aria-hidden="true">image-20230605155756968</figcaption>
</figure>
<p>频域理解不深，要完全看懂要好久，先简单略一下。</p>
<h1 id="hypergcn">HyperGCN</h1>
<p>Hypergraph, a novel way of training a GCN for SSL on hypergraphs
based on tools from sepctral theory of hypergraphs</p>
<p>主要是把hypergraph转为简单拉普拉斯图</p>
<h2 id="method-1">Method</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230606094309361.png"
alt="image-20230606094309361" />
<figcaption aria-hidden="true">image-20230606094309361</figcaption>
</figure>
<h3 id="hypergraph-generation">hypergraph generation</h3>
<ol type="1">
<li>对图上任意边<span class="math inline">\(e\in E\)</span>, 令<span
class="math inline">\((i_e,j_e):=argmax_{i,j\in e}|S_i-S_j|\)</span>
,即返回同一个边上距离最远的两个顶点表示<span
class="math inline">\((i_e,j_e)\)</span>为随机,切断点的联系。</li>
<li>为剩下的边添加权重，权重为hyperedge的权重，构造简单的邻接矩阵。</li>
<li>归一化计算拉普拉斯矩阵</li>
</ol>
<h3 id="gnn">GNN</h3>
<p>利用带权重的拉普拉斯矩阵计算GCN</p>
<h1 id="hypergraph-convolution-and-hypergraph-attention">Hypergraph
Convolution and Hypergraph Attention</h1>
]]></content>
      <categories>
        <category>GNN</category>
        <category>hypergraph</category>
      </categories>
  </entry>
  <entry>
    <title>Initialization</title>
    <url>/2023/06/12/Initialization/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/653754525">Xavier
初始化【简单易懂】 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>KGAT</title>
    <url>/2023/02/24/KGAT/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>利用KG作为辅助信息，并将KG与user-item graph 整合为一个图</p>
<h2 id="background-1">Background</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224155340260.png"
alt="image-20230224155340260" />
<figcaption aria-hidden="true">image-20230224155340260</figcaption>
</figure>
<p><strong>Previous model:</strong></p>
<p>CF: behaviorally similar users would exhibit similar preference on
items.</p>
<p><strong>focus on the histories of similar users who also watched
<span class="math inline">\(i1\)</span>, i.e., <span
class="math inline">\(u4\)</span> and <span
class="math inline">\(u5\)</span>;</strong></p>
<p>SL: transform side information into a generic feature vector,
together with user ID and item ID, and feed them into a supervised
learning (SL) model to predict the score.</p>
<p><strong>emphasize the similar items with the attribute <span
class="math inline">\(e1\)</span>, i.e.$ i2$.</strong></p>
<p><strong>current problem:</strong></p>
<p>existing SL methods fail to unify them, and ignore other
relationships in the graph:</p>
<ol type="1">
<li>the users in the yellow circle who watched other movies directed by
the same person <span class="math inline">\(e_1\)</span>.</li>
<li>the items in the grey circle that share other common relations with
<span class="math inline">\(e_1\)</span>.</li>
</ol>
<h2 id="user-item-bipartite-graph-g_1">User-Item Bipartite Graph: <span
class="math inline">\(G_1\)</span></h2>
<p><span class="math display">\[
\{(u,y_{ui},i)|u\in U, i\in I\}
\]</span> <span class="math inline">\(U\)</span>: user sets</p>
<p><span class="math inline">\(I\)</span>: item sets</p>
<p><span class="math inline">\(y_{ui}\)</span>: if user <span
class="math inline">\(u\)</span> interacts with item <span
class="math inline">\(i\)</span> <span
class="math inline">\(y_{ui}\)</span>=, else <span
class="math inline">\(y_{ui}\)</span>=0.</p>
<h2 id="knowledge-graph-g2">Knowledge Graph <span
class="math inline">\(G2\)</span></h2>
<p><span class="math display">\[
\{(h,r,t)|h,t\in E, r\in R\}
\]</span></p>
<p><span class="math inline">\(t\)</span> there is a relationship <span
class="math inline">\(r\)</span> from head entity <em>h</em> to tail
entity <span class="math inline">\(t\)</span>.</p>
<h2 id="ckg-combination-of-g1-and-g2"><span
class="math inline">\(CKG\)</span>: Combination of <span
class="math inline">\(G1\)</span> and <span
class="math inline">\(G2\)</span></h2>
<ol type="1">
<li>represent each user-item behavior as a triplet $ (u,
Interact,i)<span class="math inline">\(, where\)</span> y^{ui}$ =
1.</li>
<li>we establish a set of item-entity alignments</li>
</ol>
<p><span class="math display">\[
A = \{(i, e)|i ∈ I, e ∈ E \}
\]</span></p>
<ol start="3" type="1">
<li>based on the item-entity alignment set, the user-item graph can be
integrated with KG as a unified graph.</li>
</ol>
<p><span class="math display">\[
G = \{(h,r,t)|h,t ∈ E^′,r ∈R^′\}
\]</span></p>
<p><span class="math display">\[
E^′ = E ∪ U
\]</span></p>
<p><span class="math display">\[
R^′ = R ∪ {Interact}
\]</span></p>
<h1 id="methodology">Methodology</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222185609261.png"
alt="image-20230222185609261" />
<figcaption aria-hidden="true">image-20230222185609261</figcaption>
</figure>
<p>KGAT has three main components:</p>
<ol type="1">
<li>Embedding layer</li>
<li>Attentive embedding propagation layer</li>
<li>prediction layer</li>
</ol>
<h2 id="embedding-layer">Embedding layer</h2>
<p>Using <strong>TransR</strong> to calculate embedding</p>
<p><strong>Assumption</strong>: if a triplet (h,r,t) exist in the graph,
<span class="math display">\[
e^r_h+e_r\approx e_t^r
\]</span> Herein, <span class="math inline">\(e^h\)</span>, <span
class="math inline">\(e^t\)</span> ∈ <span
class="math inline">\(R^d\)</span> and <span
class="math inline">\(e^r\)</span> ∈ <span
class="math inline">\(R^k\)</span>are the embedding for <em>h</em>,
<em>t</em>, and <em>r</em>; and <span
class="math inline">\(e^r_h\)</span>, <span
class="math inline">\(e^r_t\)</span> are the projected representations
of <span class="math inline">\(e^h\)</span>, <span
class="math inline">\(e^t\)</span> in the relation <em>r</em>’s
space.</p>
<p><strong>Plausibility score</strong>:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222193700417.png"
alt="image-20230222193700417" />
<figcaption aria-hidden="true">image-20230222193700417</figcaption>
</figure>
<p><span class="math inline">\(W_r ∈ R^{k\times d}\)</span> is the
transformation matrix of relation <em>r</em>, which projects entities
from the <em>d</em>-dimension entity space into the <em>k</em> dimension
relation space.</p>
<p>A lower score suggests that the triplet is more likely to be
true.</p>
<p><strong>Loss</strong>:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222195306105.png"
alt="image-20230222195306105" />
<figcaption aria-hidden="true">image-20230222195306105</figcaption>
</figure>
<p><span class="math inline">\(\{(h,r,t,t^′ )|(h,r,t) \in G, (h,r,t^′ )
\notin G\}\)</span>, <span class="math inline">\((h,r,t^′ )\)</span> is
a negative sample constructed by replacing one entity in a valid triplet
randomly.</p>
<p><em>σ</em>(·): sigmoid function, ——》将分数映射再0-1区间，归一化</p>
<p>？？？？？？？？？？？why this layer model working as a
regularizer</p>
<h2 id="attentive-embedding-propagation-layersupon-gcn">Attentive
Embedding Propagation Layers(upon GCN)</h2>
<h3 id="first-order-propagation">First-order propagation</h3>
<p>和之前模型不同，这个的propagation layer encode了<span
class="math inline">\(e_r\)</span>.</p>
<p>For entity h, the information propagating from neighbor is :</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222201217039.png"
alt="image-20230222201217039" />
<figcaption aria-hidden="true">image-20230222201217039</figcaption>
</figure>
<p><span class="math inline">\(π(h,r,t)\)</span>: to controls the decay
factor on each propagation on edge (<em>h</em>,<em>r</em>,<em>t</em>),
indicating how much information is propagated</p>
<p>from <em>t</em> to <em>h</em> conditioned to relation <em>r</em>.</p>
<p>For <span class="math inline">\(π(h,r,t)\)</span>, we use attention
mechanism:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222204949423.png"
alt="image-20230222204949423" />
<figcaption aria-hidden="true">image-20230222204949423</figcaption>
</figure>
<p>This makes the attention score dependent on the distance between
<span class="math inline">\(e^h\)</span> and <span
class="math inline">\(e^t\)</span> in the relation <em>r</em>’s
space.</p>
<p>这里，tanh用于增加非线性因素；但不缺定是否有归一化作用？？？？？归一化就可以把这个function的大小集中在角度上，但是这样<span
class="math inline">\(e^h_t\)</span>也没有归一化，到时候看看输出参数</p>
<p>and than use softmax to normalize(no need to use as<span
class="math inline">\(\frac1{|N_t |}\)</span><span
class="math inline">\(\frac1{|N_t ||N_h |}\)</span>)</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222234256082.png"
alt="image-20230222234256082" />
<figcaption aria-hidden="true">image-20230222234256082</figcaption>
</figure>
<p>The final part is aggregation, threre are three choices:</p>
<ol type="1">
<li>GCN aggregator</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222235616598.png"
alt="image-20230222235616598" />
<figcaption aria-hidden="true">image-20230222235616598</figcaption>
</figure>
<ol start="2" type="1">
<li>GraphSage aggregator</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222235806956.png"
alt="image-20230222235806956" />
<figcaption aria-hidden="true">image-20230222235806956</figcaption>
</figure>
<ol start="3" type="1">
<li>Bi-Interaction aggregator</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223000647293.png"
alt="image-20230223000647293" />
<figcaption aria-hidden="true">image-20230223000647293</figcaption>
</figure>
<h3 id="multi-layer-propagation">Multi-layer propagation</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223000834658.png"
alt="image-20230223000834658" />
<figcaption aria-hidden="true">image-20230223000834658</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223000850960.png"
alt="image-20230223000850960" />
<figcaption aria-hidden="true">image-20230223000850960</figcaption>
</figure>
<h2 id="model-prediction">Model Prediction</h2>
<p>multi-layers combination and inner product</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223001515690.png"
alt="image-20230223001515690" />
<figcaption aria-hidden="true">image-20230223001515690</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223001526127.png"
alt="image-20230223001526127" />
<figcaption aria-hidden="true">image-20230223001526127</figcaption>
</figure>
<h2 id="optimizazion">Optimizazion</h2>
<h3 id="loss">loss</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223002144083.png"
alt="image-20230223002144083" />
<figcaption aria-hidden="true">image-20230223002144083</figcaption>
</figure>
<p><span class="math inline">\(L_{cf}\)</span> is BPR Loss</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223002439536.png"
alt="image-20230223002439536" />
<figcaption aria-hidden="true">image-20230223002439536</figcaption>
</figure>
<p><span class="math inline">\(L_{kg}\)</span> is loss forTranR .</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230222195306105.png"
alt="image-20230222195306105" />
<figcaption aria-hidden="true">image-20230222195306105</figcaption>
</figure>
<h3 id="optimizer">Optimizer</h3>
<p>Adam</p>
<h3 id="updata-method">updata method</h3>
<p>we update the embeddings for all nodes;</p>
<p>hereafter, we sample a batch of (<em>u</em>,<em>i</em>, <em>j</em>)
randomly, retrieve their representations after <em>L</em> steps of
propagation, and then update model parameters by using the gradients of
the prediction loss.</p>
<p>在同一个epoch中，先把所以数据扔进tranR训练，得到loss（此时不更新参数）</p>
<p>然后sample算BPR LOSS</p>
<h1 id="experiments">EXPERIMENTS</h1>
<h2 id="rq1-performance-comparison">RQ1: Performance Comparison</h2>
<ol type="1">
<li>regular dataset</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223004843914.png"
alt="image-20230223004843914" />
<figcaption aria-hidden="true">image-20230223004843914</figcaption>
</figure>
<ol start="2" type="1">
<li><p>Sparsity Levels</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223005253034.png"
alt="image-20230223005253034" />
<figcaption aria-hidden="true">image-20230223005253034</figcaption>
</figure></li>
</ol>
<p>KGAT outperforms the other models in most cases, especially on the
two sparsest user groups.</p>
<p>说明KGAT能够缓解稀疏性影响</p>
<h2 id="rq2study-of-kgat">RQ2：Study of KGAT</h2>
<ol type="1">
<li>study of layer influence and effect of aggregators</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223010038345.png"
alt="image-20230223010038345" />
<figcaption aria-hidden="true">image-20230223010038345</figcaption>
</figure>
<ol start="2" type="1">
<li><p>cut attention layer and TransR layer</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230223010347815.png"
alt="image-20230223010347815" />
<figcaption aria-hidden="true">image-20230223010347815</figcaption>
</figure></li>
</ol>
<h1 id="source-code">Source code</h1>
<h2 id="dataprocess">DataProcess</h2>
<h3 id="load-data">Load data</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data:[[u1,interacted_item1],[u1,interacted_item2],[u2,interacted_item1]]</span><br><span class="line"></span><br><span class="line">train_user_dict:&#123;</span><br><span class="line">    user_id1:[interacted_item1,interacted_item2,...],</span><br><span class="line">    user_id2:[...]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">kg_data:[[head_e,relation,tail_e],[head_e,relation,tail_e]]</span><br><span class="line"></span><br><span class="line">kg_dict:&#123;</span><br><span class="line">    head:[(tail,relation), (tail,relation),...]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">relation_dict:&#123;</span><br><span class="line">    relation:[(head,tail),(head,tail),...]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3
id="generate-the-adjacency-matrices-and-matrices-after-laplacian">generate
the adjacency matrices and matrices after Laplacian</h3>
<ol type="1">
<li><p>regard interacted as relation 0, now the number of relations is
<span class="math inline">\(self.n\_relations+1\)</span></p></li>
<li><p>every relation <span class="math inline">\((idx)\)</span> convert
to 2 adjacency matrix (by inversing cols and rows), which representate
as 2 new relations <span class="math inline">\((idx,
self.n\_relations+idx)\)</span>：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/643ED74EDA6A241DF772EA9C9435EFBD.png"
alt="643ED74EDA6A241DF772EA9C9435EFBD" />
<figcaption
aria-hidden="true">643ED74EDA6A241DF772EA9C9435EFBD</figcaption>
</figure></li>
</ol>
<p>As a result: we get adj_list, adj_r_list</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">adj_list: [adjancy matrix1, adjancy matrix2,adjancy matrix3,...]</span><br><span class="line">adj_r_list: The relation adjancy matrix Correspondento to</span><br><span class="line">			e.g.[0,self.n_relations+0,1,self.n_relations+1,2,self.n_relations+2,...]</span><br></pre></td></tr></table></figure>
<p>Than, genarate adjancy matrix after laplacian normalization and save
in self.lap_list.</p>
<h3 id="update-kg-dict">Update kg dict</h3>
<p>according to the change of relation, update kg dict</p>
<h3 id="generate-batch-data">Generate batch data</h3>
<h2 id="build_model">build_model</h2>
<h3 id="placeholder-definition">Placeholder definition</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_inputs</span>(<span class="params">self</span>):</span><br><span class="line">    tf.compat.v1.disable_eager_execution()</span><br><span class="line">    <span class="comment"># placeholder definition</span></span><br><span class="line">    self.users = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>,))</span><br><span class="line">    self.pos_items = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>,))</span><br><span class="line">    self.neg_items = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>,))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># for knowledge graph modeling (TransD)</span></span><br><span class="line">    self.A_values = tf.placeholder(tf.float32, shape=[<span class="built_in">len</span>(self.all_v_list)],</span><br><span class="line">                                   name=<span class="string">&#x27;A_values&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.h = tf.placeholder(tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">    self.r = tf.placeholder(tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    self.pos_t = tf.placeholder(tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">&#x27;pos_t&#x27;</span>)</span><br><span class="line">    self.neg_t = tf.placeholder(tf.int32, shape=[<span class="literal">None</span>], name=<span class="string">&#x27;neg_t&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="trainable-weight-definition">trainable weight definition</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_weights</span>(<span class="params">self</span>):</span><br><span class="line">    all_weights = <span class="built_in">dict</span>()</span><br><span class="line">    initializer = tf.keras.initializers.glorot_normal()</span><br><span class="line"></span><br><span class="line">    all_weights[<span class="string">&#x27;user_embed&#x27;</span>] = tf.Variable(initializer([self.n_users, self.emb_dim]),</span><br><span class="line">                                            name=<span class="string">&#x27;user_embed&#x27;</span>)</span><br><span class="line">    all_weights[<span class="string">&#x27;entity_embed&#x27;</span>] = tf.Variable(initializer([self.n_entities,</span><br><span class="line">                                                           self.emb_dim]),</span><br><span class="line">                                                           name=<span class="string">&#x27;entity_embed&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    all_weights[<span class="string">&#x27;relation_embed&#x27;</span>] = tf.Variable(initializer([self.n_relations,</span><br><span class="line">                                             self.kge_dim]),name=<span class="string">&#x27;relation_embed&#x27;</span>)</span><br><span class="line">    <span class="comment"># E_h, E_t to E_r space</span></span><br><span class="line">    all_weights[<span class="string">&#x27;trans_W&#x27;</span>] = tf.Variable(initializer([self.n_relations, </span><br><span class="line">                                                      self.emb_dim, self.kge_dim]))</span><br><span class="line">    self.weight_size_list = [self.emb_dim] + self.weight_size</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>KGCN</title>
    <url>/2023/03/02/KGCN/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<h2 id="cf-questions">CF Questions</h2>
<ol type="1">
<li>sparsity</li>
<li>cold start</li>
</ol>
<h2 id="kg-benefits">KG Benefits</h2>
<ol type="1">
<li>The rich semantic relatedness among items in a KG can help explore
their latent connections and improve the <em>precision</em> of
results;</li>
<li>The various types of relations in a KG are helpful for extending a
user’s interests reasonably and increasing the <em>diversity</em> of
recommended items;</li>
<li>KG connects a user’s historically-liked and recommended items,
thereby bringing <em>explainability</em> to recommender systems.</li>
</ol>
<h2 id="previous-kg-method">Previous KG Method</h2>
<h3 id="knowledge-graph-embedding">Knowledge graph embedding</h3>
<p>Example: TransE [1] and TransR [12] assume <em>head</em> +
<em>relation</em> = <em>tail</em>, which focus on modeling rigorous
semantic relatedness</p>
<p>Problem: KGE methods are more suitable for in-graph applications such
as KG completion and link prediction rather than the recommendation
system.</p>
<h3 id="path-base-method">Path-base Method</h3>
<p>Example: PER, FMG</p>
<p>problem: Labor sensitivity</p>
<h2 id="ripple-net">Ripple Net</h2>
<p>problem:</p>
<ol type="1">
<li>the importance of relations is weakly characterized in RippleNet,
because the relation <strong>R</strong> can hardly be trained to capture
the sense of importance in the quadratic form <strong>v</strong>
⊤<strong>Rh</strong> (<strong>v</strong> and <strong>h</strong> are
embedding vectors of two entities).</li>
<li>The size of ripple set may go unpredictably with the increase of the
size of KG, which incurs heavy computation and storage overhead.</li>
</ol>
<h2 id="solution-kgcn">Solution: KGCN</h2>
<ol type="1">
<li>Propagation and aggregation mechanism.</li>
<li>Attention mechanism.</li>
<li>sample a fixed-size neighborhood to control compute cost.</li>
</ol>
<h1 id="model">Model</h1>
<h2 id="single-layer">Single layer</h2>
<p>Consider a pair(u,v)</p>
<h3 id="overall-of-single-layer">Overall of single layer</h3>
<p>!!!Propagation only use for updating of item's vector</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302114017500.png"
alt="image-20230302114017500" />
<figcaption aria-hidden="true">image-20230302114017500</figcaption>
</figure>
<h3 id="propagation">Propagation</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302111400335.png"
alt="image-20230302111400335" />
<figcaption aria-hidden="true">image-20230302111400335</figcaption>
</figure>
<p><span class="math inline">\(N(v)\)</span> is the neighbor set of
v</p>
<p>e$ is the embedding of entity(parameter to train)</p>
<p><span class="math inline">\(\pi^u_{r_{v,e}}\)</span> is attention
weight</p>
<p><span class="math inline">\(r_{v,e}\)</span> represent the relation
of v and e</p>
<h3 id="attention">Attention</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302112401231.png"
alt="image-20230302112401231" />
<figcaption aria-hidden="true">image-20230302112401231</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302112315690.png"
alt="image-20230302112315690" />
<figcaption aria-hidden="true">image-20230302112315690</figcaption>
</figure>
<p><span class="math inline">\(g : R^d ×R^d → R\)</span> (e.g., inner
product:内积能计算相似度)to compute the score between a user and a
relation</p>
<p><span class="math inline">\(u\in R\)</span>, <span
class="math inline">\(r\in R\)</span> : embedding of user and
relation(parameter to train)</p>
<p><span class="math inline">\(\pi^u_{r_{v,e}}\)</span>characterizes the
importance of relation <em>r</em> to user <em>u</em>. E.g. example, a
user may have more interests in the movies that share the same “star"
with his historically liked ones, while another user may be more
concerned about the “genre" of movies.</p>
<p>!!!!!!!!!!个性化！！！用户对不同关系重视程度不同！！</p>
<p>所以KGCN不用propagation更新用户的原因是否是因为希望user的embedding能专注于提取个性化信息（提高用户和重要relation的相似度），但是这样是否会让user和item没那么好聚类？</p>
<h3 id="sample-the-number-of-neighbors">Sample the number of
neighbors</h3>
<p>limit the neighbor number in K(can be config)</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302113734945.png"
alt="image-20230302113734945" />
<figcaption aria-hidden="true">image-20230302113734945</figcaption>
</figure>
<p>S(<em>v</em>) is also called the (single layer) <em>receptive
field</em> of entity <em>v</em></p>
<p>example K=2:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302113907523.png"
alt="image-20230302113907523" />
<figcaption aria-hidden="true">image-20230302113907523</figcaption>
</figure>
<h3 id="aggregation">aggregation</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302114047762.png"
alt="image-20230302114047762" />
<figcaption aria-hidden="true">image-20230302114047762</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302114057869.png"
alt="image-20230302114057869" />
<figcaption aria-hidden="true">image-20230302114057869</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302114106975.png"
alt="image-20230302114106975" />
<figcaption aria-hidden="true">image-20230302114106975</figcaption>
</figure>
<p><span class="math inline">\(\sigma\)</span> is ReLU</p>
<h2 id="multi-layer">Multi layer</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/9C6A6E4346910DDDD43EBB55E1A2FE6C.png"
alt="9C6A6E4346910DDDD43EBB55E1A2FE6C" />
<figcaption
aria-hidden="true">9C6A6E4346910DDDD43EBB55E1A2FE6C</figcaption>
</figure>
<p>First we consider the Receptive-Field:</p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/1739B546615C1AEDC69F7A3514E2E458.png" alt="1739B546615C1AEDC69F7A3514E2E458" style="zoom:67%;" /></p>
<p>We first update eneities in M[0] by using propagation and aggregation
to get the high-hop neighbor information.</p>
<p>And then gradually narrow it down, and finally focus on v.</p>
<p>Note that we have only one user in one pair, every relations will
calculate the score with this user embedding</p>
<h2 id="predict">Predict</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302114437063.png"
alt="image-20230302114437063" />
<figcaption aria-hidden="true">image-20230302114437063</figcaption>
</figure>
<h2 id="loss-function">Loss function</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302120154981.png"
alt="image-20230302120154981" />
<figcaption aria-hidden="true">image-20230302120154981</figcaption>
</figure>
<p><span class="math inline">\(J\)</span> is cross-entropy loss</p>
<p><em>P</em> is a negative sampling distribution, and <span
class="math inline">\(T_u\)</span> is the number of negative samples for
user <em>u</em>. In this paper,</p>
<h1 id="experiment">Experiment</h1>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>KR-GCN</title>
    <url>/2023/04/26/KR-GCN/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>previous study:</p>
<ol type="1">
<li>error propagation: consider all paths between every user-item pair
might involve irrelevant one</li>
<li>weak explainability</li>
</ol>
<h1 id="model">Model</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230426111943016.png"
alt="image-20230426111943016" />
<figcaption aria-hidden="true">image-20230426111943016</figcaption>
</figure>
<p>4 parts:</p>
<ol type="1">
<li>the Graph encoding module: learn the representations of nodes in the
heterogeneous graph.</li>
<li>the Path Extraction and Selection module: extract paths between
users and items from the heterogeneous graph and select higher-quality
reasoning paths</li>
<li>the Path Encoding module: learn the representations of the selection
reasoning paths.</li>
<li>the Preference Prediction module: predicts users’ preferences
according to the reasoning paths.</li>
</ol>
<h2 id="graph-encoding---gcn">Graph Encoding - GCN</h2>
<ol type="1">
<li>propagation and aggregation</li>
</ol>
<p>initialized randomly</p>
<p>weighted sum aggregator : the neighborhood nodes are aggregated via
mean function.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230426113233853.png"
alt="image-20230426113233853" />
<figcaption aria-hidden="true">image-20230426113233853</figcaption>
</figure>
<ol start="2" type="1">
<li>weight sum to merge every layers</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230426114004010.png"
alt="image-20230426114004010" />
<figcaption aria-hidden="true">image-20230426114004010</figcaption>
</figure>
<h2 id="path-extraction">Path Extraction</h2>
<p>we prune irrelevant paths between each user-item pair.</p>
<p>we extract multi-hop paths with the limitation that hops in every
single path are less than l.</p>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>LINUX</title>
    <url>/2024/04/10/LINUX/</url>
    <content><![CDATA[<span id="more"></span>
<h1 id="一些常用方法">一些常用方法</h1>
<h2 id="添加环境变量">添加环境变量</h2>
<p>使用vim编辑环境变量文件（只修改当前用户的环境变量）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>将下面的命令加入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ export PATH=$PATH:/usr/local/xxxxxx</span><br></pre></td></tr></table></figure>
<p>最后，用source在当前bash环境下读取并执行FileName中的命令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ source ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>Note:</p>
<p>Hadoop环境变量配置cdoe如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/安装目录</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Basic Of Computer</category>
      </categories>
  </entry>
  <entry>
    <title>LLM</title>
    <url>/2024/04/10/LLM/</url>
    <content><![CDATA[<p>LLM</p>
<span id="more"></span>
<h1 id="nlp">NLP</h1>
<h2 id="transformer">Transformer</h2>
<ul>
<li>self-attention表达式</li>
</ul>
<p><span class="math display">\[
Softmax(\frac{QK^T}{\sqrt{d_k}})V
\]</span></p>
<ul>
<li><p><strong>why scaling</strong></p>
<p><span class="math inline">\(QK^t\)</span>相乘会让数值变大，scaling
后进行softmax可以使得输入的数据的分布变得更好，避免数据进入softmax敏感区间，防止梯度消失，让模型能够更容易训练。</p></li>
<li><p><strong>可以不除以<span
class="math inline">\(\sqrt{d_k}\)</span>吗</strong> ？</p>
<p>可以，只要有别的方法可以缓解梯度消失即可</p></li>
<li><p><strong>self-attention一定要这样表达吗</strong></p>
<p>不一定，只要可以建模相关性就可以。这样表示的优点：高速计算（矩阵乘法）；表达能力强（query可以主动去关注到其他的key并在value上进行强化，并且忽略不相关的其他部分），模型容量够（引入了project_q/k/v，att_out，多头）。</p></li>
<li><p><strong>为什么transformer用Layer Norm？有什么用？</strong></p>
<p>任何norm的意义都是为了让使用norm的网络的输入的数据分布变得更好，也就是转换为标准正态分布，避免数值进入敏感度区间，以减缓梯度消失，从而更容易训练。当然，这也意味着舍弃了除此维度之外其他维度的其他信息。layer
norm舍弃了batch维度信息； batch Norm舍弃了layer维度信息。</p></li>
<li><p><strong>为什么不用BN</strong></p>
<p>BN广泛应用于CV，针对同一特征，以跨样本的方式开展归一化，也就是对不同样本的同一channel间的所有像素值进行归一化，因此不会破坏不同样本同一特征之间的关系，毕竟“减均值，除标准差”只是一个平移加缩放的线性操作。在“身高体重”的例子中，这就意味着“归一化前是高个儿的归一化后仍然是高个儿，归一化前胖的归一化后也不会变瘦”。这一性质进而决定了经过归一化操作后，样本之间仍然具有可比较性。但是，同一样本特征与特征之间的不再具有可比较性，也就是上一个问题中我所说的“舍弃了除此维度之外其他维度的其他信息”。</p></li>
</ul>
<p>​
但是在NLP中对不同样本同一特征的信息进行归一化没有意义，而且不能舍弃同一个样本的不同维度的信息。</p>
<ul>
<li><p><strong>Bert为什么要搞一个position embedding？</strong></p>
<p>self-attention无法表达位置信息，用三角函数避免句子过长时位置编码太大。</p></li>
<li><p><strong>Bert为什么三个embedding可以相加？</strong></p>
<p>在实际场景中，叠加是一个更为常态的操作。比如声音、图像等信号。一个时序的波可以用多个不同频率的正弦波叠加来表示。只要叠加的波的频率不同，我们就可以通过傅里叶变换进行逆向转换。</p>
<p>一串文本也可以看作是一些时序信号，也可以有很多信号进行叠加，只要频率不同，都可以在后面的复杂神经网络中得到解耦（但也不一定真的要得到解耦）。在BERT这个设定中，token，segment，position明显可以对应三种非常不同的频率。</p></li>
<li><p><strong>transformer为什么要用三个不一样的QKV？</strong></p>
<p>增强网络的表达能力。</p></li>
<li><p><strong>为什么要多头？举例说明多头相比单头注意力的优势？</strong></p>
<p>增强网络的表达能力。不同的头关注不同信息。</p>
<p>假设有一个句子"the cat, which is black, sat on the
mat"。在处理"sat"这个词时，一个头可能会更注"cat"，因为"cat"是"sat"的主语；另一个头可能会更关注"on
the mat"，因为这是"sat"的宾语；还有一个头可能会关注"which is
black"，因为这是对"cat"的修饰。</p>
<p>经过多头之后，我们还需要att_out线性层来做线性变换，以自动决定（通过训练）对每个头的输出赋予多大的权重，从而在最终的输出中强调一些头的信息，而忽视其他头的信息。</p></li>
<li><p><strong>为什么Bert中要用WordPiece/BPE这样的subword
Token？</strong></p>
<p>避免OOV（Out Of
Vocabulary），也就是词汇表外的词。在NLP中，通常会预先构建一个词汇表，包含所有模型能够识别的词。然而，总会有一些词没有出现在预先构建的词汇表中，这些词就是
OOV。</p>
<p>传统的处理方式往往是将这些 OOV 映射到一个特殊的符号，如
<code>&lt;UNK&gt;</code>，但这种方式无法充分利用 OOV
中的信息。例如，对于词汇表中没有的词 "unhappiness"，如果直接映射为
<code>&lt;UNK&gt;</code>，则模型就无法理解它的含义。</p>
<p>WordPiece/Byte Pair Encoding (BPE) 等基于子词的分词方法提供了一种解决
OOV
问题的方式。现在更多的语言大模型选择基于BPE的方式，只不过BERT时代更多还是WordPiece。BPE
通过将词分解为更小的单元（子词或字符），可以有效地处理词汇表外的词。对于上面的
"unhappiness" 例子，即使 "unhappiness"
本身不在词汇表中，但是它可以被分解为 "un"、"happiness"
等子词，而这些子词可能在词汇表中。这样，模型就可以通过这些子词来理解
"unhappiness" 的含义。</p>
<p>另一方面就是，BPE本身的语义粒度也很合适，一个token不会太大，也不会小到损失连接信息（如一个字母）。</p></li>
<li><p><strong>Bert中为什么要在开头加个[CLS]?</strong></p>
<p>用[cls]学习整个句子的表示</p></li>
<li><p><strong>不用[CLS]的语义输出，有其他方式可以代替吗？</strong></p>
<p>这个问题还是考察到了[CLS]的核心内涵，也就是如何获得整个sentence的语义表示。既然不让使用特意训好的[CLS]，那我们就从每个token得到的embedding入手，把所有的token弄到一起。</p>
<p>很直观的思路，就是对BERT的所有输出词向量（忽略[CLS]和[SEP]）应用MaxPooling和AvgPooling，然后将得到的两个向量拼接起来，作为整个序列的表示。这样做的话可以同时保留序列中最显著的特征（通过MaxPooling）和整体的，均衡的特征（通过AvgPooling）。</p></li>
<li><p><strong>Bert中有哪些地方用到了mask?</strong></p>
<p><strong>预训练任务Masked Language Model (MLM)：</strong></p>
<p>主要的思想是，把输入的其中一部分词汇随机掩盖，模型的目标是预测这些掩盖词汇。这种训练方式使得每个位置的BERT都能学习到其上下文的信息。</p>
<p><strong>self-attention的计算：</strong></p>
<p>不同样本的seq_len不一样。但是由于输出的seq_len需要一致，所以需要通过补padding来对齐。而在attention中我们不希望一个token去注意到这些padding的部分，attention中的mask就是来处理掉这些无效的信息的。</p>
<p>具体来说就是在softmax前每个都设为-inf，然后过完softmax后"padding"部分的权重就会接近于零，query
token就不会分配注意力权重了。</p>
<p><strong>下游任务的decoder</strong>：</p>
<p>在做next token
prediction的时候，模型是根据前面已有的tokens来做的，也就是看不到未来的tokens的信息。而在我们训练的过程中，通常采用teacher
forcing的策略，也就是我们当然会把完整的标签喂给模型，但是由于在一个一个生成next
token的过程中，模型应该是一个一个往外“蹦“字的过程（想想chatgpt回复你的样子）所以我们会遮盖掉seqence中当前位置之后信息，以防止模型利用未来信息，也就是信息泄露。mask掉后模型的注意力只会集中在此前的序列上。</p></li>
<li><p><strong>Bert中self attention 计算复杂度如何？</strong></p>
<p><span
class="math inline">\(O(d_L^2)\)</span>，因为输入的序列的每一个token都要对这个序列上的所有token去求一个attention
score。</p></li>
<li><p><strong>有什么技术降低复杂度提升输入长度的？</strong></p>
<p>比如Sparse
Attention，放弃对全文的关注，只关心局部的语义组合，相当于self-attention上又加了一些mask，这样的话就可以降低复杂度，而且下游任务的语义关联性的体现往往是局部/稀疏的。</p></li>
<li><p><strong>为什么以前char level/subword
level的NLP模型表现一般都比较差，但是到了bert这里就比较好？</strong></p>
<p>还是归功于Transformers，因为对于字符级别（char-level）或者子词级别（subword-level）的NLP模型，挑战在于需要模型能够理解字符或者子词组合起来形成词语和句子的语义，这对模型的能力有很高的要求。</p>
<p>然而，以前NLP模型没办法做到很深，两层lstm基本就到极限了，非线性成长路线过分陡峭，所以增加网络容量的时候，降低了泛化能力。</p>
<p>Bert降低了输入的复杂度，提升了模型的复杂度。模型多层产生的非线性增长平滑，可以加大网络容量，同时增强容量和泛化能力。</p></li>
<li><p><strong>Bert为什么要使用warmup的学习率trick</strong></p>
<p>主要是考虑到训练的初始阶段params更新比较大，可能会使模型陷入local
minima或者overfitting。</p>
<p>warmup就是把lr从一个较小的值线性增大到预设，以减缓参数震荡，让训练变得比较smooth，当模型参数量上来后这种策略变得更重要了。</p></li>
<li><p><strong>为什么说GPT是单向的Bert是双向的？</strong></p>
<p>这也是decoder-only和encoder-only的区别。</p>
<p>decoder-only架构的生成模型在输出的时候只能看到当前位置前的tokens，也就是屏蔽了序列后面的位置，以适配NTP任务。</p>
<p>encoder-only架构的编码模型在输出的时候可以利用前后位置的tokens，以适配MLM任务。</p>
<p>具体的做法是self-attention加不加casual
mask，也就是遮不遮住序列后面的内容。</p></li>
<li><p><strong>Bert如何处理一词多义？</strong></p>
<p>一词多义指的是在不同句子中token有不同的含义。</p>
<p>这正是self-attention解决的，搭配上MLM的任务，就可以让每个token会注意到上下文的其他token来得到自己的embedding。</p></li>
<li><p><strong>Bert中的transformer和原生的transformer有什么区别？</strong></p>
<p>其实很多，如果我们只讨论模型架构，也就是对比<a
href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762">Attention
is All You Need</a>的encoder和BERT的话，最重点的区别在于位置编码。</p>
<p>原生的transformer是最经典的Sinusoidal绝对位置编码。</p>
<p>而BERT中变成了可以学习的参数，也就是可学习位置编码。</p>
<h2 id="四种norm">四种Norm</h2>
<ul>
<li><p>Batch
Norm：把每个Batch中，每句话的相同位置的字向量看成一组做归一化。</p></li>
<li><p>Layer Norm：在每一个句子中进行归一化。</p></li>
<li><p>Instance Norm：每一个字的字向量的看成一组做归一化。</p></li>
<li><p>Group Norm：把每句话的每几个字的字向量看成一组做归一化。</p></li>
<li><p><strong>Batch Normalization（Batch Norm）</strong>：
<strong>缺点</strong>：在处理序列数据（如文本）时，Batch
Norm可能不会表现得很好，因为序列数据通常长度不一，并且一次训练的Batch中的句子的长度可能会有很大的差异；此外，Batch
Norm对于Batch大小也非常敏感。对于较小的Batch大小，Batch
Norm可能会表现得不好，因为每个Batch的统计特性可能会有较大的波动。</p></li>
<li><p><strong>Layer Normalization（Layer Norm）</strong>：
<strong>优点</strong>：Layer
Norm是对每个样本进行归一化，因此它对Batch大小不敏感，这使得它在处理序列数据时表现得更好；另外，Layer
Norm在处理不同长度的序列时也更为灵活。</p></li>
<li><p><strong>Instance Normalization（Instance Norm）</strong>：
<strong>优点</strong>：Instance
Norm是对每个样本的每个特征进行归一化，因此它可以捕捉到更多的细节信息。Instance
Norm在某些任务，如风格迁移，中表现得很好，因为在这些任务中，细节信息很重要。
<strong>缺点</strong>：Instance
Norm可能会过度强调细节信息，忽视了更宏观的信息。此外，Instance
Norm的计算成本相比Batch Norm和Layer Norm更高。</p></li>
<li><p><strong>Group Normalization（Group Norm）</strong>：
<strong>优点</strong>：Group Norm是Batch Norm和Instance
Norm的折中方案，它在Batch的一个子集（即组）上进行归一化。这使得Group
Norm既可以捕捉到Batch的统计特性，又可以捕捉到样本的细节信息。此外，Group
Norm对Batch大小也不敏感。 <strong>缺点</strong>：Group
Norm的性能取决于组的大小，需要通过实验来确定最优的组大小。此外，Group
Norm的计算成本也比Batch Norm和Layer Norm更高。</p></li>
</ul>
<h1 id="大模型算法">大模型算法</h1>
<h2 id="并行计算">并行计算</h2>
<p>并行化指的是拆分任务并将它们分布到多个处理器或设备(如gpu)上，以便它们可以同时完成。</p>
<h3 id="data-parallenlism">Data Parallenlism</h3>
<p>数据并行性将训练数据分成多个分片(partition)，并将其分布到不同的节点上。
每个节点首先用自己的局部数据训练自己的子模型，然后与其他节点通信，以一定的间隔将结果组合在一起，从而得到全局模型。
最大的缺点是，在向后传递期间，您必须将整个梯度传递给所有其他gpu。它还在所有工作线程中复制模型和优化器，这是相当低内存效率的。</p>
<h3 id="tensor-parallelism">Tensor Parallelism</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240411135309145.png"
alt="image-20240411135309145" />
<figcaption aria-hidden="true">image-20240411135309145</figcaption>
</figure>
<p>张量并行将大型矩阵乘法划分为较小的子矩阵计算，然后使用多个gpu同时执行。</p>
<p>然而，缺点是它在每次前向和后向传播中引入了额外的激活通信，因此需要高通信带宽才能高效</p>
<h3 id="pipeline-parallelism-and-model-parallelism">Pipeline parallelism
and model parallelism</h3>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240411135707760.png"
alt="image-20240411135707760" />
管道并行通过将模型的层划分为可以并行处理的阶段来提高深度学习训练的内存和计算效率。这有助于显著提高总体吞吐量速度，同时增加最小的通信开销。你可以把管道并行看作是“层间并行”(张量并行可以看作是“层内并行”)。</p>
<p>与管道并行类似，模型并行是指在gpu之间分割模型并为每个模型使用相同的数据;所以每个GPU只处理模型的一部分，而不是数据的一部分。管道和模型并行的缺点是它不能无限扩展，因为管道并行的程度受模型深度的限制。</p>
<h3 id="ptd-p">PTD-P</h3>
<p>combines pipeline, tensor, and data parallelism</p>
<h3 id="gradient-accumulation">Gradient accumulation</h3>
<p>在一次对所有累积的梯度执行一个权重更新步骤之前，将多个批次的梯度相加。</p>
<p>这种方法减少了之间的通信开销,gpu通过允许它们独立地处理自己的本地批数据，直到它们再次相互同步，在为单个优化步骤积累足够的梯度之后。</p>
<h3
id="asynchronous-stochastic-gradient-descent-optimization">Asynchronous
stochastic gradient descent optimization</h3>
<ul>
<li>从参数服务器获取处理当前小批量所需的模型的最新参数。</li>
<li>我们根据这些参数计算损失的梯度.</li>
<li>这些梯度被发送回参数服务器，然后参数服务器相应地更新模型。</li>
</ul>
<h3 id="micro-batching">Micro-batching</h3>
<p>将 small
mini-batches合并成大批，这样在反向传播操作期间，可以在更短的时间内处理更多的批，并且在设备之间使用更少的同步点。</p>
<h2 id="数据集预处理">数据集预处理</h2>
<ul>
<li>Data Sampling</li>
</ul>
<p>某些数据组件可以被上采样以获得更平衡的数据分布。一些研究对低质量的数据集进行了降采样，如未过滤的网络爬虫数据。其他研究根据模型目标对特定领域的数据进行采样。</p>
<p>还有一些先进的方法可以过滤高质量的数据，例如将训练好的分类器模型应用到数据集上。例如，Meta
AI的模型Galactica是专门为科学而建立的，特别是存储、组合和推理科学知识。</p>
<ul>
<li>Data cleaning</li>
</ul>
<p>删除样板文本和HTML代码或标记，修复拼写错误，处理跨域单应词，删除有偏见、有害的言论。</p>
<p>有的项目，这些技术并没有被使用，因为模型应该看到真实世界的公平表示，并学习处理拼写错误和毒性作为模型能力的一部分。</p>
<ul>
<li>Non-standard textual components handling</li>
</ul>
<p>非标准文本组件转换为文本，例如，将表情符号雪花转换为对应的文本“snowflake”。</p>
<ul>
<li>Data deduplication</li>
</ul>
<p>擅长重复数据</p>
<ul>
<li>Downstream task data removal</li>
</ul>
<p>在训练集中删除测试集中也存在的数据</p>
<h2 id="tokenization">Tokenization</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240411152753420.png"
alt="image-20240411152753420" />
<figcaption aria-hidden="true">image-20240411152753420</figcaption>
</figure>
<p>将文本字符串编码为transformer可读的token ID整数。</p>
<p>Most state-of-the-art LLMs use subword-based tokenizers like
byte-pair encoding (BPE) as opposed to word-based approaches.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240411153647039.png"
alt="image-20240411153647039" />
<figcaption aria-hidden="true">image-20240411153647039</figcaption>
</figure></li>
</ul>
<p>subword-based methods</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240411154107909.png"
alt="image-20240411154107909" />
<figcaption aria-hidden="true">image-20240411154107909</figcaption>
</figure>
<h2 id="pre-train">Pre-Train</h2>
<h2 id="supervised-fine-tuning-sft"><strong>Supervised fine-tuning
(SFT)</strong></h2>
<p><a
href="https://blog.csdn.net/sinat_39620217/article/details/131751780">人工智能大语言模型微调技术：SFT
监督微调、LoRA 微调方法、P-tuning v2 微调方法、Freeze 监督微调方法_lora
ptuningv2-CSDN博客</a></p>
<p>lora：</p>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20240411183752670.png"
alt="image-20240411183752670" />
<figcaption aria-hidden="true">image-20240411183752670</figcaption>
</figure>
<p><a
href="https://www.zhihu.com/tardis/zm/art/623543497?source_id=1005">LORA：大模型轻量级微调
(zhihu.com)</a></p>
<p><a
href="https://blog.csdn.net/sinat_39620217/article/details/131751780">人工智能大语言模型微调技术：SFT
监督微调、LoRA 微调方法、P-tuning v2 微调方法、Freeze 监督微调方法_lora
ptuningv2-CSDN博客</a></p>
]]></content>
      <categories>
        <category>ML</category>
        <category>LLM</category>
      </categories>
  </entry>
  <entry>
    <title>LLM Basic Knowledge</title>
    <url>/2024/04/18/LLM_review/</url>
    <content><![CDATA[<p>参考博客：</p>
<p>https://dongnian.icu/note/llm</p>
<p><a
href="https://zhuanlan.zhihu.com/p/454482273">Transformer学习笔记一：Positional
Encoding（位置编码） - 知乎 (zhihu.com)</a></p>
<span id="more"></span>
<h1 id="llm-模型">LLM 模型</h1>
<h2 id="一些概念">一些概念</h2>
<h3 id="prefix-lm-和-causal-lm">prefix LM 和 causal LM</h3>
<ul>
<li>prefix LM：可以看到输入序列的上下文作为条件信息。</li>
<li>causal LM：自回归语言模型，只能看到当前和历史输入token序列。</li>
</ul>
<h2 id="主流预训练框架">主流预训练框架</h2>
<h3 id="自回归模型">自回归模型</h3>
<p>根据上文内容预测下一个可能跟随的单词，就是常说的自左向右的语言模型任务，或者反过来也行，就是根据下文预测前面的单词，这种类型的LM被称为自回归语言模型，常用于生成任务。代表作有GPT。</p>
<p>将每个单词<span
class="math inline">\(x_n\)</span>当作token，计算一个句子存在概率 <span
class="math display">\[
p(x_1:x_L) = p(x_1)p(x_2|x_1)p(x_3|x_1:x_2)\cdots p(x_L|x_1：x_{L-1})
\]</span> e.g. <span class="math display">\[
\begin{align*} p({the}, {mouse}, {ate}, {the}, {cheese}) = \, &amp;
p({the}) \\ &amp; p({mouse} \mid {the}) \\ &amp; p({ate} \mid {the},
{mouse}) \\ &amp; p({the} \mid {the}, {mouse}, {ate}) \\ &amp;
p({cheese} \mid {the}, {mouse}, {ate}, {the}). \end{align*}
\]</span></p>
<p>自回归语言模型的特点是<strong>它可以利用例如前馈神经网络等方法有效计算出每个条件概率分布</strong>。</p>
<h3 id="autoencoding自编码模型">Autoencoding自编码模型</h3>
<p>通过某个降噪目标（MLM）训练的双向文本编码器，即是mask掉文本中间某个token，让模型去预测，例如BERT。编码器会产出适用于NLU任务的上下文表示，但无法直接用于文本生成。</p>
<h3 id="encoder-decoder模型">encoder-decoder模型</h3>
<p>源自Seq2seq模型，代表作有T5.采用双向注意力机制，常用于条件生成任务，例如文本摘要或机械翻译。</p>
<h2 id="经典nlp模型">经典NLP模型</h2>
<h3 id="n-gram">N-gram</h3>
<p>N-gram假设第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关；形成一个长度为N的滑动窗口计算第N个单词出现概率。
<span class="math display">\[
p(x_i|x_{1:i-1}) = p(x_i|x_{i-(n-1):i-1})
\]</span> 对于bigram model： <span class="math display">\[
p(x_i|x_{i-1}) = \frac{C(x_{i-1}x_i)}{C(x_{i-1})}
\]</span> 对于n-gram model： <span class="math display">\[
p(x_i|x_{i-n-1},\cdots x_{i-1}) = \frac{C(x_{i-n-1}\cdots
x_{i})}{C(x_{i-n-1}\cdots x_{i-1})}
\]</span>
然后在给定的训练语料中，将上述的条件概率值都统计计算出来即可。</p>
<p>如果n太小，那么模型将无法捕获长距离的依赖关系。然而，如果n太大，统计上将无法得到概率的好估计.</p>
<h3 id="神经语言模型">神经语言模型</h3>
<h4 id="rnn">RNN</h4>
<h4 id="lstm">LSTM</h4>
<h4 id="seq2seq">Seq2seq</h4>
<h4 id="transformer">Transformer</h4>
<h5 id="基本架构">基本架构</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418155205656.png"
alt="image-20240418155205656" />
<figcaption aria-hidden="true">image-20240418155205656</figcaption>
</figure>
<h5 id="attention">Attention</h5>
<p>核心思想：网络应该更关注输入中的重要部分，而忽略不重要的部分，它通过学习不同部分的权重，将输入的序列中的重要部分显式地加权，从而使得模型可以更好地关注与输出有关的信息。</p>
<p>相较于传统的Seq2Seq模型只使用编码器来捕捉输入序列的信息，而解码器只从编码器的最后状态中获取信息，并将其用于生成输出序列。
Attention机制允许解码器在生成每个输出时，根据输入序列的不同部分给予不同的注意力，从而使得模型更好地关注到输入序列中的重要信息。</p>
<p>Transformer的Attention公式如下：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418155227786.png"
alt="image-20240418155227786" />
<figcaption aria-hidden="true">image-20240418155227786</figcaption>
</figure>
<ul>
<li><p>Q,K,V通过输入经过三个不同的MLP层计算获得，使用三个不同的vector（QKV）可以增强网络表达能力</p></li>
<li><p><span class="math inline">\(\sqrt{d_k}\)</span>作用：<span
class="math inline">\(QK^t\)</span>相乘会让数值变大，scaling
后进行softmax可以使得输入的数据的分布变得更好，避免数据进入softmax敏感区间，防止梯度消失，让模型能够更容易训练。</p>
<p>Attention的计算是在内积之后进行softmax，可以大致认为内积之后、softmax之前的数值在<span
class="math inline">\(−3\sqrt{d}\)</span>−到<span
class="math inline">\(3\sqrt{d}\)</span>这个范围内，由于d通常都至少是64，所以<span
class="math inline">\(e^{3\sqrt{d}}\)</span>比较大而<span
class="math inline">\(e^{-3\sqrt{d}}\)</span>比较小，因此经过softmax之后，Attention的分布非常接近一个one
hot分布了，这带来严重的梯度消失问题，导致训练效果差。</p>
<p>可以不除以<span
class="math inline">\(\sqrt{d_k}\)</span>，只要有别的方法可以缓解梯度消失即可。例如T5，初始化q、k全连接层的时候，其初始化方差要多除以一个d。</p></li>
<li><p>Transformer使用多头注意力机制：增强网络的表达能力。不同的头关注不同信息。</p>
<p>假设有一个句子"the cat, which is black, sat on the
mat"。在处理"sat"这个词时，一个头可能会更注"cat"，因为"cat"是"sat"的主语；另一个头可能会更关注"on
the mat"，因为这是"sat"的宾语；还有一个头可能会关注"which is
black"，因为这是对"cat"的修饰。</p>
<p>经过多头之后，我们还需要att_out线性层来做线性变换，以自动决定（通过训练）对每个头的输出赋予多大的权重，从而在最终的输出中强调一些头的信息，而忽视其他头的信息。</p></li>
<li><p>self-attention中，Q和K在点积之后，需要先经过mask再进行softmax，因此，对于要屏蔽的部分，mask之后的输出需要为负无穷，这样softmax之后输出才为0。</p></li>
<li><p>transformer使用了权重共享：</p>
<p>在Transformer中，Encoder和Decoder是由多层的Self-Attention
Layer和前馈神经网络层交叉堆叠而成。</p>
<p>在Encoder中，所有的自注意力层和前馈神经网络层都共享相同的参数。这种共享保证了每一层都执行相同的计算过程，使得模型能够更好地捕捉输入序列的不同位置之间的关联性。</p>
<p>在Decoder中，除了和Encoder相同的权重共享方式外，还存在另一种特殊的权重共享：Decoder的自注意力层和Encoder的自注意力层之间也进行了共享。通过这种共享方式，Decoder可以利用Encoder的表示来理解输入序列并生成输出序列。</p>
<p>权重共享的好处是大大减少了模型的参数数量，使得Transformer可以更有效地训练，并且更容易进行推理。此外，共享参数还有助于加快训练速度和提高模型的泛化能力，因为模型可以在不同位置共享并学习通用的特征表示。</p></li>
</ul>
<h5 id="位置编码">位置编码</h5>
<p>发展历史：<a
href="https://zhuanlan.zhihu.com/p/454482273">Transformer学习笔记一：Positional
Encoding（位置编码） - 知乎 (zhihu.com)</a></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418215532333.png"
alt="image-20240418215532333" />
<figcaption aria-hidden="true">image-20240418215532333</figcaption>
</figure>
<p>为什么用三角函数：希望位置编码是连续有界</p>
<p>为什么<span
class="math inline">\(w_k\)</span>很小，避免序列前后端的编码重合</p>
<p>为什么sin和cos交替使用：希望不同位置编码之间能通过线性转换得到</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418215748852.png"
alt="image-20240418215748852" />
<figcaption aria-hidden="true">image-20240418215748852</figcaption>
</figure>
<h2 id="常见大语言模型">常见大语言模型</h2>
<p>常有encoder-only, decoder-only以及encoder-decoder模型</p>
<ul>
<li>Encoder：Transformer中的Encoder是用于将输入序列转换成隐藏表示的模块。它将输入序列中的每一个位置的词嵌入向量作为初始输入，然后通过多层的自注意力机制和全连接层，将每个位置的信息编码成一个定长的隐藏向量表示。Encoder的输出可以被送入Decoder中进行下一步处理。</li>
<li>Decoder：Transformer中的Decoder是用于生成输出序列的模块。它接受Encoder的输出，以及前面已经生成的部分输出序列作为输入。Decoder的主要任务是生成下一个位置的词，直到整个序列生成完成。Decoder同样也是由多层的自注意力机制和全连接层组成，但相比于Encoder还加入了一个额外的注意力机制，用于将Encoder输出的信息融合到生成过程中。Decoder还包括一个线性变换层，用于将Decoder的输出映射成输出词的概率分布。</li>
</ul>
<p>Encoder和Decoder的区别在于它们的输入和输出以及它们的功能。Encoder的输入是输入序列，输出是每个位置的隐藏向量表示；Decoder的输入是Encoder的输出和前面生成的部分输出序列，输出是生成的下一个位置的词。Encoder用于编码输入信息，Decoder用于生成输出信息。</p>
<h3 id="gpt系列">GPT系列</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419170521376.png"
alt="image-20240419170521376" />
<figcaption aria-hidden="true">image-20240419170521376</figcaption>
</figure>
<ul>
<li><p>使用了一个仅有decoder的 Transformer
结构，每一个作为一个Layer，共有12层。</p></li>
<li><p>激活函数是 GELU（更平滑减少梯度爆炸的风险
处处可导，不会出现神经元死亡的状态）。</p></li>
<li><p>首先以无监督的方式预训练模型，让它接触大量的原始文本数据。这个预训练阶段使模型能够理解自然语言中存在的统计模式和结构。</p></li>
<li><p>模型经历了一个监督微调阶段，其中它在具有标签数据的特定任务上得到了进一步的改进。</p></li>
</ul>
<h3 id="bert系列">BERT系列</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419172830240.png"
alt="image-20240419172830240" />
<figcaption aria-hidden="true">image-20240419172830240</figcaption>
</figure>
<ul>
<li>采用MLM对双向的Transformers进行预训练，以生成深层的双向语言表征。</li>
<li>预训练后，只需要添加一个额外的输出层进行fine-tune，就可以在各种各样的下游任务中取得state-of-the-art的表现。在这过程中并不需要对BERT进行任务特定的结构修改。</li>
</ul>
<h4 id="结构">结构</h4>
<p>BERT是基于transformer的，但是它只使用了transformer的encoder部分，它的整体框架是由多层transformer的encoder堆叠而成的。每一层的encoder则是由一层muti-head-attention和一层feed-forword组成</p>
<h4 id="预训练">预训练</h4>
<ul>
<li><p>Masked Language Model（MLM）</p>
<p>以15%的概率用mask token
（[MASK]）随机地对每一个训练序列中的token进行替换，然后预测出[MASK]位置原有的单词。然而，由于[MASK]并不会出现在下游任务的微调（fine-tuning）阶段，因此预训练阶段和微调阶段之间产生了<strong>不匹配</strong><em>（这里很好解释，就是预训练的目标会令产生的语言表征对[MASK]敏感，但是却对其他token不敏感）</em>。因此BERT采用了以下策略来解决这个问题：</p>
<p>首先在每一个训练序列中以15%的概率随机地选中某个token位置用于预测，假如是第i个token被选中，则会被替换成以下三个token之一</p>
<p>1）80%的时候是[MASK]。如，my dog is <strong>hairy</strong>——&gt;my
dog is <strong>[MASK]</strong></p>
<p>2）10%的时候是随机的其他token。如，my dog is
<strong>hairy</strong>——&gt;my dog is <strong>apple</strong></p>
<p>3）10%的时候是原来的token<em>（保持不变，个人认为是作为2）所对应的负类）</em>。如，my
dog is <strong>hairy</strong>——&gt;my dog is <strong>hairy</strong></p>
<p>再用该位置对应的输出向量
去预测出原来的token（<em>输入到全连接，然后用softmax输出每个token的概率，最后用交叉熵计算loss）</em>。</p>
<p>该策略令到BERT不再只对[MASK]敏感，而是对所有的token都敏感，以致能抽取出任何token的表征信息。</p></li>
<li><p>Next Sentence Prediction（NSP）</p>
<p>预测两个句子是否连在一起。具体的做法是：对于每一个训练样例，我们在语料库中挑选出句子A和句子B来组成，50%的时候句子B就是句子A的下一句<em>（标注为IsNext）</em>，剩下50%的时候句子B是语料库中的随机句子<em>（标注为NotNext）</em>。接下来把训练样例输入到BERT模型中，用[CLS]对应的C信息去进行二分类的预测。</p></li>
<li><p>Masked Language Model（MLM）</p>
<p>以15%的概率用mask token
（[MASK]）随机地对每一个训练序列中的token进行替换，然后预测出[MASK]位置原有的单词。然而，由于[MASK]并不会出现在下游任务的微调（fine-tuning）阶段，因此预训练阶段和微调阶段之间产生了<strong>不匹配</strong><em>（这里很好解释，就是预训练的目标会令产生的语言表征对[MASK]敏感，但是却对其他token不敏感）</em>。因此BERT采用了以下策略来解决这个问题：</p>
<p>首先在每一个训练序列中以15%的概率随机地选中某个token位置用于预测，假如是第i个token被选中，则会被替换成以下三个token之一</p>
<p>1）80%的时候是[MASK]。如，my dog is <strong>hairy</strong>——&gt;my
dog is <strong>[MASK]</strong></p>
<p>2）10%的时候是随机的其他token。如，my dog is
<strong>hairy</strong>——&gt;my dog is <strong>apple</strong></p>
<p>3）10%的时候是原来的token<em>（保持不变，个人认为是作为2）所对应的负类）</em>。如，my
dog is <strong>hairy</strong>——&gt;my dog is <strong>hairy</strong></p>
<p>再用该位置对应的 ��
去预测出原来的token（<em>输入到全连接，然后用softmax输出每个token的概率，最后用交叉熵计算loss）</em>。</p>
<p>该策略令到BERT不再只对[MASK]敏感，而是对所有的token都敏感，以致能抽取出任何token的表征信</p></li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419181519909.png"
alt="image-20240419181519909" />
<figcaption aria-hidden="true">image-20240419181519909</figcaption>
</figure>
<ul>
<li>最终输入
<ul>
<li>Token
Embeddings是词向量，第一个单词是CLS（Classification）标志，可以用于之后的分类任务；第一个SEP表示第一个句子的结束，同时标志第二个句子开始。</li>
<li>Segment
Embeddings用来区别两种句子，因为预训练不光做LM（语言模型）还要做以两个句子为输入的分类任务</li>
<li>Position
Embeddings表示位置信息，这里的位置embedding是通过学习的方式得到的。</li>
</ul></li>
</ul>
<p>最后训练样例长这样：</p>
<p>Input1=[CLS] the man went to [MASK] store [SEP] he bought a gallon
[MASK] milk [SEP]</p>
<p>Label1=IsNext</p>
<p>Input2=[CLS] the man [MASK] to the store [SEP] penguin [MASK] are
flight ##less birds [SEP]</p>
<p>Label2=NotNext</p>
<p>把每一个训练样例输入到BERT中可以相应获得两个任务对应的loss，再把这两个loss加在一起就是整体的预训练loss。<em>（也就是两个任务<strong>同时</strong>进行训练）</em></p>
<h4 id="fine-tuning">Fine-tuning</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419182742596.png"
alt="image-20240419182742596" />
<figcaption aria-hidden="true">image-20240419182742596</figcaption>
</figure>
<ul>
<li><p>sequence的分类任务：(a)图表示两个句子的分类，如比如判断两句话是否表示相同的含义；(b)是单句子分类，如：比如判断电影评论是喜欢还是讨厌。预训练中的NSP任务使得BERT中的“[CLS]”位置的输出包含了整个句子对（句子）的信息，我们利用其在有标注的数据上微调（Fine-tuning）模型，给出预测结果。所以，这两种情况，只需要在
Transformer 的输出之上加一个分类层。</p></li>
<li><p>问答任务：输入部分由问题和包含答案的文本组成，并有特殊分隔符“【SEP】”分隔。因为答案由文本中连续的token组成，所以<strong>预测答案的过程本质上是确定答案开头和结尾token所在的位置的过程</strong>。e.g.：输入：身体内哪些元素缺失容易导致抽筋[sep]小腿肚抽筋通常是由于钙流失导致骨质疏松引起的；输出：钙（输出token位置）</p></li>
<li><p>NER（实体命名识别）：给出一句话，对每个词进行标注，判断属于人名，地名，机构名，还是其他。</p>
<ul>
<li><p>BERT模型+FC layer（全连接层）：</p>
<p>BERT的output 是每个token的encoding
vector。只需要在BERT的基础上增加一层全连接层，一般情况下，在NER任务中，全连接层(经过softmax)的输出为4个维度，分别作为每一类的概率。（在NER任务中一般有4类：B表示实体的开始，I表示实体的中间，E表示实体的结束，O表示不是实体）。</p></li>
<li><p>BERT+CRF 模型</p>
<p>在BERT后连接一个CRF层，CRF是一种经典的概率图模型，CRF层可以加入一些约束来保证最终的预测结果是有效的。这些约束可以在训练数据时被CRF层自动学习得到。</p></li>
</ul></li>
</ul>
<h4 id="小知识点">小知识点</h4>
<ul>
<li><p>Bert在原输入前加入[cls]用于学习整个句子的表示</p></li>
<li><p>warm-up：将学习率逐渐从一个较小的初始值增加到预定的最大学习率，解决两个问题：</p>
<p><strong>不稳定性：</strong>在训练初期，由于模型参数的随机初始化以及模型的复杂性，模型可能处于一个较不稳定的状态。此时使用较大的学习率可能导致模型的参数变动太大，使得模型很难收敛，学习率warm-up可以在这个阶段将学习率保持较小，提高模型训练的稳定性。
<strong>避免过拟合：</strong>BERT模型往往需要较长的训练时间来获得高质量的表示。如果在训练的早期阶段就使用较大的学习率，可能会导致模型在训练初期就过度拟合训练数据，降低模型的泛化能力。通过学习率warm-up，在训练初期使用较小的学习率，可以避免过度拟合，等模型逐渐稳定后再使用较大的学习率进行更快的收敛。</p></li>
<li></li>
</ul>
<h3 id="xlnet">XLNet</h3>
<p>To be continue...</p>
<h3 id="roberta">RoBERTa</h3>
<p>To be continue...</p>
<h3 id="t5">T5</h3>
<p>To be continue...</p>
<h3 id="llama">LLama</h3>
<h4 id="llama-1">LLama</h4>
<p>LLaMA 所采用的 Transformer 结构和细节，与标准的 Transformer
架构不同的地方包括采用了<strong>前置层归一化</strong>（Pre-normalization）并使用
<strong>RMSNorm 归一化函数</strong> （Normalizing
Function）、激活函数更换为
<strong>SwiGLU</strong>，并使用了<strong>旋转位置嵌入</strong>（RoP），整体
Transformer 架构与 GPT-2 类似。</p>
<h5 id="rmsnorm归一化">RMSNorm归一化</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418160600375.png"
alt="image-20240418160600375" />
<figcaption aria-hidden="true">image-20240418160600375</figcaption>
</figure>
<p>为了使得模型训练过程更加稳定，GPT-2 相较于 GPT
就引入了前置层归一化方法，将第一个层归一化移动到多头自注意力层之前，第二个层归一化也移动到了全连接层之前，同时残差连接的位置也调整到了多头自注意力层与全连接层之后。层归一化中也采用了
RMSNorm 归一化函数。 针对输入向量 aRMSNorm 函数计算公式如下</p>
<p><span class="math display">\[
RMS(a)=\sqrt{\frac{1}{n}\sum_{i=1}^na_i^2}
\]</span></p>
<p><span class="math display">\[
\overline{a_i}=\frac{a_i}{RMS(a)}
\]</span></p>
<p>此外，RMSNorm 还可以引入可学习的缩放因子<span
class="math inline">\(g_i\)</span>和偏移参数<span
class="math inline">\(b_i\)</span>，从而得到 <span
class="math display">\[
\overline{a_i}=\frac{a_i}{RMS(a)}g_i + b_i
\]</span></p>
<h5 id="swiglu激活函数">SwiGLU激活函数</h5>
<p><span class="math display">\[
Swish_{\beta}(x) = x\sigma(\beta x)
\]</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418200505781.png"
alt="image-20240418200505781" />
<figcaption aria-hidden="true">image-20240418200505781</figcaption>
</figure>
<p>Transformer中FFN(Feed Forwar
d)层包括两层全连接，第一层升维，第二层降维回归到输入维度，中间插入一个非线性激活函数ReLU。
<span class="math display">\[
FFN_{ReLU}(x,W_1,W_2)=ReLU(xW_1)W_2
\]</span> <img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418200241972.png"
alt="image-20240418200241972" /></p>
<p>SwiGLU激活函数是相较于 ReLU 函数在大部分评测中都有不少提升。在 LLaMA
中全连接层 使用带有 SwiGLU 激活函数的 FFN（Position-wise Feed-Forward
Network）的计算公式如下： <span class="math display">\[
FFN_{SwiGLU}(x,W_1,V,W_2)=SwiGLU(x,W,V)W_2
\]</span></p>
<p><span class="math display">\[
SwiGLU(x,W,V) = Swish_{\beta}(xW)\otimes xV
\]</span></p>
<p><span class="math display">\[
Swish_{\beta}(x) = x\sigma(\beta x)
\]</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418200302617.png"
alt="image-20240418200302617" />
<figcaption aria-hidden="true">image-20240418200302617</figcaption>
</figure>
<p>llama是把SwiGLU中的W，V，W2的矩阵维度从(dim， dim)变成(dim,
2/3dim)，从而打平参数量和计算量。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418200358968.png"
alt="image-20240418200358968" />
<figcaption aria-hidden="true">image-20240418200358968</figcaption>
</figure>
<h5 id="旋转位置嵌入rope">旋转位置嵌入（RoPE）</h5>
<p><a
href="https://www.zhihu.com/tardis/zm/art/647109286?source_id=1005#:~:text=旋转位置编码（Rotary%20Position%20Embedding，RoPE）是论文%20Roformer%3A%20Enhanced%20Transformer%20With%20Rotray,提出的一种能够将相对位置信息依赖集成到%20self-attention%20中并提升%20transformer%20架构性能的位置编码方式。%20而目前很火的%20LLaMA、GLM%20模型也是采用该位置编码方式。">十分钟读懂旋转编码（RoPE）
(zhihu.com)</a></p>
<p>对于位置编码，常规的做法是在计算query,key和value向量之前，会计算一个位置编码向量<span
class="math inline">\(p_i\in R_d\)</span>加到词嵌入<span
class="math inline">\(x_i\in
R_d\)</span>上，然后再乘对应的变换矩阵转换为<span
class="math inline">\(q,k,v\)</span></p>
<p>经典的<span class="math inline">\(p_i\)</span>计算方法是Sinusoidal
函数，k是第k个token,维度是d，i=2tor2t+1是位置向量里第i个元素： <span
class="math display">\[
p_{i,2t} = sin(\frac{k}{10000^{2t/d}})
\]</span></p>
<p><span class="math display">\[
p_{i,2t+1} = cos(\frac{k}{10000^{2t/d}})
\]</span></p>
<p>RoPE为了能利用上 token 之间的相对位置信息，假定 query 向量<span
class="math inline">\(q_m\)</span> 和 key 向量<span
class="math inline">\(k_n\)</span>间的内积操作可以被一个函数<span
class="math inline">\(g\)</span>表示，该函数<span
class="math inline">\(g\)</span>的输入是词嵌入向量<span
class="math inline">\(x_m,x_n\)</span> 和它们之间的相对位置m-n ： <span
class="math display">\[
&lt;f_q(x_m,m),f_k(x_n,n)&gt;=g(x_m,x_n,m-n)
\]</span>
接下来的目标就是找到一个等价的位置编码方式，从而使得上述关系成立,在二维：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418221338409.png"
alt="image-20240418221338409" />
<figcaption aria-hidden="true">image-20240418221338409</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418221353501.png"
alt="image-20240418221353501" />
<figcaption aria-hidden="true">image-20240418221353501</figcaption>
</figure>
<p>扩展到任意维度</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418221653937.png"
alt="image-20240418221653937" />
<figcaption aria-hidden="true">image-20240418221653937</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418221835955.png"
alt="image-20240418221835955" />
<figcaption aria-hidden="true">image-20240418221835955</figcaption>
</figure>
<h4 id="llama-2">Llama-2</h4>
<p>模型结构的变动主要是体现在GQA和FFN缩放上</p>
<ul>
<li>MHA改成GQA：整体参数量会有减少</li>
<li>FFN模块矩阵维度有扩充：增强泛化能力，整体参数量增加</li>
<li>上下文长度是llama两倍(长度从2048-&gt;4096) 训练语料增加约
40%，体现在1.4T-&gt;2.0T的Tokens
llama2-34B和llama2-70B使用了GQA，加速模型训练和推理速度</li>
</ul>
<h5 id="mqa和gqa">MQA和GQA</h5>
<ul>
<li>Mutil-Head Attention
因为自回归模型生成回答时，需要前面生成的KV缓存起来，来加速计算。</li>
<li>Multi-Query Attention
多个头之间可以共享KV对，因此速度上非常有优势，实验验证大约减少30-40%吞吐。</li>
<li>Group Query Attention
没有像MQA那么极端，将query分组，组内共享KV，效果接近MQA，速度上与MQA可比较。</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240418222254764.png"
alt="image-20240418222254764" />
<figcaption aria-hidden="true">image-20240418222254764</figcaption>
</figure>
<h3 id="chatglm系列">ChatGLM系列</h3>
<h4 id="chatglm">ChatGLM</h4>
<p>GLM希望通过多任务学习将不同框架目标结合</p>
<p>GLM模型基于autoregressive blank
infilling方法，结合了上述三种预训练模型的思想。</p>
<ul>
<li>自编码思想：在输入文本中，随机删除连续的tokens。</li>
<li>自回归思想：顺序重建连续tokens。在使用自回归方式预测缺失tokens时，模型既可以访问corrupted文本，又可以访问之前已经被预测的spans。</li>
<li>span shuffling + 二维位置编码技术。</li>
<li>通过改变缺失spans的数量和长度，自回归空格填充目标可以为条件生成以及无条件生成任务预训练语言模型。</li>
</ul>
<h5 id="自回归空格填充任务">自回归空格填充任务</h5>
<p><a
href="https://www.zhihu.com/tardis/zm/art/637382548?source_id=1005">清华大学通用预训练模型：GLM
(zhihu.com)</a></p>
<p>给定一个输入文本<span class="math inline">\(x=[x_1,\cdots ,
x_n]\)</span>,从中随机取样多个文本片段<span
class="math inline">\(\{s_1,s_2,\cdots,
s_m\}\)</span>构成span，对应x中一系列连续的词，每个片段用一个单独的[mask]替换，这样原文本x将变成一个损坏文本,e.g.<span
class="math inline">\(x_{corrup}=[x_1,[mask], x_4,\cdots,
[mask]]\)</span>。模型以自回归的方式从损坏的文本中预测缺失的词,这意味着在预测一个片段中的缺失词时，模型可以访问损坏的文本和<strong>之前预测的片段</strong>。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419145518680.png"
alt="image-20240419145518680" />
<figcaption aria-hidden="true">image-20240419145518680</figcaption>
</figure>
<ul>
<li>原始文本<span class="math inline">\(x\)</span>被分成两部分：Part
A是损坏文本<span class="math inline">\(x_{corrup}\)</span>,Part
B是被mask的span，这里假设mask掉<span
class="math inline">\([x_3]\)</span>和<span
class="math inline">\([x_5,x_6]\)</span>，跨度长度付出泊松分布(<span
class="math inline">\(\lambda =3\)</span>)。Part A
的词可以相互看到，但不能看到 Part B 中的任何词。Part B 的词可以看到 Part
A 和 Part B 中的前置词（前面预测的词），但不能看到 Part B
中的后续词。</li>
<li>mask掉<span class="math inline">\([x_3]\)</span>和<span
class="math inline">\([x_5,x_6]\)</span>， 并打乱 Part B
的顺序。为了捕捉span之间的内在联系，随机交换span的顺序。</li>
<li>GLM 自回归地生成 Part B。 每个片段在输入时前面加上
[Start]，在输出时后面加上 [End]。
二维位置编码表示不同片段之间和片段内部的位置关系。</li>
<li><strong>自注意力掩码</strong>。 <strong>灰色区域被掩盖</strong>。
<strong>Part A 的词语可以自我看到（图2(d)蓝色框），但不能看到 Part B。
Part B 的词语可以看到 Part A 和 Part B
中的前面的词语（图2(d)黄色和绿色框对应两个片段）</strong>。 [M] :=
[MASK]，[S] := [START]，[E] := [END]。</li>
</ul>
<h5 id="多目标预训练">多目标预训练</h5>
<p>GLM 遮盖了短的文本区域，适合于 NLU
任务。我们更感兴趣的是预训练一个能够同时处理 NLU
和文本生成的单一模型。因此，清华大学研究了一种多任务预训练设置，其中一个生成更长文本的目标与空白填充目标共同优化。GLM
考虑了以下两种目标：</p>
<ul>
<li>文档级别。采样一个单一的区域，其长度从原始长度的 50% 到1 00%
之间的均匀分布中采样。该目标旨在进行长文本生成。</li>
<li>句子级别。限制遮盖的区域必须是完整的句子。多个区域（句子）被采样，覆盖原始文本的
15% 的词数。该目标旨在进行 seq2seq
任务，其预测结果通常是完整的句子或段落。</li>
</ul>
<p>这两种新的目标都是按照原始目标的相同方式定义的，即公式1。唯一的区别是区域的数量和区域的长度。</p>
<h5 id="模型架构">模型架构</h5>
<p>GLM 使用了一个单一的 Transformer，并对架构做了一些修改：</p>
<p>（1）重新排列了层归一化和残差连接的顺序，这对于大规模的语言模型来避免数值错误是非常关键。</p>
<p>（2）使用了一个单一的线性层来进行输出词的预测。</p>
<p>（3）用 GeLUs 替换了 ReLU 激活函数。</p>
<h5 id="二维位置编码">二维位置编码</h5>
<p>图中 Position1 = [1, 2, 3, 4, 5, 5, 5, 5, 3, 3]，Position2 = [0, 0,
0, 0, 0, 1, 2, 3, 1, 2] 是怎么得到的。Position1 和 Position2
是输入的二维编码，第一个维度表示片段在原始文本中的相对位置，第二个维度表示片段内部的相对位置。</p>
<p>GLM
的编码方法确保了模型在重建被遮盖的跨度时不知道它们的长度。这与其他模型相比是一个重要的区别。</p>
<p>注意Position2耶不会知道跨度长度，因为token是一个一个预测的，position
encoding不断加1直到预测到[end]。</p>
<h5 id="多任务">多任务</h5>
<ul>
<li>NLU</li>
</ul>
<p>GLM 将 NLU
分类任务重新制定为填空生成任务，例如，情感分类任务可以表述为
“{SENTENCE}。这真的是 [MASK]”。输出label
y也同样会被映射到完形填空的答案中。“positive” 和 “negative”
对应的标签就是“good” 和
“bad。因此，句子是正面或负面的概率与在空白处预测“好”或“坏”成正比。然后我们用交叉熵损失来微调
GLM。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419153829264.png"
alt="image-20240419153829264" />
<figcaption aria-hidden="true">image-20240419153829264</figcaption>
</figure>
<ul>
<li>NLG</li>
</ul>
<p>给定的上下文构成了输入的 Part A，末尾附加了一个 mask
符号。模型自回归地生成 Part B 的文本。可以直接应用预训练的 GLM
进行无条件的生成，或者在下游的条件生成任务上对其进行微调。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240419153920299.png"
alt="image-20240419153920299" />
<figcaption aria-hidden="true">image-20240419153920299</figcaption>
</figure>
<h4 id="chatglm-2">ChatGLM-2</h4>
<ul>
<li>更长的上下文：基于 FlashAttention
技术，将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K
扩展到了 32K，并在对话阶段使用 8K
的上下文长度训练。对于更长的上下文，发布了 ChatGLM2-6B-32K
模型。LongBench 的测评结果表明，在等量级的开源模型中，ChatGLM2-6B-32K
有着较为明显的竞争优势。</li>
<li>更强大的性能：基于 ChatGLM 初代模型的开发经验，全面升级了
ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了
1.4T
中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B
在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%）
、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。</li>
<li>更高效的推理：基于 Multi-Query Attention 技术，ChatGLM2-6B
有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了
42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。
更开放的协议：ChatGLM2-6B
权重对学术研究完全开放，在填写问卷进行登记后亦允许免费商业使用。</li>
</ul>
<h5 id="与chatglm的变化">与ChatGLM的变化</h5>
<ul>
<li>使用了RoPE替换二维位置编码。目前大部分主流的LLMs都在使用RoPE，</li>
<li>Multi-Query Attention：这是一种共享机制的Attention，相比Multi-Head
Attention，其Query部分没有区别，Key和Value可以只用一个Head。计算时，对Key和Value进行expand或者repeat操作，使它们填充到与Query一样的维度，后续计算就与Multi-Head
Attention没区别。</li>
<li>Attention Mask: V1的attention mask分了2部分，Part A和Part B，Part
A部分是双向Attention，Part B部分是Causal
Attention。在V2版本，全部换成了Causal Attention，不再区分是Part
A还是Part B，完全变成了decoder-only的架构。</li>
<li>多目标任务：Chat版本主要还是用的gMask生成式任务，但是在V1版本的代码还能看到mask、gMask等字样，V2已经摒弃了这些特殊token，原因与Attention
Mask一致，均因为变成了decoder-only的架构，不再需要区分Part A和Part B。
3.ChatGLM-3</li>
</ul>
<h4 id="chatglm-3">ChatGLM-3</h4>
<p>ChatGLM2与ChatGLM3模型架构是完全一致的。
词表的大小从ChatGLM的150528缩小为65024
位置编码从每个GLMBlock一份提升为全局一份
SelfAttention之后的前馈网络有不同。ChatGLM用GELU（Gaussian Error Linear
Unit）做激活；ChatGLM用Swish-1做激活。而且ChatGLM2、3应该是修正了之前的一个bug，因为GLU（Gated
Linear
Unit）本质上一半的入参是用来做门控制的，不需要输出到下层，所以ChatGLM2、3看起来前后维度不一致（27392-&gt;13696)反而是正确的。</p>
<h1 id="有监督微调sft">有监督微调SFT</h1>
<p>流程：</p>
<ul>
<li>预训练模型选择：选择一个在大规模数据上进行预训练的模型作为基础模型。例如，可以选择一种预训练的语言模型，如BERT、GPT等。</li>
<li>数据准备：准备用于微调的特定任务数据集。这些数据集应包含任务相关的样本和相应的标签或目标。确保数据集与任务的特定领域或问题相关。</li>
<li>构建任务特定的模型头：根据任务的要求，构建一个特定的模型头（task-specific
head）。模型头是添加到预训练模型之上的额外层或结构，用于根据任务要求进行输出预测或分类。例如，对于文本分类任务，可以添加一个全连接层和softmax激活函数。</li>
<li>参数初始化：将预训练模型的参数作为初始参数加载到微调模型中。这些参数可以被视为模型已经学习到的通用语言表示。</li>
<li>微调训练：使用特定任务的数据集对模型进行有监督训练。这包括将任务数据输入到模型中，计算损失函数，并通过反向传播和优化算法（如梯度下降）更新模型参数。在微调过程中，只有模型头的参数会被更新，而预训练模型的参数会保持不变。</li>
<li>调整超参数：微调过程中，可以根据需要调整学习率、批量大小、训练迭代次数等超参数，以达到更好的性能。</li>
<li>评估和验证：在微调完成后，使用验证集或测试集对微调模型进行评估，以评估其在特定任务上的性能。可以使用各种指标，如准确率、精确率、召回率等。
可选的后续微调：根据实际情况，可以选择在特定任务的数据上进行进一步的微调迭代，以进一步提高模型性能。</li>
</ul>
<h2 id="peftparameter-efficient-fine-tuning">PEFT（Parameter-Efficient
Fine-Tuning）</h2>
<p>PEFT旨在仅训练少量参数使模型适应到下游任务，通过冻结预训练模型的某些层，并仅微调特定于下游任务的最后几层来实现这种效率。即可节省计算资源，又只修改模型参数的一小部分，并且不容易过度拟合。高效微调技术可以粗略分为以下三大类：</p>
<ul>
<li><p>增加额外参数：</p>
<ul>
<li><p>适配器（Adapters）：适配器层是插入预训练模型层之间的小型神经网络。在微调过程中，只训练这些适配器层，保持预先训练的参数冻结</p></li>
<li><p>软提示：固定模型权重并更新提示的参数，生成的提示被称为“软提示”，e.g.</p>
<p>对于给定的: <code>What's 2+2?</code>.</p>
<ol type="1">
<li>它可能被标记为 <code>What, 's, 2, +, 2, ?</code>.</li>
<li>然后，每个标记将被转换为一组值的向量。</li>
<li>这些向量可以视为模型参数。模型可以进一步训练，仅调整这些提示的权重。一旦我们开始更新这些权重，标记的向量就不再对应于词汇表中实际的嵌入。</li>
</ol></li>
</ul></li>
<li><p>选取一部分参数更新</p>
<ul>
<li>选择性层调整（Selective Layer
Tuning）：可以只微调层的一个子集，而不是微调模型的所有层。</li>
<li>稀疏微调（Sparse
Fine-Tuning）：传统的微调会略微调整所有参数，但稀疏微调只涉及更改模型参数的一个子集。</li>
</ul></li>
<li><p>引入重参数化</p></li>
</ul>
<h2 id="prefix-tuning">Prefix Tuning</h2>
<p>Prefix
Tuning提出固定预训练LM，为LM添加可训练，任务特定的前缀，这样就可以为不同任务保存不同的前缀，微调成本也小；同时，这种Prefix实际就是连续可微的Virtual
Token（Soft Prompt/Continuous
Prompt），相比离散的Token，更好优化，效果更好。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421142012294.png"
alt="image-20240421142012294" />
<figcaption aria-hidden="true">image-20240421142012294</figcaption>
</figure>
<p>在输入token之前构造一段任务相关的virtual
tokens作为Prefix，然后训练的时候只更新Prefix部分的参数，而PLM中的其他部分参数固定。针对不同的模型结构，需要构造不同的Prefix。</p>
<ul>
<li>针对自回归架构模型：在句子前面添加前缀，得到 z = [PREFIX; x;
y]，合适的上文能够在固定 LM
的情况下去引导生成下文（比如：GPT3的上下文学习）。</li>
<li>针对编码器-解码器架构模型：Encoder和Decoder都增加了前缀，得到 z =
[PREFIX; x; PREFIX0;
y]。Encoder端增加前缀是为了引导输入部分的编码，Decoder
端增加前缀是为了引导后续token的生成。</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421142326432.png"
alt="image-20240421142326432" />
<figcaption aria-hidden="true">image-20240421142326432</figcaption>
</figure>
<p>该方法其实和构造Prompt类似，只是Prompt是人为构造的“显式”的提示，并且无法更新参数，而Prefix则是可以学习的“隐式”的提示。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421142410640.png"
alt="image-20240421142410640" />
<figcaption aria-hidden="true">image-20240421142410640</figcaption>
</figure>
<p>同时，为了防止直接更新Prefix的参数导致训练不稳定和性能下降的情况，在Prefix层前面加了MLP结构，训练完成后，只保留Prefix的参数。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421142649411.png"
alt="image-20240421142649411" />
<figcaption aria-hidden="true">image-20240421142649411</figcaption>
</figure>
<p>除此之外，通过消融实验证实，只调整embedding层的表现力不够，将导致性能显著下降，因此，在每层都加了prompt的参数，改动较大。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421142704694.png"
alt="image-20240421142704694" />
<figcaption aria-hidden="true">image-20240421142704694</figcaption>
</figure>
<p>另外，实验还对比了位置对于生成效果的影响，Prefix-tuning也是要略优于Infix-tuning的。其中，Prefix-tuning形式为
[PREFIX; x; y]，Infix-tuning形式为 [x; INFIX; y]。</p>
<h2 id="prompt-tuning">Prompt Tuning</h2>
<p>作者提出了Prompt
Tuning，通过反向传播更新参数来学习prompts，而不是人工设计prompts；同时冻结模型原始权重，只训练prompts参数。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421143331005.png"
alt="image-20240421143331005" />
<figcaption aria-hidden="true">image-20240421143331005</figcaption>
</figure>
<p>该方法可以看作是Prefix
Tuning的简化版本，它给每个任务定义了自己的Prompt，然后拼接到数据上作为输入，但只在输入层加入prompt
tokens，并且不需要加入 MLP 进行调整来解决难训练的问题。</p>
<p>Prompt Tuning 还提出了 Prompt
Ensembling，也就是在一个批次（Batch）里同时训练同一个任务的不同
prompt（即采用多种不同方式询问同一个问题），这样相当于训练了不同模型，比模型集成的成本小多了。</p>
<h2 id="p-tuning">P-Tuning</h2>
<p>该方法将Prompt转换为可以学习的Embedding层，并用MLP+LSTM的方式来对Prompt
Embedding进行一层处理。</p>
<p>相比Prefix Tuning，P-Tuning加入的可微的virtual
token，但仅限于输入层，没有在每一层都加；另外，virtual
token的位置也不一定是前缀，插入的位置是可选的。这里的出发点实际是把传统人工设计模版中的真实token替换成可微的virtual
token。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421143637201.png"
alt="image-20240421143637201" />
<figcaption aria-hidden="true">image-20240421143637201</figcaption>
</figure>
<p>经过预训练的LM的词嵌入已经变得高度离散，如果随机初始化virtual
token，容易优化到局部最优值，而这些virtual
token理论是应该有相关关联的。因此，作者通过实验发现用一个prompt
encoder来编码会收敛更快，效果更好。即用一个LSTM+MLP去编码这些virtual
token以后，再输入到模型。</p>
<h2 id="p-tuning-v2">P-Tuning v2</h2>
<p>之前的Prompt Tuning和P-Tuning等方法存在两个主要的问题：</p>
<ul>
<li>缺乏模型参数规模和任务通用性。
<ul>
<li>缺乏规模通用性：Prompt
Tuning论文中表明当模型规模超过100亿个参数时，提示优化可以与全量微调相媲美。但是对于那些较小的模型（从100M到1B），提示优化和全量微调的表现有很大差异，这大大限制了提示优化的适用性。</li>
<li>缺乏任务普遍性：尽管Prompt Tuning和P-tuning在一些 NLU
基准测试中表现出优势，但提示调优对硬序列标记任务（即序列标注）的有效性尚未得到验证。</li>
</ul></li>
<li>缺少深度提示优化，在Prompt
Tuning和P-tuning中，连续提示只被插入transformer第一层的输入embedding序列中，在接下来的transformer层中，插入连续提示的位置的embedding是由之前的transformer层计算出来的，这可能导致两个可能的优化挑战。
<ul>
<li>由于序列长度的限制，可调参数的数量是有限的。</li>
<li>输入embedding对模型预测只有相对间接的影响。</li>
</ul></li>
</ul>
<p>考虑到这些问题，作者提出了Ptuning v2，它利用深度提示优化（如：Prefix
Tuning），对Prompt
Tuning和P-Tuning进行改进，作为一个跨规模和NLU任务的通用解决方案。</p>
<p>该方法在每一层都加入了Prompts
tokens作为输入，而不是仅仅加在输入层。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421144227395.png"
alt="image-20240421144227395" />
<figcaption aria-hidden="true">image-20240421144227395</figcaption>
</figure>
<p>具体做法基本同Prefix Tuning，可以看作是将文本生成的Prefix
Tuning技术适配到NLU任务中，然后做了一些改进：</p>
<ul>
<li>移除重参数化的编码器。以前的方法利用重参数化功能来提高训练速度和鲁棒性（如：Prefix
Tuning中的MLP、P-Tuning中的LSTM））。在 P-tuning v2
中，作者发现重参数化的改进很小，尤其是对于较小的模型，同时还会影响模型的表现。</li>
<li>针对不同任务采用不同的提示长度。提示长度在提示优化方法的超参数搜索中起着核心作用。在实验中，我们发现不同的理解任务通常用不同的提示长度来实现其最佳性能，这与Prefix-Tuning中的发现一致，不同的文本生成任务可能有不同的最佳提示长度。</li>
<li>引入多任务学习（一种通过共享模型参数来学习多个闲逛任务的方法，利用不同任务之间的知识提高泛化能力。多任务学习的损失函数是每个人物的损失函数加权求和）。先在多任务的Prompt上进行预训练，然后再适配下游任务。多任务学习对我们的方法来说是可选的，但可能是相当有帮助的。一方面，连续提示的随机惯性给优化带来了困难，这可以通过更多的训练数据或与任务相关的无监督预训练来缓解；另一方面，连续提示是跨任务和数据集的特定任务知识的完美载体。我们的实验表明，在一些困难的序列任务中，多任务学习可以作为P-tuning
v2的有益补充。</li>
<li>回归传统的分类标签范式，而不是映射器。标签词映射器（Label Word
Verbalizer）一直是提示优化的核心组成部分，它将one-hot类标签变成有意义的词（例如positive或者negative），以利用预训练语言模型头。尽管它在few-shot设置中具有潜在的必要性，但在全数据监督设置中，Verbalizer并不是必须的。它阻碍了提示调优在我们需要无实际意义的标签和句子嵌入的场景中的应用。因此，P-Tuning
v2回归传统的CLS标签分类范式，采用随机初始化的分类头（Classification
Head）应用于tokens之上，以增强通用性，可以适配到序列标注任务。</li>
</ul>
<h2 id="lora">LoRA</h2>
<p>文的作者认为权重更新的那部分参数矩阵尽管随机投影到较小的子空间，仍然可以有效的学习，可以理解为针对特定的下游任务这些权重矩阵就不要求满秩。</p>
<p>该方法的核心思想就是通过低秩分解来模拟参数的改变量，从而以极小的参数量来实现大模型的间接训练。</p>
<p>在涉及到矩阵相乘的模块，在原始的PLM旁边增加一个新的通路，通过前后两个矩阵A,B相乘，第一个矩阵A负责降维，第二个矩阵B负责升维，中间层维度为r，从而来模拟所谓的本征秩（intrinsic
rank）。</p>
<p>可训练层维度和预训练模型层维度一致为d，先将维度d通过全连接层降维至r，再从r通过全连接层映射回d维度，其中，r&lt;&lt;d，r是矩阵的秩，这样矩阵计算就从d
x d变为d x r + r x d，参数量减少很多。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240421145635079.png"
alt="image-20240421145635079" />
<figcaption aria-hidden="true">image-20240421145635079</figcaption>
</figure>
]]></content>
      <categories>
        <category>ML</category>
        <category>LLM</category>
      </categories>
  </entry>
  <entry>
    <title>LightGCN</title>
    <url>/2023/02/24/LightGCN/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>question: why concentrated to sum</p>
<h2 id="main-contributes">Main contributes</h2>
<ol type="1">
<li><p>We empirically show that two common designs in GCN, feature
transformation and nonlinear activation, have no positive effect on the
effectiveness of collaborative filtering.</p>
<p>GCN is originally proposed for node classification on the attributed
graph, where each node has rich attributes as input features; whereas in
the user-item interaction graph for CF, each node (user or item) is only
described by a one-hot ID, which has no concrete semantics besides being
an identifier.</p></li>
<li><p>Propose LightGCN.</p></li>
</ol>
<h1 id="analyze-about-ngcf">Analyze about NGCF</h1>
<h2 id="brief">Brief</h2>
<p>完全想不起来的话建议先看NGCF的笔记</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213192715250.png"
alt="image-20230213192715250" />
<figcaption aria-hidden="true">image-20230213192715250</figcaption>
</figure>
<p>## Some experiment</p>
<h3 id="method">Method</h3>
<p>Using ablation studies, implement three simplified variants of
NGCF:</p>
<ol type="1">
<li>NGCF-f: which removes the feature transformation matrices <span
class="math inline">\(W1\)</span> and <span
class="math inline">\(W2\)</span>.</li>
<li>NGCF-n: which removes the non-linear activation function $ σ$.</li>
<li>NGCF-fn: which removes both the feature transformation matrices and
non-linear activation function.</li>
</ol>
<p><strong>Note</strong>: Since the core of GCN is to refine embeddings
by propagation, we are more interested in the embedding quality under
the same embedding size. Thus, we change the way of obtaining final
embedding from concatenation (i.e., <span
class="math inline">\(e_u^*=e_u^{(0)}\|e_u^{(1)}\|...\|e_u^{(L)}\)</span>)
to sum(i.e., <span
class="math inline">\(e_u^*=e_u^{(0)}+e_u^{(1)}+...+e_u^{(L)}\)</span>).</p>
<p>This change has little effect on NGCF’s performance but makes the
following ablation studies more indicative of the embedding quality
refined by GCN.</p>
<h3 id="result">Result</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213193937873.png"
alt="image-20230213193937873" />
<figcaption aria-hidden="true">image-20230213193937873</figcaption>
</figure>
<ol type="1">
<li>Adding feature transformation imposes negative effect on NGCF, since
removing it in both models of NGCF and NGCF-n improves the performance
significantly;</li>
<li>Adding nonlinear activation affects slightly when feature
transformation is included, but it imposes negative effect when feature
transformation is disabled.</li>
<li>As a whole, feature transformation and nonlinear activation impose
rather negative effect on NGCF, since by removing them simultaneously,
NGCF-fn demonstrates large improvements over NGCF.</li>
</ol>
<h3 id="conclusion">Conclusion</h3>
<p>The deterioration of NGCF stems from the training
difficulty(underfitting), rather than overfitting, because:</p>
<ol type="1">
<li><p>Such lower training loss of NGCF-fn successfully transfers to
better recommendation accuracy.</p></li>
<li><p>NGCF is more powerful and complex, but it demonstrates higher
training loss and worse generalization performance than NGCF-f.</p></li>
</ol>
<h1 id="model-of-lightgcn">Model of LightGCN</h1>
<p>Consisting four parts:</p>
<ol type="1">
<li>initialize users and items embedding.</li>
<li>Light Graph Convolution (LGC)</li>
<li>Layer Combination</li>
<li>Model Prediction</li>
</ol>
<h2 id="light-graph-convolution-lgc">Light Graph Convolution (LGC)</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213194939594.png"
alt="image-20230213194939594" />
<figcaption aria-hidden="true">image-20230213194939594</figcaption>
</figure>
<p>$ $： symmetric normalization, which can avoid the scale of
embeddings increasing with graph convolution operations. Here can use
other normalization, but symmetric normalization has good
performance.</p>
<p><strong>Note</strong>: Without self-connection, because the layer
combination operation of LightGCN captures the same effect as
self-connections.</p>
<h2 id="layer-combination">Layer Combination</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213195607414.png"
alt="image-20230213195607414" />
<figcaption aria-hidden="true">image-20230213195607414</figcaption>
</figure>
<p><span class="math inline">\(α_k\)</span>can be treated as a
hyperparameter to be tuned manually, or as a model parameter, and
setting <span class="math inline">\(α_k\)</span> uniformly as <span
class="math inline">\(1/(K + 1)\)</span> leads to good performance in
general.</p>
<p>This is probably because the training data does not contain
sufficient signal to learn good α that can generalize to unknown
data.</p>
<p>The reason of using the Layer Combination:</p>
<ol type="1">
<li>With the increasing of the number of layers, the embeddings will be
over-smoothed [27]. Thus simply using the last layer is
problematic.</li>
<li>The embeddings at different layers capture different semantics.</li>
<li>Combining embeddings at different layers with weighted sum captures
the effect of graph convolution with self-connections, an important
trick in GCNs.</li>
</ol>
<h2 id="model-prediction">Model Prediction</h2>
<p>inner product</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213200915280.png"
alt="image-20230213200915280" />
<figcaption aria-hidden="true">image-20230213200915280</figcaption>
</figure>
<h2 id="matrix-form">Matrix form</h2>
<p>Similar to NGCF, and there are some explanations in detail in NGCF
note.</p>
<p>Light Graph Convolution:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213201201896.png"
alt="image-20230213201201896" />
<figcaption aria-hidden="true">image-20230213201201896</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213201107785.png"
alt="image-20230213201107785" />
<figcaption aria-hidden="true">image-20230213201107785</figcaption>
</figure>
<p>Layer combination:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213201221159.png"
alt="image-20230213201221159" />
<figcaption aria-hidden="true">image-20230213201221159</figcaption>
</figure>
<h1 id="analyze-about-lightgcn">Analyze about LightGCN</h1>
<h2 id="relation-with-sgcn">Relation with SGCN</h2>
<p><strong>Purpose</strong>: by doing layer combination, LightGCN
subsumes the effect of self-connection thus there is no need for
LightGCN to add self-connection in adjacency matrix.</p>
<p>SGCN: a recent linear GCN model that integrates self-connection into
graph convolution.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213201725744.png"
alt="image-20230213201725744" />
<figcaption aria-hidden="true">image-20230213201725744</figcaption>
</figure>
<p>In the following analysis, we omit the <span class="math inline">\((D
+ I)^{-\frac{1}{2}}\)</span> terms for simplicity, since they only
re-scale embeddings.</p>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230213212117430.png"
alt="image-20230213212117430" />
<figcaption aria-hidden="true">image-20230213212117430</figcaption>
</figure>
<p>The above derivation shows that, inserting self-connection into A and
propagating embeddings on it, is essentially equivalent to a weighted
sum of the embeddings propagated at each LGC layer.</p>
<p>because <span class="math inline">\(AE^{(0)}=E^{(1)}\)</span>...<span
class="math inline">\(A^KE^{(0)}=E^{(K)}\)</span></p>
<h2 id="relation-with-appnp">Relation with APPNP</h2>
<p><strong>Purpose</strong>: shows the underlying equivalence between
LightGCN and APPNP, thus our LightGCN enjoys the sames benefits in
propagating long-range with controllable overs-moothing.</p>
<p>APPNP: a recent GCN variant that addresses over-smoothing. APPNP
complements each propagation layer with the starting features.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213212642134.png"
alt="image-20230213212642134" />
<figcaption aria-hidden="true">image-20230213212642134</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213212845456.png"
alt="image-20230213212845456" />
<figcaption aria-hidden="true">image-20230213212845456</figcaption>
</figure>
<p>also equivalent to a weighted sum of the embeddings propagated at
each LGC layer.</p>
<h2 id="second-order-embedding-smoothness">Second-Order Embedding
Smoothness</h2>
<p><strong>Purpose</strong>: providing more insights into the working
mechanism of LightGCN.</p>
<p>below is influence from2-order neighbor to target node.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213213500081.png"
alt="image-20230213213500081" />
<figcaption aria-hidden="true">image-20230213213500081</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213213521206.png"
alt="image-20230213213521206" />
<figcaption aria-hidden="true">image-20230213213521206</figcaption>
</figure>
<p><strong>conclusion</strong>: the influence of a second-order neighbor
v on u is determined by</p>
<ol type="1">
<li>the number of co-interacted items, the more the larger.</li>
<li>the popularity of the co-interacted items, the less popularity
(i.e., more indicative of user personalized preference) the larger</li>
<li>the activity of v, the less active the larger.</li>
</ol>
<h1 id="model-train">Model Train</h1>
<h2 id="loss-function">Loss function</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230213213949666.png"
alt="image-20230213213949666" />
<figcaption aria-hidden="true">image-20230213213949666</figcaption>
</figure>
<h2 id="optimizer-adam">Optimizer: Adam</h2>
<h2 id="no-dropout-strategy">No dropout strategy</h2>
<p>The reason is that we do not have feature transformation weight
matrices in LightGCN, thus enforcing L2 regularization on the embedding
layer is sufficient to prevent overfitting.</p>
<h1 id="experiment">Experiment</h1>
<h2 id="compared-with-ngcf">compared with NGCF</h2>
<ol type="1">
<li>LightGCN performs better than NGCF and NGCF-fn, as NGCF-fn still
contains more useless operations than LightGCN.</li>
<li>Increasing the number of layers can improve performance, but the
benefits diminish. Increasing the layer number from 0 to 1 leads to the
largest performance gain, and using a layer number of 3 leads to
satisfactory performance in most cases.</li>
<li>LightGCN consistently obtains lower training loss, which indicates
that LightGCN fits the training data better than NGCF. Moreover, the
lower training loss successfully transfers to better testing accuracy,
indicating the strong generalization power of LightGCN. In contrast, the
higher training loss and lower testing accuracy of NGCF reflect the
practical difficulty to train such a heavy model it well.</li>
</ol>
<h2 id="ablation-and-effectiveness-analyses">Ablation and Effectiveness
Analyses</h2>
<h3 id="impact-of-layer-combination">Impact of Layer Combination</h3>
<h4 id="using-models">Using models:</h4>
<ol type="1">
<li>LightGCN</li>
<li>LightGCN-single: does not use layer combination</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230215151920378.png"
alt="image-20230215151920378" />
<figcaption aria-hidden="true">image-20230215151920378</figcaption>
</figure>
<h4 id="conclusion-1">Conclusion</h4>
<ol type="1">
<li>Focusing on LightGCN-single, we find that its performance first
improves and then drops when the layer number increases from 1 to 4.
This indicates that smoothing a node’s embedding with its first-order
and secondorder neighbors is very useful for CF, but will suffer from
oversmoothing issues when higher-order neighbors are used.</li>
<li>Focusing on LightGCN, we find that its performance gradually
improves with the increasing of layers even using 4 layers. This
justifies the effectiveness of layer combination for addressing
over-smoothing.</li>
<li>we find that LightGCN consistently outperforms LightGCN-single on
Gowalla, but not on AmazonBook and Yelp2018. There are two reason:
<ol type="1">
<li>LightGCN-single is special case of LightGCN that sets αK to 1 and
other αk to 0;</li>
<li>we do not tune the <span class="math inline">\(αk\)</span> and
simply set it as <span class="math inline">\(\frac{1}{K+1}\)</span>
uniformly for LightGCN.</li>
</ol></li>
</ol>
<h3 id="impact-of-symmetric-sqrt-normalization">Impact of Symmetric Sqrt
Normalization</h3>
<h4 id="setting">Setting:</h4>
<ol type="1">
<li>LightGCN-L: normalization only at the left side (i.e., the target
node’s coefficient).</li>
<li>LightGCN-R: the right side (i.e., the neighbor node’s
coefficient).</li>
<li>LightGCN-L1: use L1 normalization( i.e., removing the square
root).</li>
<li>LightGCN-L1-L: use L1 normalization only on the left side.</li>
<li>LightGCN-L1-R: use L1 normalization only on the right side.</li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230215153734701.png"
alt="image-20230215153734701" />
<figcaption aria-hidden="true">image-20230215153734701</figcaption>
</figure>
<h4 id="conclusion-2">Conclusion</h4>
<ol type="1">
<li>The best setting in general is using sqrt normalization at both
sides (i.e., the current design of LightGCN). Removing either side will
drop the performance largely.</li>
<li>The second best setting is using L1 normalization at the left side
only (i.e., LightGCN-L1-L). This is equivalent to normalize the
adjacency matrix as a stochastic matrix by the
in-degree(norm后矩阵无对称性).</li>
<li>Normalizing symmetrically on two sides is helpful for the sqrt
normalization, but will degrade the performance of L1
normalization.</li>
</ol>
<h3 id="analysis-of-embedding-smoothness">Analysis of Embedding
Smoothness</h3>
<p><strong>Object</strong>: Making sure such
smoothing（有点像聚类的感觉） of embeddings is the key reason of
LightGCN’s effectiveness.</p>
<p><strong>Method</strong>: we first define the smoothness of user
embeddings as(用于衡量2-order
neighbor的embedding差别大小，是否合理聚类的感觉):</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230215160123446.png"
alt="image-20230215160123446" />
<figcaption aria-hidden="true">image-20230215160123446</figcaption>
</figure>
<p>where the L2 norm on embeddings is used to eliminate the impact of
the embedding’s scale.</p>
<p><strong>result</strong>:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230215160328103.png"
alt="image-20230215160328103" />
<figcaption aria-hidden="true">image-20230215160328103</figcaption>
</figure>
<p><strong>Conclusion</strong>: the smoothness loss of LightGCN-single
is much lower than that of MF.</p>
<p>This indicates that by conducting light graph convolution, the
embeddings become smoother and more suitable for recommendation.</p>
<h2 id="hyper-parameter-studies">Hyper-parameter Studies</h2>
<p><strong>object</strong>: Ensure the L2 regularization coefficient
<span class="math inline">\(λ\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230215161009450.png"
alt="image-20230215161009450" />
<figcaption aria-hidden="true">image-20230215161009450</figcaption>
</figure>
<p><strong>Conclusion</strong>:</p>
<ol type="1">
<li>LightGCN is relatively insensitive to λ.</li>
<li>Even when λ sets to 0, LightGCN is better than NGCF, which
additionally uses dropout to prevent overfitting. This shows that
LightGCN is less prone to overfitting</li>
<li>When λ is larger than 1e−3, the performance drops quickly, which
indicates that too strong regularization will negatively affect model
normal training and is not encouraged.</li>
</ol>
]]></content>
      <categories>
        <category>RecSys</category>
      </categories>
  </entry>
  <entry>
    <title>Math in DNN</title>
    <url>/2023/06/24/MATHinDNN/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="相似度">相似度</h1>
<h2 id="余弦相似度">余弦相似度</h2>
<h2 id="皮尔逊相关系数">皮尔逊相关系数</h2>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
  </entry>
  <entry>
    <title>NGCF</title>
    <url>/2023/02/24/NGCF/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p>question: example(the Laplacian)</p>
<h2 id="some-definition">Some Definition</h2>
<ol type="1">
<li><p>Recommendation system: Estimate how likely a user will adopt an
item based on the historical interaction like purchase and
click.</p></li>
<li><p>Collaborative filtering(CF): behaviorally similar users would
exhibit similar preference on items.</p>
<p>CF consists of</p>
<ol type="1">
<li><p>embedding: transforms users and items into vectorized
representations. e.g. matrix factorization(MF),deep learning
function...</p></li>
<li><p>interaction modeling: reconstructs historical interactions based
on the embeddings. e.g. inner product, neural function...</p></li>
</ol></li>
<li><p>collaborative signal: signal latent in user-item
interactions</p></li>
</ol>
<h2 id="existing-problem">Existing Problem</h2>
<p>The current embedding process of CF doesn't encode a collaborative
signal. Most of them focus on the descriptive feature(e.g. user id,
attributes). When the embeddings are insufficient in capturing CF, the
methods have to rely on the interaction function to make up for the
deficiency of suboptimal embeddings</p>
<h2 id="main-contribute">Main contribute</h2>
<ol type="1">
<li><p>Highlight the critical importance of explicitly exploiting the
collaborative signal in the embedding function of model-based CF
methods.</p></li>
<li><p>Propose NGCF, a new recommendation framework based on a graph
neural network, which explicitly encodes the collaborative signal in the
form of high-order connectivities by performing embedding
propagation.</p></li>
</ol>
<h1 id="model">Model</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230211111222966.png"
alt="image-20230211111222966" />
<figcaption aria-hidden="true">image-20230211111222966</figcaption>
</figure>
<p>There are three components in the framework:</p>
<ol type="1">
<li>Embedding layer: offers and initialization of user embeddings and
item embeddings;</li>
<li>Multiple embedding propagation layers: refine the embeddings by
injecting high-order connectivity relations;</li>
<li>Prediction layer: aggregates the refined embeddings from different
propagation layers and outputs the affinity score of a user-item
pair.</li>
</ol>
<h2 id="embedding-layer">Embedding layer</h2>
<p>Just initializing user embeddings and item embeddings by using ID or
other features.</p>
<p>Get user embedding <span class="math inline">\(e_i\)</span> and item
embedding <span class="math inline">\(e_u\)</span>.</p>
<h2 id="multiple-embedding-propagation-layers">Multiple Embedding
Propagation Layers</h2>
<h3 id="one-layer-propagation">One layer propagation</h3>
<p>It consists of two parts: Message Construction and Message
aggregation.</p>
<h4 id="message-construction">Message Construction</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230211112521161.png"
alt="image-20230211112521161" />
<figcaption aria-hidden="true">image-20230211112521161</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230211111736136.png"
alt="image-20230211111736136" />
<figcaption aria-hidden="true">image-20230211111736136</figcaption>
</figure>
<p><span class="math inline">\(m_{u&lt;-i}\)</span>: the result of the
message construction module. It is a message embedding that will be used
to update the target node.</p>
<p><span class="math inline">\(e_i\)</span>: Embedding of neighbor
item.</p>
<p><strong>meaning</strong> : encode neighbor item's feature.</p>
<p><span class="math inline">\(e_i⊙e_u\)</span> : element-wise product
of <span class="math inline">\(e_i\)</span> and <span
class="math inline">\(e_u\)</span>.</p>
<p><strong>meaning</strong>: encodes the interaction between <span
class="math inline">\(e_i\)</span> and <span
class="math inline">\(e_u\)</span> into the message and makes the
message dependent on the affinity between <span
class="math inline">\(e_i\)</span> and <span
class="math inline">\(e_j\)</span>.</p>
<p><span class="math inline">\(W_1\)</span>, <span
class="math inline">\(W_2\)</span>: trainable weight matrices， the
shape is (<span class="math inline">\(d&#39;\)</span>, <span
class="math inline">\(d\)</span>), while <span
class="math inline">\(d\)</span> is the size of the initial embedding,
<span class="math inline">\(d&#39;\)</span> is the size of
transformation size.</p>
<p><span class="math inline">\(P_{ui}\)</span>: to control the decay
factor on each propagation on edge (u, i). Here, we set <span
class="math inline">\(P_{ui}\)</span> as <strong>Laplacian norm</strong>
$ $, $ N_u$, $ N_i$ is the first-hot neighbors of user u and item i.
(就是拉普拉斯矩阵归一化！！<span
class="math inline">\(D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\)</span>)</p>
<p><strong>meaning</strong> -From the viewpoint of representation
learning: <span class="math inline">\(P_{ui}\)</span> reflects how much
the historical item contributes to the user preference.</p>
<p>From the viewpoint of the message passing: <span
class="math inline">\(P_{ui}\)</span> can be interpreted as a discount
factor, considering the messages being propagated should decay with the
path length.</p>
<h4 id="message-aggregation">Message Aggregation</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230211151741633.png"
alt="image-20230211151741633" />
<figcaption aria-hidden="true">image-20230211151741633</figcaption>
</figure>
<p><span class="math inline">\(e_u^{(1)}\)</span>: the representation of
user u after 1 propagation layer.</p>
<p><span class="math inline">\(m_{u&lt;-u}\)</span>: self-connection of
u. Here is <span class="math inline">\(W1e_u\)</span>.</p>
<p><strong>meaning</strong>: retain information of original feature.</p>
<p><span class="math inline">\(m_{u&lt;-i}\)</span>： neighbor node
propagation.</p>
<h3 id="high-order-propagation">High-order propagation</h3>
<h4 id="formulate-form">Formulate Form</h4>
<p>By stacking l-embedding propagation layers, a user (and an item) is
capable of receiving the messages propagated from its l-hop neighbors.
The formulates are similar to one-layer propagation.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212105956664.png"
alt="image-20230212105956664" />
<figcaption aria-hidden="true">image-20230212105956664</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212110019741.png"
alt="image-20230212110019741" />
<figcaption aria-hidden="true">image-20230212110019741</figcaption>
</figure>
<h4 id="matrix-form">Matrix Form</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212110725475.png"
alt="image-20230212110725475" />
<figcaption aria-hidden="true">image-20230212110725475</figcaption>
</figure>
<p><span class="math inline">\(E^{(l)}\)</span> : the representations
for users and items obtained after l-layers propagation. Shape is
(N+M,d)</p>
<p>L: Laplacian matrix for the user-item graph.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212111719667.png"
alt="image-20230212111719667" />
<figcaption aria-hidden="true">image-20230212111719667</figcaption>
</figure>
<p>D is the diagonal degree matrix. where <span
class="math inline">\(D_{tt}=\vert N_t\vert\)</span> meaning the
<code>D[t][t]</code> is the number of neighbors' node. The shape is
(N+M, N+M), because there are totally n+m node(including user and
item)</p>
<p>A is the adjacency matrix. The shape of R is (N, M), while the shape
of A is (N+M, N+M).</p>
<p>some extra knowledge: <a
href="https://zhuanlan.zhihu.com/p/362416124/">理解拉普拉斯矩阵</a></p>
<p>I: identity matrix</p>
<h5 id="a-simple-example-for-matrix-form">A simple example for matrix
form:</h5>
<p>Suppose we have 2 users (A, B), 3 items(C, D, E), N=2 and M=3.</p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/D9B00E7DDF74FF18B83E42668335328A.png" alt="D9B00E7DDF74FF18B83E42668335328A" style="zoom: 25%;" /></p>
<p>Let consider this part: <span
class="math inline">\((L+I)E^{(l-1)}W^{(l)}\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/81DBE0096BF060771E3355F2E6A34151.png"
alt="81DBE0096BF060771E3355F2E6A34151" />
<figcaption
aria-hidden="true">81DBE0096BF060771E3355F2E6A34151</figcaption>
</figure>
<p>After calculating <span
class="math inline">\((L+I)E^{(l-1)}\)</span>, we get information on
self-connection and neighbor-propagation (after the Laplacian norm), and
then we can multiply the trainable parameter W1(MLP).</p>
<p>拉普拉斯矩阵归一化的不成熟小理解：</p>
<p>①target node由n个邻居点做贡献，为了避免邻居越多，target
node的value越大的情况，首先除<span
class="math inline">\(\frac{1}{\sqrt{N_n}}\)</span>,
大概也可以理解为邻居越多，每个邻居对其造成的影响越小</p>
<p>②只做一次norm影响对称性，所以为了保持对称性在做一次<span
class="math inline">\(\frac{1}{\sqrt{N_t}}\)</span>,可以理解为neighbor
node有多少邻居对他给到每个邻居的权重有影响，是否能理解为邻居越多说明这个node能提供的信息更普通没价值（例如所有用户购买了水，对推荐系统来说，水能提供的信息就没那么有用）</p>
<p>xxxxxxxxxx class UV_Aggregator(nn.Module):    """   item and user
aggregator: for aggregating embeddings of neighbors (item/user
aggreagator).   """​    def <strong>init</strong>(self, v2e, r2e, u2e,
embed_dim, cuda="cpu", uv=True):        ...​    def forward(self, nodes,
history_uv, history_r):        # create a container for result, shpe of
embed_matrix is (batchsize,embed_dim)        embed_matrix =
torch.empty(len(history_uv), self.embed_dim,
dtype=torch.float).to(self.device)​        # deal with each single item
nodes' neighbors        for i in range(len(history_uv)):          
 history = history_uv[i]            num_histroy_item = len(history)    
       tmp_label = history_r[i]​            # e_uv : turn neighbors(user
node) id to embedding            # uv_rep : turn single node(item node)
to embedding            if self.uv == True:                # user
component                e_uv = self.v2e.weight[history]              
 uv_rep = self.u2e.weight[nodes[i]]            else:                #
item component                e_uv = self.u2e.weight[history]          
     uv_rep = self.v2e.weight[nodes[i]]​            # get rating score
embedding            e_r = self.r2e.weight[tmp_label]            #
concatenated rating and neighbor, and than through two layers mlp to get
fjt            x = torch.cat((e_uv, e_r), 1)            x =
F.relu(self.w_r1(x))​            o_history = F.relu(self.w_r2(x))        
   # calculate neighbor attention and fjt*weight to finish aggregation  
         att_w = self.att(o_history, uv_rep, num_histroy_item)          
 att_history = torch.mm(o_history.t(), att_w)            att_history =
att_history.t()​            embed_matrix[i] = att_history        # result
(batchsize, embed_dim)        to_feats = embed_matrix        return
to_featspython</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/8EE43A6D961CA0F0145CD44C62B9F9BE.png"
alt="8EE43A6D961CA0F0145CD44C62B9F9BE" />
<figcaption
aria-hidden="true">8EE43A6D961CA0F0145CD44C62B9F9BE</figcaption>
</figure>
<p>We get information on the interaction between <span
class="math inline">\(e_i\)</span> and <span
class="math inline">\(e_u\)</span> (after the Laplacian norm), and then
we can multiply the trainable parameter W2(MLP).</p>
<p>Add two parts and through LeakyRelu, we get user or item embedding
after l-layers propagation.</p>
<h2 id="model-prediction">Model Prediction</h2>
<p>Just concatenate all propagation layers' output embedding, and use
inner product to estimate the user's preference towards the target
item.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212173756733.png"
alt="image-20230212173756733" />
<figcaption aria-hidden="true">image-20230212173756733</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212173813003.png"
alt="image-20230212173813003" />
<figcaption aria-hidden="true">image-20230212173813003</figcaption>
</figure>
<h1 id="optimization">Optimization</h1>
<h2 id="loss">Loss</h2>
<p>BPR Loss: assumes that the observed interactions, which are more
reflective of a user’s preferences, should be assigned higher prediction
values than unobserved ones.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212212248890.png"
alt="image-20230212212248890" />
<figcaption aria-hidden="true">image-20230212212248890</figcaption>
</figure>
<h2 id="optimizer-adam">Optimizer: Adam</h2>
<h2 id="model-size">Model Size</h2>
<p>In NGCF, only W1 and W2 in the propagation layer need to be trained,
so has <span class="math inline">\(2Ld_ld_{l-1}\)</span> more
parameters, while L is always smaller than 5 and <span
class="math inline">\(d\)</span> is set as the embedding size(e.g. 64)
which is also small.</p>
<h2 id="message-and-node-dropout">Message and Node Dropout</h2>
<ol type="1">
<li><p><strong>Message dropout</strong>: randomly drops out the outgoing
messages (equal to dropout edge).</p>
<p><strong>meaning</strong>: endows the representations more robustness
against the presence or absence of single connections between users and
items.</p>
<p><strong>example</strong>: For the <span
class="math inline">\(l-th\)</span> propagation layer, we drop out the
messages being propagated, with a probability <span
class="math inline">\(p1\)</span>.</p></li>
<li><p><strong>Node dropout</strong>: randomly blocks a particular node
and discards all its outgoing messages.</p>
<p><strong>meaning</strong>: focuses on reducing the influences of
particular users or items.</p>
<p><strong>example</strong>: For the <span
class="math inline">\(l-th\)</span> propagation layer, we randomly drop
<span class="math inline">\((M + N)p2\)</span> nodes of the Laplacian
matrix, where <span class="math inline">\(p2\)</span> is the dropout
ratio.</p></li>
</ol>
<p>区别：对于message
dropout，计算时node的邻居数、拉普拉斯norm都是正常的，就是更新embedding的时候遗漏了信息，作用是提高一下鲁棒性和容错性；对于Node
dropout，直接在拉普拉斯矩阵中屏蔽若干个node，可能影响临界点数、归一化数值等，在矩阵运算时候就有影响，作用是希望模型不要过于依赖某些特定邻接点，没了部分点依然能正常运行。</p>
<h1 id="experiment">Experiment</h1>
<h2 id="conclusions-from-comparing-with-other-models">Conclusions from
comparing with other models</h2>
<ol type="1">
<li>The inner product is insufficient to capture the complex relations
between users and items.</li>
<li>Nonlinear feature interactions between users and items are
important</li>
<li>Neighbor information can improve embedding learning, and using the
attention mechanism is better than using equal and heuristic
weight.</li>
<li>Considering high-order connectivity or neighbor is better than only
considering first-order neighbor.</li>
<li>that exploiting high-order connectivity greatly facilitates
representation learning for inactive users, as the collaborative signal
can be effectively captured. And the embedding propagation is beneficial
to relatively inactive users.</li>
</ol>
<h2 id="study-for-ngcf">Study for NGCF</h2>
<p>....</p>
<h2 id="effect-of-high-order-connectivity">Effect of High-order
Connectivity</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230212225247958.png"
alt="image-20230212225247958" />
<figcaption aria-hidden="true">image-20230212225247958</figcaption>
</figure>
<ol type="1">
<li>the representations of NGCF-3 exhibit discernible clustering,
meaning that the points with the same colors (<em>i.e.,</em> the items
consumed by the same users) tend to form the clusters.</li>
<li>when stacking three embedding propagation layers, the embeddings of
their historical items tend to be closer. It qualitatively verifies that
the proposed embedding propagation layer is capable of injecting the
explicit collaborative signal (via NGCF-3) into the
representations.</li>
</ol>
]]></content>
      <categories>
        <category>RecSys</category>
      </categories>
  </entry>
  <entry>
    <title>GraphRec</title>
    <url>/2023/02/24/Note_for_GraphRec/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="graphrec">GraphRec</h1>
<h1 id="graphrec-feature">GraphRec feature</h1>
<ol type="1">
<li><p>Can capture both interactions and opinions in user-item
graph.</p></li>
<li><p>Consider different strengths of social relations.</p></li>
<li><p>Use attention mechanism.</p></li>
</ol>
<h1 id="overall-architecture">Overall architecture</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/Snipaste_2023-02-02_15-10-34.png"
alt="Snipaste_2023-02-02_15-10-34" />
<figcaption aria-hidden="true">Snipaste_2023-02-02_15-10-34</figcaption>
</figure>
<h2 id="three-import-module">Three import module:</h2>
<ol type="1">
<li><p>User Modeling: used to compute User Latent Factor(vector
containing many useful information)</p></li>
<li><p>Item Modeling: used to compute Item Latent Factor.</p></li>
<li><p>Rating Prediction: used to predict the item which user would like
to interact with.</p></li>
</ol>
<h1 id="source-code-analyses">Source code analyses</h1>
<h2 id="data">Data</h2>
<h3 id="what-kind-of-datas-we-use"><strong>What kind of datas we
use?</strong></h3>
<ol type="1">
<li><p>User-Item graph: record interation(e.g. purchase) and
opinion(e.g. five star rating) between user and item</p></li>
<li><p>User-User social graph: relationship between user and
user</p></li>
</ol>
<h3 id="how-to-represent-these-datas-in-code"><strong>How to represent
these datas in code?</strong></h3>
<h4 id="user-item-graph">User-Item graph:</h4>
<ol type="1">
<li>history_u_lists, history_ur_lists: user's purchased history (item
set in training set), and his/her rating score (dict)</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history_u_list = &#123;</span><br><span class="line">    user_id1:[item_id1, item_id2, item_id3...],</span><br><span class="line">    user_id2:[item_id4...],</span><br><span class="line">&#125;</span><br><span class="line">history_ur_list = &#123;</span><br><span class="line">    user_id1:[rating_score_u1i1, rating_score_u1i2, rating_score_u1i3...],</span><br><span class="line">    user_id2:[rating_score_u2i4...],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">e.g.</span><br><span class="line">history_u_list = &#123;</span><br><span class="line">    <span class="number">681</span>: [<span class="number">0</span>, <span class="number">156</span>], </span><br><span class="line">    <span class="number">81</span>: [<span class="number">1</span>, <span class="number">41</span>, <span class="number">90</span>]&#125;</span><br><span class="line">history_ur_list = &#123;</span><br><span class="line">    <span class="number">681</span>: [<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    <span class="number">81</span>: [<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>history_v_lists, history_vr_lists: user set (in training set) who
have interacted with the item, and rating score (dict). Similar with
history_u_lists, history_ur_lists but key is item id and value is user
id.</li>
</ol>
<h4 id="user-user-socal-graph">User-User socal graph</h4>
<ol type="1">
<li>social_adj_lists: user's connected neighborhoods</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">social_adj_lists = &#123;</span><br><span class="line">    user_id1:[user_id2, user_id3, user_id4...],</span><br><span class="line">    user_id2:[user_id1...],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="other">other</h4>
<ol type="1">
<li>train_u, train_v, train_r: used for model training, one by one based
on index (user, item, rating)</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_u = [user_id1, user_id2,....]</span><br><span class="line">train_v = [item_id34, item_id1,...]</span><br><span class="line">train_r = [rating_socre_u1i34, rating_socre_u2i1]</span><br><span class="line"><span class="built_in">len</span>(train_u) = <span class="built_in">len</span>(train_v) = <span class="built_in">len</span>(train_r)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li><p>test_u, test_v, test_r: similar with training datas</p></li>
<li><p>ratings_list: rating value from 0.5 to 4.0 (8 opinion embeddings)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;2.0: 0, 1.0: 1, 3.0: 2, 4.0: 3, 2.5: 4, 3.5: 5, 1.5: 6, 0.5: 7&#125;</span><br></pre></td></tr></table></figure></p></li>
</ol>
<h3 id="how-to-pre-process-data"><strong>How to pre-process
data?</strong></h3>
<p>use <code>torch.utils.data.TensorDataset</code> and
<code>torch.utils.data.DataLoader</code> generate
<code>training_dataset</code> and <code>testing_dataset</code> (user,
item, rating)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">support batchsize = <span class="number">5</span></span><br><span class="line">[tensor([<span class="number">409</span>,  <span class="number">88</span>, <span class="number">134</span>, <span class="number">298</span>, <span class="number">340</span>]),                             <span class="comment">#user id</span></span><br><span class="line">tensor([<span class="number">1221</span>,  <span class="number">761</span>,   <span class="number">39</span>,  <span class="number">145</span>,    <span class="number">0</span>]),                         <span class="comment">#item id</span></span><br><span class="line">tensor([<span class="number">1.0000</span>, <span class="number">2.0000</span>, <span class="number">3.5000</span>, <span class="number">0.5000</span>, <span class="number">1.5000</span>, <span class="number">3.5000</span>])        <span class="comment">#rating score</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h2 id="model">Model</h2>
<h3 id="init">Init</h3>
<p>Translate user_id, item_id and rating_id to low-dimension vector,
just random initize, the weight of embedding layers will be trained.</p>
<p>After translate we get</p>
<pre><code>qj-embedding of item vj, 
pi-embedding of user ui, 
er-embedding of rating.</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">u2e = nn.Embedding(num_users, embed_dim).to(device)</span><br><span class="line">v2e = nn.Embedding(num_items, embed_dim).to(device)</span><br><span class="line">r2e = nn.Embedding(num_ratings, embed_dim).to(device)</span><br><span class="line"><span class="built_in">print</span>(u2e, v2e, r2e)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;Output</span></span><br><span class="line"><span class="string">Embedding(705, 64) </span></span><br><span class="line"><span class="string">Embedding(1941, 64) </span></span><br><span class="line"><span class="string">Embedding(8, 64)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>So that, we can easily get embedding through U2e, V2e and r2e.</p>
<h3 id="overall-architecture-1">Overall architecture</h3>
<figure>
<img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/GraphRec.jpg"
alt="GraphRec" />
<figcaption aria-hidden="true">GraphRec</figcaption>
</figure>
<p>GraphRec consist of User Modeling, Item Modeling and Rating
Prediction. The forward code of GraphRec is as follow:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GraphRec</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, enc_u, enc_v_history, r2e</span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes_u, nodes_v</span>):</span><br><span class="line">        <span class="comment"># nodes_u : [128] 128(batchsize) user id</span></span><br><span class="line">        <span class="comment"># nodes_v : [128] 128(batchsize) item id</span></span><br><span class="line">        <span class="comment"># self.enc_u is the User Modeling part(including Item Aggregation and Social Aggregation )</span></span><br><span class="line">        <span class="comment"># self.enc_v_history is the Item Modeling part(User Aggregation)</span></span><br><span class="line">        embeds_u = self.enc_u(nodes_u)</span><br><span class="line">        embeds_v = self.enc_v_history(nodes_v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># After aggregation information, forward two layer MLP， and get the Latent vector of user and item</span></span><br><span class="line">        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))</span><br><span class="line">        x_u = F.dropout(x_u, training=self.training)</span><br><span class="line">        x_u = self.w_ur2(x_u)</span><br><span class="line">        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))</span><br><span class="line">        x_v = F.dropout(x_v, training=self.training)</span><br><span class="line">        x_v = self.w_vr2(x_v)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># concatenated user vector and item vector, use three layer MLP to predict</span></span><br><span class="line">        x_uv = torch.cat((x_u, x_v), <span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.bn3(self.w_uv1(x_uv)))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = F.relu(self.bn4(self.w_uv2(x)))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        scores = self.w_uv3(x)</span><br><span class="line">        <span class="keyword">return</span> scores.squeeze()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, nodes_u, nodes_v, labels_list</span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>full code of GraphRec class</p>
<details>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GraphRec</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, enc_u, enc_v_history, r2e</span>):</span><br><span class="line">        <span class="built_in">super</span>(GraphRec, self).__init__()</span><br><span class="line">        self.enc_u = enc_u</span><br><span class="line">        self.enc_v_history = enc_v_history</span><br><span class="line">        self.embed_dim = enc_u.embed_dim</span><br><span class="line"></span><br><span class="line">        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)</span><br><span class="line">        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)</span><br><span class="line">        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)</span><br><span class="line">        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)</span><br><span class="line">        self.w_uv1 = nn.Linear(self.embed_dim * <span class="number">2</span>, self.embed_dim)</span><br><span class="line">        self.w_uv2 = nn.Linear(self.embed_dim, <span class="number">16</span>)</span><br><span class="line">        self.w_uv3 = nn.Linear(<span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line">        self.r2e = r2e</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm1d(<span class="number">16</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes_u, nodes_v</span>):</span><br><span class="line">        embeds_u = self.enc_u(nodes_u)</span><br><span class="line">        embeds_v = self.enc_v_history(nodes_v)</span><br><span class="line"></span><br><span class="line">        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))</span><br><span class="line">        x_u = F.dropout(x_u, training=self.training)</span><br><span class="line">        x_u = self.w_ur2(x_u)</span><br><span class="line">        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))</span><br><span class="line">        x_v = F.dropout(x_v, training=self.training)</span><br><span class="line">        x_v = self.w_vr2(x_v)</span><br><span class="line"></span><br><span class="line">        x_uv = torch.cat((x_u, x_v), <span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.bn3(self.w_uv1(x_uv)))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = F.relu(self.bn4(self.w_uv2(x)))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        scores = self.w_uv3(x)</span><br><span class="line">        <span class="keyword">return</span> scores.squeeze()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, nodes_u, nodes_v, labels_list</span>):</span><br><span class="line">        scores = self.forward(nodes_u, nodes_v)</span><br><span class="line">        <span class="keyword">return</span> self.criterion(scores, labels_list)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>
<h3 id="user-modeling">User Modeling</h3>
<p>It contain Item Aggregation and Social Aggregation</p>
<p>在这里本质上是先做了一层Item
Aggregation之后，用得到的结果再做一层Social Aggregation 所以这里的Item
Aggregation，本质上是Social Aggregation中的self-connection</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Social_Encoder</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, embed_dim, social_adj_lists, aggregator, base_model=<span class="literal">None</span>, cuda=<span class="string">&quot;cpu&quot;</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># to_neighs is a list which element is list recording social neighbor node, and len(list) is batchsize,</span></span><br><span class="line">        to_neighs = []</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">            to_neighs.append(self.social_adj_lists[<span class="built_in">int</span>(node)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Social aggregation</span></span><br><span class="line">        neigh_feats = self.aggregator.forward(nodes, to_neighs)  <span class="comment"># user-user network</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Item aggregation</span></span><br><span class="line">        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)</span><br><span class="line">        self_feats = self_feats.t()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># self-connection could be considered.</span></span><br><span class="line">        <span class="comment"># Concatenate Item Aggregation and Social Aggregation, and through one layer MLP</span></span><br><span class="line">        combined = torch.cat([self_feats, neigh_feats], dim=<span class="number">1</span>)</span><br><span class="line">        combined = F.relu(self.linear1(combined))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> combined</span><br></pre></td></tr></table></figure>
<p>full code of User Modeling</p>
<details>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Social_Encoder</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, embed_dim, social_adj_lists, aggregator, base_model=<span class="literal">None</span>, cuda=<span class="string">&quot;cpu&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Social_Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features = features</span><br><span class="line">        self.social_adj_lists = social_adj_lists</span><br><span class="line">        self.aggregator = aggregator</span><br><span class="line">        <span class="keyword">if</span> base_model != <span class="literal">None</span>:</span><br><span class="line">            self.base_model = base_model</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.device = cuda</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">2</span> * self.embed_dim, self.embed_dim)  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># to_neighs is a list which element is list recording social neighbor node, and len(list) is batchsize,</span></span><br><span class="line">        to_neighs = []</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">            to_neighs.append(self.social_adj_lists[<span class="built_in">int</span>(node)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Item aggregation</span></span><br><span class="line">        neigh_feats = self.aggregator.forward(nodes, to_neighs)  <span class="comment"># user-user network</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Social aggregation</span></span><br><span class="line">        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)</span><br><span class="line">        self_feats = self_feats.t()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># self-connection could be considered.</span></span><br><span class="line">        <span class="comment"># Concatenate Item Aggregation and Social Aggregation, and through one layer MLP</span></span><br><span class="line">        combined = torch.cat([self_feats, neigh_feats], dim=<span class="number">1</span>)</span><br><span class="line">        combined = F.relu(self.linear1(combined))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> combined</span><br></pre></td></tr></table></figure>
</details>
<h4 id="item-aggregation">Item Aggregation</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UV_Encoder</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=<span class="string">&quot;cpu&quot;</span>, uv=<span class="literal">True</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes</span>):</span><br><span class="line">        tmp_history_uv = []</span><br><span class="line">        tmp_history_r = []</span><br><span class="line"></span><br><span class="line">        <span class="comment">#get nodes(batch) neighbors</span></span><br><span class="line">        <span class="comment">#tmp_history_uv is a list which len is 128,while it&#x27;s element is also a list meaning that the each node&#x27;s(in batch) neighbor item id list</span></span><br><span class="line">        <span class="comment">#tmp_history_r is similar with tmp_history_uv, but record the rating score instead of item id</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">            tmp_history_uv.append(self.history_uv_lists[<span class="built_in">int</span>(node)])</span><br><span class="line">            tmp_history_r.append(self.history_r_lists[<span class="built_in">int</span>(node)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># after neigh aggregation</span></span><br><span class="line">        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  <span class="comment"># user-item network</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># id to embedding (features : u2e)</span></span><br><span class="line">        self_feats = self.features.weight[nodes]</span><br><span class="line">        <span class="comment"># self-connection could be considered.</span></span><br><span class="line">        combined = torch.cat([self_feats, neigh_feats], dim=<span class="number">1</span>)</span><br><span class="line">        combined = F.relu(self.linear1(combined))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> combined</span><br></pre></td></tr></table></figure>
<p>And the <code>self.aggregator</code> in neigh aggregation is:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UV_Aggregator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, v2e, r2e, u2e, embed_dim, cuda=<span class="string">&quot;cpu&quot;</span>, uv=<span class="literal">True</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes, history_uv, history_r</span>):</span><br><span class="line">        <span class="comment"># create a container for result, shpe of embed_matrix is (batchsize,embed_dim)</span></span><br><span class="line">        embed_matrix = torch.empty(<span class="built_in">len</span>(history_uv), self.embed_dim, dtype=torch.<span class="built_in">float</span>).to(self.device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deal with each single nodes&#x27; neighbors</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(history_uv)):</span><br><span class="line">            history = history_uv[i]</span><br><span class="line">            num_histroy_item = <span class="built_in">len</span>(history)</span><br><span class="line">            tmp_label = history_r[i]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># e_uv : turn neighbors id to embedding</span></span><br><span class="line">            <span class="comment"># uv_rep : turn single node to embedding</span></span><br><span class="line">            <span class="keyword">if</span> self.uv == <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># user component</span></span><br><span class="line">                e_uv = self.v2e.weight[history]</span><br><span class="line">                uv_rep = self.u2e.weight[nodes[i]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># item component</span></span><br><span class="line">                e_uv = self.u2e.weight[history]</span><br><span class="line">                uv_rep = self.v2e.weight[nodes[i]]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># get rating score embedding</span></span><br><span class="line">            e_r = self.r2e.weight[tmp_label]</span><br><span class="line">            <span class="comment"># concatenated rating and neighbor, and than through two layers mlp to get xia</span></span><br><span class="line">            x = torch.cat((e_uv, e_r), <span class="number">1</span>)</span><br><span class="line">            x = F.relu(self.w_r1(x))</span><br><span class="line"></span><br><span class="line">            o_history = F.relu(self.w_r2(x))</span><br><span class="line">            <span class="comment"># calculate neighbor attention and xia*weight to finish aggregation</span></span><br><span class="line">            att_w = self.att(o_history, uv_rep, num_histroy_item)</span><br><span class="line">            att_history = torch.mm(o_history.t(), att_w)</span><br><span class="line">            att_history = att_history.t()</span><br><span class="line"></span><br><span class="line">            embed_matrix[i] = att_history</span><br><span class="line">        <span class="comment"># result (batchsize, embed_dim)</span></span><br><span class="line">        to_feats = embed_matrix</span><br><span class="line">        <span class="keyword">return</span> to_feats</span><br></pre></td></tr></table></figure>
<p>While <code>self.att</code> is:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dims</span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, node1, u_rep, num_neighs</span>):</span><br><span class="line">        <span class="comment"># pi</span></span><br><span class="line">        uv_reps = u_rep.repeat(num_neighs, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># concatenated neighbot and pi</span></span><br><span class="line">        x = torch.cat((node1, uv_reps), <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># through 3 layers MLP</span></span><br><span class="line">        x = F.relu(self.att1(x))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = F.relu(self.att2(x))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = self.att3(x)</span><br><span class="line">        <span class="comment"># get weights</span></span><br><span class="line">        att = F.softmax(x, dim=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> att</span><br></pre></td></tr></table></figure>
<h4 id="social-aggregation">Social Aggregation</h4>
<p>use the result of Item Aggregation and pi as input</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Social_Aggregator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Social Aggregator: for aggregating embeddings of social neighbors.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, u2e, embed_dim, cuda=<span class="string">&quot;cpu&quot;</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes, to_neighs</span>):</span><br><span class="line">        <span class="comment">#return a uninitialize matrix as result container, which shape is (batchsize, embed_dim)</span></span><br><span class="line">        embed_matrix = torch.empty(<span class="built_in">len</span>(nodes), self.embed_dim, dtype=torch.<span class="built_in">float</span>).to(self.device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nodes)):</span><br><span class="line">            <span class="comment"># get social graph neighbor</span></span><br><span class="line">            tmp_adj = to_neighs[i]</span><br><span class="line">            num_neighs = <span class="built_in">len</span>(tmp_adj)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># fase : can use user embedding instead of result of item aggregation to improve speed</span></span><br><span class="line">            <span class="comment"># e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding </span></span><br><span class="line">            <span class="comment"># slow: item-space user latent factor (item aggregation)</span></span><br><span class="line">            feature_neigbhors = self.features(torch.LongTensor(<span class="built_in">list</span>(tmp_adj)).to(self.device))</span><br><span class="line">            e_u = torch.t(feature_neigbhors)</span><br><span class="line"></span><br><span class="line">            u_rep = self.u2e.weight[nodes[i]]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># concatenated node embedding and neigbor vector (result of item aggregation) </span></span><br><span class="line">            <span class="comment"># and than through MLPs and Softmax to calculate weights</span></span><br><span class="line">            att_w = self.att(e_u, u_rep, num_neighs)</span><br><span class="line">            <span class="comment"># weight*neighbor vector</span></span><br><span class="line">            att_history = torch.mm(e_u.t(), att_w).t()</span><br><span class="line">            embed_matrix[i] = att_history</span><br><span class="line">        to_feats = embed_matrix</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> to_feats</span><br></pre></td></tr></table></figure>
<h3 id="item-modeling">Item Modeling</h3>
<p>Similar with the Item Aggregation of User Modeling</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UV_Encoder</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=<span class="string">&quot;cpu&quot;</span>, uv=<span class="literal">True</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes</span>):</span><br><span class="line">        tmp_history_uv = []</span><br><span class="line">        tmp_history_r = []</span><br><span class="line"></span><br><span class="line">        <span class="comment">#get nodes(batch) neighbors of item</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">            tmp_history_uv.append(self.history_uv_lists[<span class="built_in">int</span>(node)])</span><br><span class="line">            tmp_history_r.append(self.history_r_lists[<span class="built_in">int</span>(node)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># after neigh aggregation</span></span><br><span class="line">        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  <span class="comment"># user-item network</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># id to embedding (features : v2e)</span></span><br><span class="line">        self_feats = self.features.weight[nodes]</span><br><span class="line">        <span class="comment"># self-connection could be considered.</span></span><br><span class="line">        combined = torch.cat([self_feats, neigh_feats], dim=<span class="number">1</span>)</span><br><span class="line">        combined = F.relu(self.linear1(combined))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> combined</span><br></pre></td></tr></table></figure>
<p>And the <code>self.aggregator</code> in neigh aggregation is:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UV_Aggregator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, v2e, r2e, u2e, embed_dim, cuda=<span class="string">&quot;cpu&quot;</span>, uv=<span class="literal">True</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, nodes, history_uv, history_r</span>):</span><br><span class="line">        <span class="comment"># create a container for result, shpe of embed_matrix is (batchsize,embed_dim)</span></span><br><span class="line">        embed_matrix = torch.empty(<span class="built_in">len</span>(history_uv), self.embed_dim, dtype=torch.<span class="built_in">float</span>).to(self.device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deal with each single item nodes&#x27; neighbors</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(history_uv)):</span><br><span class="line">            history = history_uv[i]</span><br><span class="line">            num_histroy_item = <span class="built_in">len</span>(history)</span><br><span class="line">            tmp_label = history_r[i]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># e_uv : turn neighbors(user node) id to embedding</span></span><br><span class="line">            <span class="comment"># uv_rep : turn single node(item node) to embedding</span></span><br><span class="line">            <span class="keyword">if</span> self.uv == <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># user component</span></span><br><span class="line">                e_uv = self.v2e.weight[history]</span><br><span class="line">                uv_rep = self.u2e.weight[nodes[i]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># item component</span></span><br><span class="line">                e_uv = self.u2e.weight[history]</span><br><span class="line">                uv_rep = self.v2e.weight[nodes[i]]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># get rating score embedding</span></span><br><span class="line">            e_r = self.r2e.weight[tmp_label]</span><br><span class="line">            <span class="comment"># concatenated rating and neighbor, and than through two layers mlp to get fjt</span></span><br><span class="line">            x = torch.cat((e_uv, e_r), <span class="number">1</span>)</span><br><span class="line">            x = F.relu(self.w_r1(x))</span><br><span class="line"></span><br><span class="line">            o_history = F.relu(self.w_r2(x))</span><br><span class="line">            <span class="comment"># calculate neighbor attention and fjt*weight to finish aggregation</span></span><br><span class="line">            att_w = self.att(o_history, uv_rep, num_histroy_item)</span><br><span class="line">            att_history = torch.mm(o_history.t(), att_w)</span><br><span class="line">            att_history = att_history.t()</span><br><span class="line"></span><br><span class="line">            embed_matrix[i] = att_history</span><br><span class="line">        <span class="comment"># result (batchsize, embed_dim)</span></span><br><span class="line">        to_feats = embed_matrix</span><br><span class="line">        <span class="keyword">return</span> to_feats</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>SocialRec</category>
      </categories>
  </entry>
  <entry>
    <title>tutorial of PyG</title>
    <url>/2023/05/23/PyG/</url>
    <content><![CDATA[<p>Some simple knowledge of PyG</p>
<span id="more"></span>
<h1 id="basic">Basic</h1>
<h2 id="data">Data</h2>
<p>A single graph in PyG is described by an instance of
<code>torch_geometric.data.Data</code>, which holds the following
attributes by default:</p>
<ol type="1">
<li><p><code>data.x</code>: Node feature matrix
<code>[num_nodes,num_node_features_dim]</code></p></li>
<li><p><code>data.edge_index</code>: Graph connectivity in <a
href="https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs">COO
format</a> with shape <code>[2, num_edges]</code> and type
<code>torch.long</code></p></li>
<li><p><code>data.edge_attr</code>: Edge feature matrix with shape
<code>[num_edges, num_edge_features_dim]</code></p></li>
<li><p><code>data.y</code>: Target to train(label). <em>e.g.</em>,
node-level targets of shape <code>[num_nodes, *]</code> or graph-level
targets of shape <code>[1, *]</code></p>
<p>...</p></li>
</ol>
<p>example:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230523172031612.png"
alt="image-20230523172031612" />
<figcaption aria-hidden="true">image-20230523172031612</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                           [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                           [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                           [<span class="number">2</span>, <span class="number">1</span>]], dtype=torch.long)</span><br><span class="line">x = torch.tensor([[-<span class="number">1</span>], [<span class="number">0</span>], [<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##t()会让原变量和新变量直接有依赖（类似浅拷贝），contiguous()断开依赖</span></span><br><span class="line">data = Data(x=x, edge_index=edge_index.t().contiguous())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Data(edge_index=[<span class="number">2</span>, <span class="number">4</span>], x=[<span class="number">3</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><strong>Note</strong>： Although the graph has only two edges, we
need to define four index tuples to account for both directions of an
edge.</p>
<p>operation</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(data.keys)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;x&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[-<span class="number">1.0</span>],</span><br><span class="line">            [<span class="number">0.0</span>],</span><br><span class="line">            [<span class="number">1.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key, item <span class="keyword">in</span> data:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span> found in data&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x found <span class="keyword">in</span> data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>edge_index found <span class="keyword">in</span> data</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;edge_attr&#x27;</span> <span class="keyword">in</span> data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.num_nodes</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">3</span></span><br><span class="line"></span><br><span class="line">data.num_edges</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">4</span></span><br><span class="line"></span><br><span class="line">data.num_node_features</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1</span></span><br><span class="line"></span><br><span class="line">data.has_isolated_nodes()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.has_self_loops()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line">data.is_directed()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transfer data object to GPU.</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">data = data.to(device)</span><br></pre></td></tr></table></figure>
<h2 id="minibatch">Minibatch</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> TUDataset</span><br><span class="line"><span class="keyword">from</span> torch_geometric.loader <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=<span class="string">&#x27;/tmp/ENZYMES&#x27;</span>, name=<span class="string">&#x27;ENZYMES&#x27;</span>, use_node_attr=<span class="literal">True</span>)</span><br><span class="line">loader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">    batch</span><br><span class="line">    &gt;&gt;&gt; DataBatch(batch=[<span class="number">1082</span>], edge_index=[<span class="number">2</span>, <span class="number">4066</span>], x=[<span class="number">1082</span>, <span class="number">21</span>], y=[<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">    batch.num_graphs</span><br><span class="line">    &gt;&gt;&gt; <span class="number">32</span></span><br></pre></td></tr></table></figure>
<h1 id="message-passing-network">Message Passing Network</h1>
<ul>
<li><a
href="https://blog.csdn.net/weixin_39925939/article/details/121360884">(149条消息)
pytorch geometric教程一: 消息传递源码详解（MESSAGE
PASSING）+实例_每天都想躺平的大喵的博客-CSDN博客</a></li>
</ul>
]]></content>
      <categories>
        <category>GNN</category>
        <category>Frame</category>
      </categories>
  </entry>
  <entry>
    <title>Python Basic</title>
    <url>/2023/07/11/PythonBasic/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="sort">sort</h1>
<ol type="1">
<li>怎么让数组在第一维度正序，第二维度倒序</li>
</ol>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">li.sort(key = <span class="keyword">lambda</span> x:(x[<span class="number">0</span>],-x[<span class="number">1</span>]),reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>王树森推荐系统公开课</title>
    <url>/2023/03/13/Recommendation-WangShusen/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="基本概念">基本概念</h1>
<h2 id="指标">指标</h2>
<h3 id="消费指标">消费指标</h3>
<p>点击率=点击次数/曝光次数</p>
<p>点赞量=点赞次数/点击次数</p>
<p>收藏率=收藏次数/点击次数</p>
<p>转发率=转发次数/点击次数</p>
<p>阅读完成率=滑动到底次数/点击次数<span class="math inline">\(\times
f(笔记长度)\)</span></p>
<h3 id="北极星指标">北极星指标</h3>
<p>用户规模：日活用户数（DAU），月活用户数（MAU）</p>
<p>消费：人均使用推荐时长、人均阅读笔记数量</p>
<p>发布： 发布渗透率、人均发布量</p>
<h2 id="推荐系统链路">推荐系统链路</h2>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230313220835272.png"
alt="image-20230313220835272" />
<figcaption aria-hidden="true">image-20230313220835272</figcaption>
</figure>
<ol type="1">
<li>召回：快速从海量数据中取回几千个用户可能感兴趣的物品。</li>
<li>粗排：用小规模的模型的神经网络给召回的物品打分，然后做截断，选出分数最高的几百个物品。</li>
<li>精排：
用大规模神经网络给粗排选中的几百个物品打分，可以做截断，也可以不做截断。</li>
<li>重排：
对精排结果做多样性抽样，得到几十个物品，然后用规则调整物品的排序。</li>
</ol>
<h2 id="ab测试">AB测试</h2>
<p>完成离线测试后，使用线上小流量AB测试考察指标，或者用AB测试调参（GNN深度）</p>
<h3 id="随机分桶">随机分桶</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20231119172737630.png"
alt="image-20231119172737630" />
<figcaption aria-hidden="true">image-20231119172737630</figcaption>
</figure>
<p>在不同的桶上使用不同的策略或参数实验。</p>
<h3 id="分层实验">分层实验</h3>
<p>不同的部门都需要做AB测试，每个部门对应一个层，分层实验满足：</p>
<ol type="1">
<li><strong>同层互斥</strong>：同一个部门做实验不能使用同一个桶；例：GNN实验占了召回层4个桶，其它召回实验只能用剩下的6个桶。</li>
<li><strong>不同层正交</strong>：每一层独立随机对用户做分桶。每一层都可以独立用100%的用户做实验。</li>
</ol>
<h1 id="召回">召回</h1>
<h2 id="协同过滤">协同过滤</h2>
<h3 id="基于物品的协同过滤-itemcf">基于物品的协同过滤 ItemCF</h3>
<p>基本思想：如果用户喜欢item1,而item1与item2相似，那么用户很可能喜欢item2.</p>
<h4 id="基本结构">基本结构：</h4>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230313223949470.png"
alt="image-20230313223949470" />
<figcaption aria-hidden="true">image-20230313223949470</figcaption>
</figure>
<p>我们从用户历史互动知道用户对<span
class="math inline">\(item_j\)</span>，感兴趣利用下面公式计算对候选物品的兴趣分数
<span class="math display">\[
\sum_jlike(user,item_j)\times sim(item_j,item)
\]</span> 在这个例子中，用户对候选item的兴趣是：<span
class="math inline">\(2\times
0.1+1\times0.4+4\times0.2+3\times0.6=3.2\)</span>,我们计算所有item的分数，然后返回分数最高的若干个item</p>
<h5 id="计算item相似度">计算item相似度</h5>
<p>可以通过与item交互过的用户重合度计算item相似度（其中一种方法，也可以用KG）</p>
<ol type="1">
<li>方法1：不考虑用户对物品的喜欢程度</li>
</ol>
<p><span class="math display">\[
sim(i_1,i_2) = \frac{|W1 \cap W2|}{\sqrt[2]{|W1|\cdot |W2|}}
\]</span></p>
<p>其中，喜欢物品<span class="math inline">\(i_1\)</span>的用户记作<span
class="math inline">\(W_1\)</span>,喜欢物品<span
class="math inline">\(i_2\)</span>的用户记作<span
class="math inline">\(W_2\)</span>.</p>
<ol start="2" type="1">
<li><p>方法2： 考虑用户对物品的喜欢程度,使用余弦相似度！</p>
<p>把每个item用向量表示 <span class="math display">\[
i_1=[like(u_1,i_1),like(u_2,i_1),\cdots ,like(u_n,i_1)] \space u_n\in W
\]</span></p>
<p><span class="math display">\[
i_2=[like(u_1,i_2),like(u_2,i_2),\cdots ,like(u_n,i_2)] \space u_n\in W
\]</span></p>
<p><span class="math display">\[
W=W_1\cup W_2
\]</span></p>
<p>我们使用余弦相似度计算： <span class="math display">\[
similarity=cos(\theta) = \frac{A\cdot B}{||A||\space ||B||}
\]</span> 如果有用户k只喜欢其中一个物品:只喜欢<span
class="math inline">\(i_1\)</span>不喜欢<span
class="math inline">\(i_2\)</span>,那么<span
class="math inline">\(i_2[k]=0\)</span>，所以点乘后第k项为0，所以点乘只与同时喜欢<span
class="math inline">\(i_1,i_2\)</span>的用户有关系，如下面公式 <span
class="math display">\[
sim(i_1,i_2) = \frac{\sum_{v\in V}like(v,i_i)\cdot
like(v,i_2)}{\sqrt[2]{\sum_{u_1\in
W_1}like^2(u_1,i_1)}\sqrt[2]{\sum_{u_2\in W_2}like^2(u_2,i_2)}}
\]</span></p></li>
<li></li>
<li><p>皮尔逊系数 <span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_i)(R_{j,p}-\bar
R_j)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_i)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_j)^2}}
\]</span></p></li>
</ol>
<h4 id="运作基本流程">运作基本流程</h4>
<ol type="1">
<li><p>实现做离线计算，预先计算两个索引：</p>
<ol type="1">
<li><p>“user2item”：记录每个用户最近点击交互过的n个物品ID（lastN）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example 不一定是公司真实的保存方式</span></span><br><span class="line">user2item=&#123;</span><br><span class="line">    <span class="string">&#x27;u1&#x27;</span>:[[i1,like(u1,i1)],[i2,like(u1,i2)],...,[<span class="keyword">in</span>,like(u1,<span class="keyword">in</span>)]]</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>"item2item":计算物品之间两两相似度，记录每个物品最相似的k个物品。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">item2item=&#123;</span><br><span class="line">	#target item:[[similar item, similarity score]...]</span><br><span class="line">	&#x27;i1&#x27;:[[i2,0.9],[i6,0.88]...]</span><br><span class="line">	&#x27;i2&#x27;:...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol></li>
<li><p>线上做召回</p>
<ol type="1">
<li>给定用户ID，通过“user2item”找到用户近期感兴趣的物品列表(last-n)</li>
<li>对于last-n列表中每个物品，通过“item2item"找到top-k相似物品。现在有1个user，n个互动物品，nxk个候选物品。</li>
<li>计算候选物品兴趣分数</li>
<li>返回分数最高的100个物品作为推荐结果</li>
</ol></li>
</ol>
<h3 id="swing召回通道">Swing召回通道</h3>
<p>如果两个Item的重合用户来源于一个小圈子（微信群），一个小圈子用户同时与两个Item交互，不能说明两个Item相似，如果很多不相关的用户交互两个Item，说明Item相似。</p>
<h4 id="基本结构-1">基本结构</h4>
<ol type="1">
<li>计算用户重合度</li>
</ol>
<p>用户<span class="math display">\[u_1\]</span>喜欢的物品记作集合<span
class="math display">\[J_1\]</span></p>
<p>用户<span class="math display">\[u_2\]</span>喜欢的物品记作集合<span
class="math display">\[J_2\]</span></p>
<p>定义两个用户的重合度： <span class="math display">\[
overlap(u_1,u_2)=|J_1\cap J_2|
\]</span> 用户<span class="math display">\[u_1\]</span>和<span
class="math display">\[u_2\]</span>的重合度高，则他们可能来自一个小圈子，要降低他们的权重。</p>
<ol start="2" type="1">
<li>计算物品相似度</li>
</ol>
<p>喜欢物品<span class="math display">\[i_1\]</span>的用户记作集合<span
class="math display">\[W_1\]</span></p>
<p>喜欢物品<span class="math display">\[i_2\]</span>的用户记作集合<span
class="math display">\[W_2\]</span> <span class="math display">\[
V=W_1\cap W_2
\]</span></p>
<p><span class="math display">\[
sim(i_1,i_2) = \sum_{u_1\in V}\sum_{u_2\in
V}\frac{1}{\alpha+overlap(u_1,u_2)}
\]</span></p>
<p>u1u2都对物品i1i2感兴趣，这样的用户越多，说明物品越相似</p>
<p><span class="math display">\[\alpha\]</span>是超参数</p>
<h3 id="基于用户的协同过滤usercf">基于用户的协同过滤（UserCF）</h3>
<p>假设：u1与u2兴趣十分相似，u1可能会对u2交互的item感兴趣</p>
<p>何为兴趣相似：</p>
<ol type="1">
<li>点击、点赞、收藏、转发的笔记有很大重合</li>
<li>关注的作者有很大的重合</li>
</ol>
<h4 id="基本结构-2">基本结构</h4>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230525170605162.png"
alt="image-20230525170605162" /> <span class="math display">\[
\sum_jsim(user,user_j)\times like(user_j,item)
\]</span></p>
<h5 id="计算user相似度">计算User相似度</h5>
<ol type="1">
<li><p>计算User相似度</p>
<p>把每个用户表示为一个稀疏向量，向量每个元素对应一个物品。相似度sim就是两个向量夹角的余弦。<span
class="math display">\[u_1\cdot u_2\]</span>结果就是<span
class="math display">\[|I|\]</span></p></li>
</ol>
<p><span class="math display">\[
sim(u_1,u_2) = \frac{|I|}{\sqrt{|J_1|\cdot|J_2|}}
\]</span></p>
<p><span class="math display">\[J_1\]</span>: 用户<span
class="math display">\[u_1\]</span>喜欢的物品集合</p>
<p><span class="math display">\[J_2\]</span>: 用户<span
class="math display">\[u_2\]</span>喜欢的物品集合</p>
<p><span class="math display">\[I\]</span>：<span
class="math display">\[J_1\cap J_2\]</span></p>
<p>|*|:集合的大小</p>
<p><span
class="math display">\[sim(u_1,u_2)\in[0,1]\]</span>,越大代表用户越相似</p>
<ol start="2" type="1">
<li>降低热门物品权重</li>
</ol>
<p>大家都喜欢哈利波特，哈利波特对用户相似度计算意义小,所以我们降低热门物品权重
<span class="math display">\[
sim(u_1,u_2) = \frac{\sum_{l\in I}weight(l)}{\sqrt{|J_1|\cdot|J_2|}}
\]</span></p>
<p><span class="math display">\[
weight(l) = \frac{1}{log(1+n_l)}
\]</span></p>
<p><span class="math display">\[n_l\]</span>:
喜欢物品l的用户数量，反应物品的热门程度。<span
class="math display">\[n_l\]</span>越大，<span
class="math display">\[log(1+n_l)\]</span>越大，权重越小</p>
<h4 id="运作基本流程-1">运作基本流程</h4>
<ol type="1">
<li><p>实现做离线计算，预先计算两个索引：</p>
<ol type="1">
<li><p>“user2item”：记录每个用户最近点击交互过的n个物品ID（lastN）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example 不一定是公司真实的保存方式</span></span><br><span class="line">user2item=&#123;</span><br><span class="line">    <span class="string">&#x27;u1&#x27;</span>:[[i1,like(u1,i1)],[i2,like(u1,i2)],...,[<span class="keyword">in</span>,like(u1,<span class="keyword">in</span>)]]</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>"user2user":计算用户之间两两相似度，记录每个用户最相似的k个用户。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user2user=&#123;</span><br><span class="line">	#target user:[[similar user, similarity score]...]</span><br><span class="line">	&#x27;u1&#x27;:[[u2,0.9],[u6,0.88]...]</span><br><span class="line">	&#x27;u2&#x27;:...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol></li>
<li><p>线上做召回</p>
<ol type="1">
<li>给定用户ID，通过“user2user”找到top-k相似用户</li>
<li>对于top-k列表中每个用户，通过“user2item"找到用户近期感兴趣物品列表(last-n)。</li>
<li>对于召回的nk个相似物品，用公式预估用户对每个物品的兴趣分数</li>
<li>返回分数最高的100个物品，作为召回结果</li>
</ol></li>
</ol>
<h3 id="协同过滤缺点">协同过滤缺点</h3>
<p>。。。</p>
<h2 id="向量召回">向量召回</h2>
<h3 id="矩阵补充-matrix-completion">矩阵补充 Matrix Completion</h3>
<p>用于填充评分矩阵中无评分的部分，通过求user与item embedding的内积</p>
<p><img src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230626164840701.png" alt="image-20230626164840701" style="zoom:33%;" /></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626163645000.png"
alt="image-20230626163645000" />
<figcaption aria-hidden="true">image-20230626163645000</figcaption>
</figure>
<h4 id="数据集">数据集</h4>
<ol type="1">
<li><p>（用户ID,物品ID，兴趣分数）————》<span
class="math inline">\(dataset={(u,i,y)}\)</span></p></li>
<li><p>正负例子（0-4分）：</p>
<ol type="1">
<li>负例子：曝光没有点击-0分</li>
<li>正例子：点击、点赞、收藏、转发-各1分</li>
</ol></li>
</ol>
<h4 id="训练">训练</h4>
<p><span class="math display">\[
min_{A,B}\sum _{(u,i,y)\in dataset}(y-&lt;a_u,b_i&gt;)^2
\]</span></p>
<h4 id="缺点">缺点</h4>
<ol type="1">
<li>仅用ID embedding，没利用物品、用户的属性。</li>
<li>负样本选取方法不对。</li>
<li>做训练方法不好
<ol type="1">
<li>内积效果不如余弦相似度</li>
<li>用回归方法不如用分类方法。</li>
</ol></li>
</ol>
<h4 id="运作基本流程-2">运作基本流程</h4>
<ol type="1">
<li>离线计算
<ol type="1">
<li>训练矩阵A、B（embedding层的参数，A for user, B for item）</li>
<li>由于矩阵很大，为了快速读取使用hash方法：
<ol type="1">
<li>把矩阵A存储到key-value表{user_id: user_embedding}。</li>
<li>（加速最近邻查找）将item分区保存至key-value表</li>
</ol></li>
</ol></li>
<li>线上服务
<ol type="1">
<li>通过用户ID查询用户向量，记作A。</li>
<li>最近邻查找：查找用户最优可能感兴趣的k个物品作为召回结果。
<ol type="1">
<li>第i号物品的embedding向量记作<span
class="math inline">\(b_i\)</span></li>
<li>求<span class="math inline">\(&lt;a,b_i&gt;\)</span></li>
<li>返回内积最大的k个物品</li>
</ol></li>
</ol></li>
</ol>
<p><strong>加速最近邻查找方法</strong>：</p>
<p>一般item有几亿个，暴力计算内积并排序过慢</p>
<p>方法：</p>
<ol type="1">
<li><p>确定衡量最近邻标注：欧氏距离最小（L2距离），向量内积最大（内积相似度），向量夹角余弦最大（cosine相似度）</p></li>
<li><p>根据衡量标准将所有item
embedding分块，下面为根据余弦相似度分块的例子，每一个区域用一个向量E表示，通过key-value表保存区域向量E与区域中所有向量的embedding。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626171141459.png"
alt="image-20230626171141459" />
<figcaption aria-hidden="true">image-20230626171141459</figcaption>
</figure></li>
<li><p>求区域向量与user的余弦相似度，获取结构最大区域。再将区域中所有的item暴力枚举算相似度。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626171541263.png"
alt="image-20230626171541263" />
<figcaption aria-hidden="true">image-20230626171541263</figcaption>
</figure></li>
</ol>
<h3 id="双塔模型">双塔模型</h3>
<p>融合除了ID以为的别的特征</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626173816258.png"
alt="image-20230626173816258" />
<figcaption aria-hidden="true">image-20230626173816258</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626173835292.png"
alt="image-20230626173835292" />
<figcaption aria-hidden="true">image-20230626173835292</figcaption>
</figure>
<h4 id="数据集-1">数据集</h4>
<ol type="1">
<li><p>正样本</p>
<p>曝光且有点击的（user，item）组</p>
<p>问题：少部分物品占据大部分点击，导致正样品大多是热门物品，对冷门物品不公平。</p>
<p>解决：过采样冷门物品，或降采样热门物品</p>
<p>​ 过采样：一个样品出现多次</p>
<p>​ 降采样：一些样本被抛弃</p></li>
<li><p>负样本</p>
<p>混合几种负样本：50%的简单负样本，50%的困难负样本</p>
<p>我们分别讨论下面三种可以作为负样本的数据。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626202449765.png"
alt="image-20230626202449765" />
<figcaption aria-hidden="true">image-20230626202449765</figcaption>
</figure>
<ol type="1">
<li><p>简单负样本</p>
<p>没有被召回的数据: <strong>全体物品</strong></p>
<p>没被召回的数据，大概率是用户不感兴趣的，未被召回的样本约等于全体物品，所以在全体物品中做抽样作为负样本。</p>
<p><strong>均匀抽样</strong>：正样本大多是热门物品，负样本大多是冷门物品。（因为热门物品比例小），所以我们需要利用非均匀抽样打压热门物品。</p>
<p><strong>非均抽采样</strong>：负样本抽样概率与热门程度（点击次数）正相关，<span
class="math inline">\(抽样概率\propto (点击次数)^{0.75}\)</span></p>
<p><strong>Batch内负采样</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626203300364.png"
alt="image-20230626203300364" />
<figcaption aria-hidden="true">image-20230626203300364</figcaption>
</figure>
<p>一个batch有n个正样本对，一个用户和n-1个物品组成负样本，batch中一共有n（n-1）个负样本对。</p>
<p>此时，热门物品成为负样本的概率过大（热门物品成为正样本概率大）：<span
class="math inline">\(抽样概率\propto (点击次数)\)</span></p>
<p>所以做训练时，兴趣分数调整为：<span
class="math inline">\(cos(a,b_i)-logp_i\)</span>降低热门物品作为负样本的惩罚</p></li>
<li><p><strong>困难负样本</strong>：用户有一点兴趣，但兴趣不够，特别容易分错</p>
<p>被粗排淘汰的物品（比较困难）</p>
<p>精排分数靠后的物品（非常困难）</p></li>
</ol>
<p><strong>注意</strong>：不能用曝光但没有点击的样本，因为能通过精排（更复杂的模型）的样本已经是用户比较感兴趣的样本，可能只是机缘巧合没有点击，训练召回不能用这一类样本，但是训练排序可以</p></li>
</ol>
<h4 id="训练-1">训练</h4>
<h5 id="pointwise">Pointwise</h5>
<p>当做二分类任务，对于正样本，鼓励cos(a,b)接近+1；对于负样本，鼓励cos(a,b)接近-1</p>
<h5 id="pairwise">Pairwise</h5>
<p>鼓励<span class="math inline">\(cos(a,b^+)\)</span>大于<span
class="math inline">\(cos(a,b^-)\)</span></p>
<p>Triplet hinge loss: <span class="math display">\[
L(a,b^+,b^-) = max\{0,cos(a,b^-)+m-cos(a,b^+)\}
\]</span> m为超参数</p>
<p>Triplet logistic loss: <span class="math display">\[
L(a,b^+,b^-) = log(1+exp[\sigma(cos(a,b^-)-cos(a,b^+))])
\]</span></p>
<h5 id="listwise">Listwise</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626175637609.png"
alt="image-20230626175637609" />
<figcaption aria-hidden="true">image-20230626175637609</figcaption>
</figure>
<h4 id="运作基本流程-3">运作基本流程</h4>
<ol type="1">
<li>离线存储：把物品向量b存入向量数据库。</li>
<li>线上召回：查找用户最感兴趣的k个物品。
<ol type="1">
<li>给定用户ID和画像，线上用升级网络算用户向量A。</li>
<li>最近邻查找</li>
</ol></li>
</ol>
<p>为什么用户向量要在线计算：</p>
<ol type="1">
<li>没做一次召回只用到一个用户向量A，计算成本较小。</li>
<li>用户兴趣动态变化，物品较稳定。</li>
</ol>
<h4 id="模型更新">模型更新</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626205649864.png"
alt="image-20230626205649864" />
<figcaption aria-hidden="true">image-20230626205649864</figcaption>
</figure>
<p><strong>全量更新</strong>：</p>
<p>​
在昨天模型参数基础上做训练（不是随机初始化），用昨天的数据，shuffle后训练一个epoch后发布新的用户塔神经网络和物品向量，供线上召回使用。</p>
<p><strong>增量更新</strong>：</p>
<p>​ 用户兴趣随时发生变化，实时收集线上数据，对模型做online
learning，增量更新ID
Embedding参数(不更新神经网络其他部分参数)，发布用户ID
Embedding，供用户塔线上计算用户向量。</p>
<p><strong>不能只做增量更新，不做全量更新</strong></p>
<ol type="1">
<li>小时级数据有偏差，分钟级偏差更大。</li>
<li>全量更新：random shuffle一天数据，做
1epoch训练；增量更新按照数据从早到晚顺序做1epoch训练，全量更新效果更好。</li>
</ol>
<h4 id="自监督学习">自监督学习</h4>
<h5 id="背景">背景</h5>
<p>推荐系统头部效应严重：少部分物品占据大部分点击，大部分物品曝光、点击次数不高，导致高点击物品的表征学习的好，长尾物品的表征学的不好，用自监督学习做data
augmentation，更好的学习长尾物品的向量表征。</p>
<h5 id="method">Method</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626212328043.png"
alt="image-20230626212328043" />
<figcaption aria-hidden="true">image-20230626212328043</figcaption>
</figure>
<h6 id="特征变换方法">特征变换方法</h6>
<ol type="1">
<li><p>Random Mask</p>
<p>随机选一些离散特征(例如类目特征)，把它们遮住</p>
<p>例子：<span class="math inline">\(U=\{数码，摄影\}\)</span>-&gt;<span
class="math inline">\(U&#39;-\{default\}\)</span></p></li>
<li><p>Dropout</p>
<p>一个物品可以有多个类目，那么类目是一个多值离散特征。Dropout会随机丢弃特征中50%的值。</p>
<p>例子：<span class="math inline">\(U=\{数码，摄影\}\)</span>-&gt;<span
class="math inline">\(U&#39;-\{数码\}\)</span></p></li>
<li><p>complementary互补特征</p>
<p>假设物品一共有四种特征：ID,类目，关键词，城市</p>
<p>随机分成两组：{ID,关键词}，{类目，城市}</p>
<p>{ID,default，关键词，default}作为表征i‘</p>
<p>{default，类目，default，城市}作为表征i‘’</p></li>
<li><p>Mask一组关联的特征</p>
<p>p(u): 某特征取值为u的概率</p>
<p>p(u,v):某特征取值为u，另一个特征取值为v同时发生的概率</p>
<p>离线计算特征的两两关系，用户信息(mutual information): <span
class="math display">\[
MI(U,V)=\sum_{u\in U}\sum_{v\in V}p(u,v)\cdot log\frac{p(u,v)}{p(u)\cdot
p(v)}
\]</span>
假设一共有k种特征。离线计算两两MI，得到kxk的矩阵，随机选一个特征为种子，找到种子最相关的k/2中特征Mask掉，保留其余的k/2中特征。</p>
<p>比random
mask、dropout、互补特征等方法效果更好，但方法复杂实现难度大不容易维护。</p></li>
</ol>
<h6 id="自监督训练">自监督训练</h6>
<p>从全体物品中均匀抽样得到m个物品，作为一个batch。</p>
<p>做两类特征变换，物品他输出两组向量。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626214137364.png"
alt="image-20230626214137364" />
<figcaption aria-hidden="true">image-20230626214137364</figcaption>
</figure>
<h6 id="自监督训练正常训练">自监督训练+正常训练</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626214246267.png"
alt="image-20230626214246267" />
<figcaption aria-hidden="true">image-20230626214246267</figcaption>
</figure>
<h2 id="不适合召回的模型">不适合召回的模型</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626175824199.png"
alt="image-20230626175824199" />
<figcaption aria-hidden="true">image-20230626175824199</figcaption>
</figure>
<p>召回需要计算的item量很大，所以我们一般只做后期融合（计算相似度的时候再融合user和item的embedding），因为融合步骤一般要在线计算不能离线计算完保存（需求内存量太大）。如果我们在召回阶段就要让user
embedding与上亿个item
embedding过神经网络模型，这样时间复杂度太高了。</p>
<h2 id="其他方式召回">其他方式召回</h2>
<p>地理召回</p>
<p>作者召回</p>
<p>缓存召回：复用前n次推荐精排的结果</p>
<h2 id="曝光过滤与链路">曝光过滤与链路</h2>
<ul>
<li>如果用户看过某个物品，则不再把该物品曝光给该用户</li>
<li>对于每个用户，记录已经曝光给他的物品。(小红书只召回1个月以内的笔记，因此只需要记录每个用户最近1个月的曝光历史。)</li>
<li>对于每个召回的物品，判断它是否已经给该用户曝光过排除掉曾经曝光过的物品。</li>
<li>一位用户看过n个物品，本次召回r个物品，如果暴力对比，需要O(nr)的时间。</li>
</ul>
<h3 id="bloom-filter">Bloom Filter</h3>
<ul>
<li>Bloom filter 判断一个物品ID是否在已曝光的物品集合中。</li>
<li>如果判断为no，那么该物品一定不在集合中</li>
<li>如果判断为yes，那么该物品很可能在集合中。(可能误伤错误判断未曝光物品为已曝光，将其过滤掉)</li>
<li>Bloom flter 把物品集合表征为一个m维二进制向量。</li>
<li>Bloom
filter有k个哈希函数，每个哈希函数把物品I映射成介于0和m-1之间的整数。</li>
<li>已曝光物品和召回物品都可以用这个m维向量表示。</li>
</ul>
<p>当k=1：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430102619856.png"
alt="image-20240430102619856" />
<figcaption aria-hidden="true">image-20240430102619856</figcaption>
</figure>
<p>当k=3：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430102711948.png"
alt="image-20240430102711948" />
<figcaption aria-hidden="true">image-20240430102711948</figcaption>
</figure>
<p>BloomFilter误伤概率：</p>
<ul>
<li>曝光物品集合大小为n，二进制向量维度为m，使用k个哈希函数。</li>
<li>误伤的概率为<span
class="math inline">\(δ≈(1-exp(-\frac{kn}{m}))^k\)</span>
<ul>
<li>n越大，向量中的1越多，误伤概率越大。</li>
<li>m越大，向量越长，越不容易发生哈希碰撞。但要求更多存储空间。</li>
<li>k太大、太小都不好，k有最优取值。</li>
</ul></li>
<li>计算k最优参数，设定可容忍误伤概率<span
class="math inline">\(δ\)</span>：</li>
<li><span class="math inline">\(k=1.44\cdot
ln(\frac{1}{δ})\)</span></li>
<li><span class="math inline">\(m=2n\cdot ln(\frac{1}{δ})\)</span></li>
</ul>
<p>优缺点</p>
<ul>
<li><p>Bloom filtcr
把物品的集合表示成一个二进制向量，节省存储空间和计算成本。</p></li>
<li><p>每往集合中添加一个物品，只需要把向量k个位置的元素置为1。(如果原本就是1，则不变)</p></li>
<li><p>Bloom filter只支持添加物品，不支持删除物品。</p></li>
<li><p>每天都需要从物品集合中移除年龄大于1个月的物品(超龄物品不可能被召回，没必要把它们记录在Bloom
filter，降低n可以降低误伤率)</p></li>
</ul>
<h1 id="排序">排序</h1>
<h2 id="排序模型特征">排序模型特征</h2>
<h3 id="用户画像">用户画像</h3>
<ul>
<li>用户ID</li>
<li>性别、年龄</li>
<li>新老、活跃度</li>
<li>感兴趣类目、关键词、品牌</li>
</ul>
<h3 id="物品画像">物品画像</h3>
<ul>
<li>物品ID</li>
<li>发布时间</li>
<li>GeoHash（经纬度编码）、所在城市</li>
<li>标题、类目、关键词、品牌</li>
<li>字数、图片数、视频清晰度、标签数</li>
<li>内容信息量、图片美学</li>
</ul>
<h3 id="用户统计特征">用户统计特征</h3>
<ul>
<li>用户最近30天天曝光数、点击数、点赞数、收藏数</li>
<li>按照笔记图文/视频分桶。(比如最近7天，该用户对图文笔记的点击率、对视频笔记的点击率。)</li>
<li>按照笔记类目分桶。(比如最近30天，用户对美妆笔记的点击率、对美食笔记的点击率、对科技数码笔记的点击率。)</li>
</ul>
<h3 id="笔记统计特征">笔记统计特征</h3>
<ul>
<li>笔记最近30天(7天、1天、1小时)的曝光数、点击数点赞数、收藏数…。</li>
<li>按照用户性别分桶、按照用户年龄分桶…</li>
<li>作者特征:
<ul>
<li>发布笔记数</li>
<li>粉丝数</li>
<li>消费指标(曝光数、点击数、点赞数、收藏数)</li>
</ul></li>
</ul>
<h3 id="场景特征">场景特征</h3>
<ul>
<li>用户定位GeoHash(经纬度编码)、城市。</li>
<li>当前时刻(分段，做embedding)</li>
<li>是否是周末、是否是节假日。</li>
<li>手机品牌、手机型号、操作系统。</li>
</ul>
<h3 id="特征处理">特征处理</h3>
<ul>
<li>离散特征:做embedding。
<ul>
<li>用户ID、笔记ID、作者ID。</li>
<li>类目、关键词、城市、手机品牌</li>
</ul></li>
<li>连续特征:做分桶，变成离散特征。
<ul>
<li>年龄、笔记字数、视频长度。</li>
<li>连续特征:其他变换。</li>
<li>曝光数、点击数、点赞数等数值做log(1+x)</li>
<li>转化为点击率、点赞率等值，并做平滑。</li>
</ul></li>
</ul>
<h2 id="粗排模型">粗排模型</h2>
<ul>
<li>给几千篇笔记打分</li>
<li>单次推理代价必须小（用户与物品特征后期融合）</li>
<li>预估的准确性不高</li>
</ul>
<h3 id="粗排的三塔模型">粗排的三塔模型</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425153102228.png"
alt="image-20240425153102228" />
<figcaption aria-hidden="true">image-20240425153102228</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425153151749.png"
alt="image-20240425153151749" />
<figcaption aria-hidden="true">image-20240425153151749</figcaption>
</figure>
<h2 id="精排模型">精排模型</h2>
<ul>
<li>给几百篇笔记打分</li>
<li>单次推理代价很大（用户与物品特征前期融合）</li>
<li>预估准确性更高</li>
</ul>
<h3 id="多目标模型">多目标模型</h3>
<h4 id="模型结构">模型结构</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145400996.png"
alt="image-20240425145400996" />
<figcaption aria-hidden="true">image-20240425145400996</figcaption>
</figure>
<p>loss： <span class="math display">\[
Loss=\sum_{i=1}^4\alpha_i \cdot CrossEntropy(y_i,p_i)
\]</span></p>
<h4 id="估值校准">估值校准：</h4>
<p>why：为了缩短训练时间会对负样本进行降采样，由于负样本变少，预估点击率大于真实点击率：</p>
<p>真实点击率:<span
class="math inline">\(p_{true}=\frac{n_+}{n_++n_-}\)</span></p>
<p>预估点击率：<span
class="math inline">\(p_{pred}=\frac{n_+}{n_++\alpha \cdot
n_-}\)</span></p>
<p>校准公式： <span class="math inline">\(p_{true}=\frac{\alpha \cdot
p_{pred} }{(1-p_{pred})+\alpha \cdot p_{pred}}\)</span></p>
<h3 id="multi-gate-mixture-of-experts-mmoe">Multi-gate
Mixture-of-Experts (MMoE)</h3>
<h4 id="模型结构-1">模型结构</h4>
<p>假设现在需要求点击率与点赞率两个指标</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145112596.png"
alt="image-20240425145112596" />
<figcaption aria-hidden="true">image-20240425145112596</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145206437.png"
alt="image-20240425145206437" />
<figcaption aria-hidden="true">image-20240425145206437</figcaption>
</figure>
<h4 id="极化现象">极化现象</h4>
<p>softmax输出的权重接近与0,0,0...1，这样不能充分利用所有模型结构</p>
<p>解决方法：dropout</p>
<h2 id="预估分数融合">预估分数融合</h2>
<p>将点击率、点赞量等指标融合，计算出最终分数</p>
<ul>
<li><p>简单加权和</p>
<p><span class="math inline">\(p_{click}+w_1\cdot p_{like}+ w_2\cdot
p_{collect} + \cdots\)</span></p></li>
<li><p>点击率乘以其他项加权和</p>
<p><span class="math inline">\(p_{click}\cdot (w_1\cdot p_{like}+
w_2\cdot p_{collect} + \cdots)\)</span></p></li>
<li><p>海外某短视频app：</p>
<p><span class="math inline">\((1+w_1\cdot p_{time})^{\alpha_1}\cdot
(1+w_2\cdot p_{time})^{\alpha_2}\cdots\)</span></p>
<p><span class="math inline">\(p_{time}\)</span>是预估播放时长</p></li>
<li><p>国内某视频app：用排名计算</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425150136906.png"
alt="image-20240425150136906" />
<figcaption aria-hidden="true">image-20240425150136906</figcaption>
</figure></li>
<li><p>电商</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425150219933.png"
alt="image-20240425150219933" />
<figcaption aria-hidden="true">image-20240425150219933</figcaption>
</figure></li>
</ul>
<h2 id="视频播放时长建模">视频播放时长建模</h2>
<h3 id="播放时长建模">播放时长建模</h3>
<p>训练：最小化y与p的交叉熵函数</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430105536098.png"
alt="image-20240430105536098" />
<figcaption aria-hidden="true">image-20240430105536098</figcaption>
</figure>
<p>预测：直接求<span class="math inline">\(exp(z)\)</span></p>
<h3 id="视频完播">视频完播</h3>
<h4 id="建模方法">建模方法</h4>
<ul>
<li><p>回归方法</p>
<p>视频长度10分钟，实际播放4分钟，则实际播放率为y=0.4
让预估播放率p拟合y: <span
class="math inline">\(loss=y·logp+(1-y)·log(1-p)\)</span></p>
<p>线上预估完播率，模型输出p=0.73，意思是预计播放73%。</p></li>
<li><p>二元分类</p>
<p>定义完播指标，比如完播80%。 例:视频长度10分钟，播放$&gt;<span
class="math inline">\(8分钟作为正样本，播放\)</span>&lt;<span
class="math inline">\(8分钟作为负样本。
做二元分类训练模型:播放\)</span>&gt;<span class="math inline">\(80%vs
播放\)</span>&lt;$80%。线上预估完播率，模型输出p=0.73，意思是P(播放&gt;80%)=
0.73</p></li>
</ul>
<h4 id="融入融分公式">融入融分公式</h4>
<p>不可直接使用融分公式，因为视频越长完播率越低</p>
<p>需要做调整: <span class="math display">\[
p_{finish}=\frac{预估完播率}{f（视频时长）}
\]</span> "把<span
class="math inline">\(p_{finish}\)</span>作为融分公式中的一项。</p>
<h1 id="特征交叉">特征交叉</h1>
<h2 id="factorized-machine">Factorized Machine</h2>
<p>tbd</p>
<h2 id="dcn">DCN</h2>
<p>使用场景：</p>
<ul>
<li>双塔模型中用户塔和物品塔</li>
<li>排序模型</li>
<li>MMOE模型中专家网络</li>
</ul>
<h2 id="ppnet">PPNet</h2>
<p>语音识别中的LHUC</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425191526931.png"
alt="image-20240425191526931" />
<figcaption aria-hidden="true">image-20240425191526931</figcaption>
</figure>
<p>PPNET</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425191558660.png"
alt="image-20240425191558660" />
<figcaption aria-hidden="true">image-20240425191558660</figcaption>
</figure>
<h2 id="senet">SENet</h2>
<p>有点像autoencoder+全局注意力机制，中间缩小参数量m/r是避免过拟合</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425192121242.png"
alt="image-20240425192121242" />
<figcaption aria-hidden="true">image-20240425192121242</figcaption>
</figure>
<h2 id="bilinear-cross">bilinear cross</h2>
<ul>
<li>内积 bilinear cross</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426103501935.png"
alt="image-20240426103501935" />
<figcaption aria-hidden="true">image-20240426103501935</figcaption>
</figure>
<ul>
<li>哈达玛bilinear cross</li>
</ul>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426103501935.png" /></p>
<h2 id="fibinet">FiBiNet</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426110218217.png"
alt="image-20240426110218217" />
<figcaption aria-hidden="true">image-20240426110218217</figcaption>
</figure>
<h1 id="用户行为序列建模">用户行为序列建模</h1>
<h2 id="last-n">Last N</h2>
<ul>
<li>用户最近的n次交互(点击、点赞等)的物品 ID。</li>
<li>对Last N物品I做embedding，得到n个向量。</li>
<li>把几个向量取平均，作为用户的一种特征。</li>
</ul>
<h2 id="din模型注意力机制">DIN模型（注意力机制）</h2>
<ul>
<li>对于某候选物品，计算它与用户 Last N物品的相似度。</li>
<li>以相似度为权重，求用户Last N物品向量的加权和，结果是一个向量。</li>
<li>把得到的向量作为一种用户特征，输入排序模型，预估(用户，候选物品)的点击率、点赞率等指标。</li>
</ul>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426110602597.png" /></p>
<p>简单平均和 注意力机制 都适用于精排模型。</p>
<ul>
<li>简单平均适用于双塔模型、三塔模型。
<ul>
<li>简单平均只需要用到LastN，属于用户自身的特征。</li>
<li>把LastN向量的平均作为用户塔的输入。</li>
</ul></li>
<li>注意力机制不适用于双塔模型、三塔模型。
<ul>
<li>注意力机制需要用到LastN+候选物品。</li>
<li>用户塔看不到候选物品，不能把注意力机制用在用户塔</li>
</ul></li>
</ul>
<h2 id="sim模型长序列建模">SIM模型（长序列建模）</h2>
<p>DIN模型缺点：</p>
<ul>
<li>注意力层计算量与n相关</li>
<li>只能记录最近几百个物品，否则计算量太大</li>
<li>关注短期兴趣，遗忘长期兴趣</li>
</ul>
<p>SIM模型目的：</p>
<ul>
<li>保留用户长期行为序列，而且计算量不会很大。</li>
</ul>
<p>改善DIN方法：DIN对Last N向量做加权平均，权重是相似度，如果某Last
N物品与候选物品差异很大，则权重接近零。可以提前快速排除掉与候选物品无关（相似度低，权重接近0）的Last
N物品，降低注意力层的计算量。</p>
<h3 id="模型架构">模型架构</h3>
<ul>
<li>保留用户长期行为记录，n的大小可以是几千。</li>
<li>对于每个候选物品，在用户Last
N记录中做快速查找，找到k个相似物品。</li>
<li>把LastN变成TopK，然后输入到注意力层</li>
<li>SIM 模型减小计算量(从n降到k)。</li>
</ul>
<h4 id="查找">查找</h4>
<ul>
<li>Hard Search（基于规则）
<ul>
<li>根据候选物品的类目，保留Last N物品中类目相同的。
·简单，快速，无需训练。</li>
</ul></li>
<li>Soft Search
<ul>
<li>把物品做embedding，变成向量。</li>
<li>把候选物品向量作为query，做k近邻查找，保留LastN物品中最接近的k个。</li>
<li>效果更好，编程实现更复杂。</li>
</ul></li>
</ul>
<h4 id="注意力机制">注意力机制</h4>
<ul>
<li>只使用挑出来的Top K计算权重</li>
<li>使用时间信息：SIM序列长，记录用户长期行为，时间越久远，重要性越低
<ul>
<li>用户与某个LastN物品的交互时刻距今为δ。</li>
<li>对δ做离散化，再做embedding，变成向量d</li>
<li>把两个向量做concatenation，表征一个LastN物品。
<ul>
<li>向量x是物品embedding。</li>
<li>向量d是时间的embedding</li>
</ul></li>
</ul></li>
</ul>
<h1 id="重排">重排</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430142915426.png"
alt="image-20240430142915426" />
<figcaption aria-hidden="true">image-20240430142915426</figcaption>
</figure>
<p>粗排精排：</p>
<ul>
<li>粗排和精排用多目标模型对物品做 pointwise打分。</li>
<li>对于物品i，模型输出点击率、交互率的预估，融合成分数reward。<span
class="math inline">\(reward_i\)</span>表示用户对物品i的兴趣，即物品本身价值。</li>
</ul>
<p>后处理（精排的后处理称为重排）：</p>
<ul>
<li>从n个后序物品选出k个，既要她们总分高，也需要它们有多样性</li>
</ul>
<h2 id="相似性度量">相似性度量</h2>
<p>提高多样性意味着推荐的物品不可过于相似，首先需要度量物品之间相似度</p>
<h3 id="基于物品属性标签">基于物品属性标签。</h3>
<p>物品属性标签：类目、品牌、关键词………</p>
<p>根据一级类目、二级类目、品牌计算相似度</p>
<ul>
<li>物品i:美妆、彩妆、香奈儿</li>
<li>物品j:美妆、香水、香奈儿</li>
</ul>
<p>相似度:simi(i,j)=1，simz(i,j)=0，sim3(i,j)=1。在做加权</p>
<h3 id="基于物品向量表征">基于物品向量表征。</h3>
<ul>
<li><p>用召回的双塔模型学到的物品向量(不好)</p>
<p>召回双塔模型基于用户物品交互，冷门物品没办法学好表征，热门物品多交互也不代表相似</p></li>
<li><p>基于内容的向量表征(好)</p>
<p>用cv或nlp模型，提取特征</p>
<p>使用clip预训练方法：对于图片文字二元组，预测图文是否匹配，无需人工标注</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430142711097.png"
alt="image-20240430142711097" />
<figcaption aria-hidden="true">image-20240430142711097</figcaption>
</figure></li>
</ul>
<h2 id="maximal-margianl-relevancemmr">Maximal Margianl
Relevance（MMR）</h2>
<p>精排给n个候选物品打分，把第i和j个物品的相似度记作
sim(i,j)，从几个物品中选出k个，既要有高精排分数也要有多样性。</p>
<h3 id="原理">原理</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430143624521.png"
alt="image-20240430143624521" />
<figcaption aria-hidden="true">image-20240430143624521</figcaption>
</figure>
<h3 id="流程">流程</h3>
<p>1.已选中的物品S初始化为空集，未选中的物品初始化为全集 {1,…,n}
2.选择精排分数rewardi最高的物品，从集合R移到S 3.做k-1轮循环:
a.计算集合见中所有物品的分数<span class="math inline">\(\{MR_i\}_{i\in
R}\)</span>。 b.选出分数最高的物品，将其从<span
class="math inline">\(R\)</span>移到<span
class="math inline">\(S\)</span>。</p>
<h3 id="trick滑动窗口">Trick：滑动窗口</h3>
<ul>
<li>已选中的物品越多(即集合S越大)，越难找出物品<span
class="math inline">\(i\in R\)</span>使得i与S中的物品都不相似。</li>
<li>设sim 的取值范围是「0,1]。当S很大时，多样性分数<span
class="math inline">\({max}_{j\in S}sim(i,j)\)</span>总是约等于1,导致
MMR 算法失效。</li>
<li>解决方案:设置一个滑动窗口W，比如最近选中的10个物品，用W代替MMR
公式中的S。</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430144236363.png"
alt="image-20240430144236363" />
<figcaption aria-hidden="true">image-20240430144236363</figcaption>
</figure>
<h2 id="通过重排规则提高多样性">通过重排规则提高多样性</h2>
<h3 id="重排规则">重排规则</h3>
<ul>
<li><p>最多连续出现k篇某种笔记</p>
<p>小红书推荐系统的物品分为图文笔记、视频笔记。
最多连续出现k=5篇图文笔记，最多连续出现k-5篇视频笔记。
如果排i到i+4的全都是图文笔记，那么排在i+5的必须是视频笔记。</p></li>
<li><p>每k篇笔记最多出现1篇某种笔记
运营推广笔记的精排分会乘以大于1的系数(boost)帮助笔记获得更多曝光。
为了防止boost影响体验，限制每k-9篇笔记最多出现1篇运营推广笔记。
如果排第i位的是运营推广笔记，那么排i+1到i+8的不能是运营推广笔记。</p></li>
<li><p>每k篇笔记最多出现1篇某种笔记
运营推广笔记的精排分会乘以大于1的系数(boost)帮助笔记获得更多曝光。
为了防止boost影响体验，限制每k-9篇笔记最多出现1篇运营推广笔记。
如果排第i位的是运营推广笔记，那么排i+1到i+8的不能是运营推广笔记。</p></li>
</ul>
<h3 id="mmr重排规则">MMR+重排规则</h3>
<p>每一轮先用规则排除掉R中的部分物品，得到子集R'。</p>
<p>MMR 公式中的R替换成子集R'，选中的物品符合规则。</p>
<h2 id="dpp多样性算法">DPP多样性算法</h2>
<h3 id="数学基础-超平形体">数学基础-超平形体</h3>
<h4 id="二维">二维</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430155731053.png"
alt="image-20240430155731053" />
<figcaption aria-hidden="true">image-20240430155731053</figcaption>
</figure>
<p>2维空间的超平形体为平行四边形。</p>
<p>平行四边形中的点可以表示为 <span class="math display">\[
x=\alpha_1v_1+ \alpha_2v_2
\]</span> 系数<span class="math inline">\(\alpha_1\)</span>和<span
class="math inline">\(\alpha_2\)</span>的取值范围是[0,1]</p>
<h4 id="三维">三维</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430155806892.png"
alt="image-20240430155806892" />
<figcaption aria-hidden="true">image-20240430155806892</figcaption>
</figure>
<p>2维空间的超平形体为平行六面体。</p>
<p>平行四边形中的点可以表示为 <span class="math display">\[
x=\alpha_1v_1+ \alpha_2v_2+ \alpha_3v_3
\]</span> 系数<span class="math inline">\(\alpha_1\)</span>和<span
class="math inline">\(\alpha_2\)</span>、<span
class="math inline">\(\alpha_3\)</span>的取值范围是[0,1]</p>
<h4 id="多维">多维</h4>
<p>一组向量<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>可以确定一个k维超平行体： <span class="math display">\[
P(v_1,\cdots, v_k) = \{\alpha_1v_1+\cdots+\alpha_kv_k|0\leqslant
\alpha_1,\cdots,\alpha_k \leqslant 1\}
\]</span> 要求<span class="math inline">\(k\le
d\)</span>,比如d=3维向量空间中有k=2维平行四边形。否则超平行体会跟拍扁了一样。</p>
<h4 id="超平形体体积">超平形体体积</h4>
<p>构成超平形体的向量正交时，超平行体体积最大，vol=1</p>
<p>如果<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>线性相关，体积<span
class="math inline">\(vol(p)=0\)</span></p>
<p>我们可以认为体积最大意味着多样性好，体积最小意味着多样性差。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430162451245.png"
alt="image-20240430162451245" />
<figcaption aria-hidden="true">image-20240430162451245</figcaption>
</figure>
<p>对于一组向量<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>，<span class="math inline">\(k\leq
d\)</span>,把它们作为矩阵的列，行列式与体积满足： <span
class="math display">\[
det(V^TV) = vol(p(v_1,\cdots,v_k))^2
\]</span></p>
<h3 id="dpp应用于多样性">DPP应用于多样性</h3>
<p>精排给n个物品打分:<span class="math inline">\(reward_1,\cdots,
reward_n\)</span></p>
<p>n 个物品的向量表征:<span class="math inline">\(v_1,\cdots , v_n \in
R^d\)</span></p>
<p>从n个物品中选出k个物品，组成集合S</p>
<ul>
<li><p>价值大:分数之和<span class="math inline">\(∑_{j\in
s}reward_j\)</span>越大越好</p></li>
<li><p>多样性好:S中k个向量组成的超平形体P(S)的体积越大越好。</p></li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430165104679.png"
alt="image-20240430165104679" />
<figcaption aria-hidden="true">image-20240430165104679</figcaption>
</figure>
<p>集合S中的k个物品的向量作为列，组成矩阵 <span
class="math inline">\(V_s\in R^{dxk}\)</span></p>
<p>以这k个向量作为边，组成超平形体P(S) <span class="math display">\[
det(V_s^TV_s) = vol(p(S))^2
\]</span> DPP是一种传统的统计学习方法 <span class="math display">\[
\mathop{\arg\min}\limits_{S:|S|=k} \space log det(V_s^TV_s)
\]</span> 应用于推荐系统 <span class="math display">\[
\mathop{\arg\min}\limits_{S:|S|=k}\space \theta\cdot (\sum_{j\in
S}reward_j)+(1-\theta)\cdot log det(V_s^TV_s)
\]</span> 我们构造一个nxn的矩阵<span
class="math inline">\(A\)</span>，它的(i,j)元素使<span
class="math inline">\(a_{ij}=v_i^Tv_j\)</span>，计算这个矩阵的时间复杂度是<span
class="math inline">\(O(n^2d)\)</span>。 <span class="math display">\[
A_s \in R^{(k\times k)}=V_s^TV_s
\]</span> 是矩阵<span
class="math inline">\(A\)</span>的子矩阵，如果<span
class="math inline">\(i,j\in S\)</span>,则<span
class="math inline">\(a_{ij}\)</span>是<span
class="math inline">\(A_s\)</span>的一个元素。</p>
<p>DPP是个组合优化问题，从集合{1…,n}中选出一个大小为k的子集S。</p>
<h4 id="暴力贪心算法">暴力贪心算法</h4>
<p>用S表示已选中的物品，用R表示未选中的物品，贪心算法求解 <span
class="math display">\[
\mathop{\arg\min}\limits_{i\in R}\space \theta\cdot
(reward_i)+(1-\theta)\cdot log det(A_{S\cup i})
\]</span> 对于单个i，计算 <span class="math inline">\(A_{S\or
i}\)</span>的行列式需要<span
class="math inline">\(O(|A|^3)\)</span>时间(求行列式就是需要<span
class="math inline">\(O(n^3)\)</span>)</p>
<p>对于所有的<span class="math inline">\(i\in
R\)</span>，计算行列式需要时间<span class="math inline">\(O(|A|^3\cdot
|R|)\)</span>。</p>
<p>需要求解上式k次才能选出k个物品。如果暴力计算行列式，那么总时间复杂度为
<span class="math display">\[
O(|A|^3\cdot |R|\cdot k)=O(nk^4)
\]</span> 再加上计算A的时间，暴力算法总时间复杂度是： <span
class="math display">\[
O(n^2d+nk^4)
\]</span></p>
<h4 id="hulu快速算法">Hulu快速算法</h4>
<p>给定向量<span class="math inline">\(v_1,\cdots , v_n \in
R^d\)</span>，需要<span
class="math inline">\(O(n^2d)\)</span>时间计算A</p>
<p>用<span
class="math inline">\(O(nk^2)\)</span>)时间计算所有的行列式(利用Cholesky分解)</p>
<ul>
<li><p>Cholesky 分解</p></li>
<li><p>Cholesky 分解<span
class="math inline">\(A_s=LL^T\)</span>，其中L是下三角矩阵(对角线以上的元素全零)</p>
<p>Cholesky 分解可供计算<span
class="math inline">\(A_s\)</span>的行列式。</p>
<ul>
<li>下三角矩阵L的行列式 det(L)等于L对角线元素乘积。</li>
<li>As 的行列式为 <span class="math inline">\(det(A_s)= det(L)^2=\prod_i
l_{ii}^2\)</span></li>
</ul></li>
<li><p>已知<span
class="math inline">\(A_s=LL^T\)</span>，则可以快速求出所有<span
class="math inline">\(A_{S\cup i}\)</span> 的
Cholesky分解(有方法可以快速算出增加一行一列的行列式)，因此可以快速算出所有
<span class="math inline">\(A_{S\cup i}\)</span> 的行列式。</p></li>
</ul>
<h3 id="dpp扩展-滑动窗口">DPP扩展-滑动窗口</h3>
<p>与MMR方法一样，随着<span
class="math inline">\(S\)</span>增大，其中相似物品越来越多，物品向量会趋近线性相关。</p>
<p>DPP失效</p>
<h1 id="冷启动">冷启动</h1>
<h1 id="涨指标方法">涨指标方法</h1>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>BasicTurtorial</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习推荐系统-王喆</title>
    <url>/2023/07/01/Recommendation-Wangzhe/</url>
    <content><![CDATA[<h1 id="传统模型">传统模型</h1>
<h2 id="协同过滤">协同过滤</h2>
<p>User-CF适用于发现热点以及跟踪热点趋势。（user的爱好经常变动，相似度也会随之变动，而且容易受社交关系影响）</p>
<p>Item-CF适用于兴趣变化较为稳定的应用。（item相似度比较稳定）</p>
<p>缺点：泛化能力弱：无法将两个物品相似这一信息推广到其他物品的相似性计算上。导致热门的物品有很强的头部效应，容易根大量物品产生相似性，尾部物品则因为特征向量稀疏很少与其他物品产生相似性。</p>
<h3 id="user-cf">User-CF</h3>
<p>缺点：
用户数往往大于物品书，用户数的增长会导致用户相似度矩阵的存储空间以<span
class="math inline">\(n^2\)</span>的速度快速增长。</p>
<h4 id="计算用户相似度">计算用户相似度</h4>
<ol type="1">
<li>余弦相似度</li>
</ol>
<p><span class="math display">\[
similarity=cos(\theta) = \frac{A\cdot B}{||A||\space ||B||}
\]</span></p>
<ol start="2" type="1">
<li>皮尔逊系数-user <span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_i)(R_{j,p}-\bar
R_j)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_i)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_j)^2}}
\]</span></li>
</ol>
<p><span class="math inline">\(R_{i,p}\)</span>:
用户i对物品p的评分。</p>
<p><span class="math inline">\(\bar{R_i}\)</span>:
用户对所有物品的平均评分。</p>
<ol start="3" type="1">
<li>皮尔逊系数-item</li>
</ol>
<p><span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_p)(R_{j,p}-\bar
R_p)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_p)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_p)^2}}
\]</span></p>
<p><span class="math inline">\(R_{i,p}\)</span>:
用户i对物品p的评分。</p>
<p><span class="math inline">\(\bar{R_p}\)</span>: 物品p的平均分。</p>
<h4
id="根据top-n相似用户生成最终推荐结果">根据top-n相似用户生成最终推荐结果</h4>
<p><span class="math display">\[
R_{u,s}=\frac{\sum_{s\in S}(w_{u,s}\cdot R_{s,p})}{\sum_{s\in S}w_(u,s)}
\]</span></p>
<p><span class="math inline">\(w_{u,s}\)</span>：
是用户u和用户s的相似度</p>
<p><span class="math inline">\(R_{s,p}\)</span>：
是用户s对物品p的评分。</p>
<h3 id="item-cf">Item-CF</h3>
<p>计算相似度后（计算方法与user相同），用下面式子计算： <span
class="math display">\[
R_{u,p}=\sum_{u\in H}(w_{p,h},\cdot R_{u,h})
\]</span> <span class="math inline">\(w_{p,h}\)</span>：
是物品p与物品h的相似程度。</p>
<p><span class="math inline">\(R_{u,h}\)</span>：
是用户u对物品h的已有评分。</p>
<h2 id="矩阵分解">矩阵分解</h2>
<p><strong>协同过滤的进化</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230706214331238.png"
alt="image-20230706214331238" />
<figcaption aria-hidden="true">image-20230706214331238</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>泛化能力强</li>
<li>空间复杂度低：不用保存用户或物品相似度矩阵，<span
class="math inline">\((m,m)or(n,n)-&gt;(n+m)\cdot k\)</span></li>
<li>更好的扩展性和灵活性。易于与其他特征拼接，易于与深度学习无缝联合。</li>
</ol>
<p>缺点：没有考虑用户与物品的其他特征。</p>
<h3 id="definition">Definition</h3>
<p>通过分解共现矩阵学习用户和物品的表示。</p>
<p>将（m,n)维的共现矩阵M分解为(m,k)维的用户矩阵和(k,n)维的物品矩阵，其中相应的行和列为特定用户与物品的表示，k是用户和物品表示的维度。</p>
<p>预测方法：用户表示与物品表示的内积。 <span class="math display">\[
r_{ui}=q_i^Tp_u
\]</span></p>
<h3 id="如何分解矩阵">如何分解矩阵</h3>
<h4 id="奇异值分解">奇异值分解</h4>
<p>特征值分解只能用于方阵，所以用特征值分解</p>
<p><a
href="https://zhuanlan.zhihu.com/p/613284889">矩阵分解—特征值分解与奇异值分解
- 知乎 (zhihu.com)</a></p>
<p>通过奇异值分解求得<span class="math inline">\(M=U\sum
V^T\)</span>,其中<span class="math inline">\(U\in (m,m),\sum \in
(m,n),V^T\in (n,n)\)</span>,中间的为对角阵</p>
<p>取<span
class="math inline">\(\sum\)</span>中较大的k个元素为隐含特征，删除其他维度（U与V中的也删掉）</p>
<p>得到<span class="math inline">\(M=U_{m\times k}\sum_{k\times k}
V^T_{k\times n}\)</span></p>
<p><strong>缺点</strong>：</p>
<ol type="1">
<li><p>奇异值分解要求原始的共现矩阵是稠密的，如果要使用奇异值分解，就必须对确实的元素值进行填充。</p></li>
<li><p>复杂度高O(mn^2)</p></li>
</ol>
<h4 id="梯度下降">梯度下降</h4>
<p>主要方法</p>
<p>Loss： <span class="math display">\[
L=min_{q^*,p^*}\sum (r_{ui}-q_i^Tp_u)^2+\lambda(||q_i||^2+||p_u||^2)
\]</span> 由于不同用户打分标准不同，加入偏差 <span
class="math display">\[
r_{ui}=\mu +b_i+b_u+q^T_ip_u
\]</span> <span class="math inline">\(\mu\)</span>:
全局偏差常数,超参数，提前设置好</p>
<p><span class="math inline">\(b_i\)</span>:
物品偏差系数，可以使用物品i收到的所有评分的均值</p>
<p><span class="math inline">\(b_u\)</span>:
用户偏差系数，可以使用用户u给出的所有评分的均值 <span
class="math display">\[
L=min_{q^*,p^*}\sum
(r_{ui}-q_i^Tp_u-\mu-b_u-b_i)^2+\lambda(||q_i||^2+||p_u||^2+b_u^2+b_i^2)
\]</span></p>
<h2 id="逻辑回归">逻辑回归</h2>
<p><strong>独立于协同过滤的推荐模型方向</strong></p>
<p>将用户年龄、性别、物品属性等特征转为数值型向量输入回归或逻辑回归模型</p>
<p>优点：融合了特征</p>
<p>缺点：逻辑回归模型简单，表达能力不强</p>
<h2 id="poly2">POLY2</h2>
<p>逻辑回归只对单一特征做简单加权，不具备特征交叉生成高维组合特征的能力
<span class="math display">\[
POLY2(W,X)=\sum_{j_1=1}^{n-1}
\sum_{j_2=j_1+1}^nw_h(j_1,j_2)x_{j_1}x_{j_2}
\]</span> POLY2就是直接暴力组合特征,<span
class="math inline">\(x\)</span>是未经embedding处理的特征（one-hot 或
数值特征）</p>
<p>缺点：</p>
<ol type="1">
<li>常常用one-hot编码方式处理类别数据（就是大量<span
class="math inline">\(x_？\)</span>会为0），POLY2不进行特征选择，会让本来就稀疏的向量更稀疏</li>
<li>权重参数<span
class="math inline">\(n-&gt;n^2\)</span>，极大提高了训练复杂度。</li>
</ol>
<h2 id="fm-factorization-machines因式分解">FM-Factorization
Machines因式分解</h2>
<p>FM为给个特征学习了一个隐权重向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。下面是二阶的数学部分：
<span class="math display">\[
FM(w,x)=\sum_{j_i=1}^{n-1} \sum_{j_2=j_1+1}^n (w_{j_1}\cdot
w_{j_2})x_{j_1}x_{j_2}
\]</span> 我们也可以看作是将POLY2方法中<span
class="math inline">\(R^{n\times n}\)</span>的矩阵分解为两个矩阵<span
class="math inline">\(R^{n\times k}\)</span>和<span
class="math inline">\(R^{k\times
n}\)</span>，其中第一个矩阵第i行与第二个矩阵第j列相乘即使特征i、j的特征交叉参数。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430134835195.png"
alt="image-20240430134835195" />
<figcaption aria-hidden="true">image-20240430134835195</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>计算复杂度<span
class="math inline">\(n^2-&gt;nk\)</span>,k是隐向量维度</li>
<li>泛化强，更好的解决数据稀疏性问题：POLY2只有在出现<span
class="math inline">\(x_{j_1},x_{j_2}\)</span>组合同时出现时才能学习到weight（不如梯度下降梯度为0），FM只要在组合中其中一个是<span
class="math inline">\(x_{j_1}\)</span>就能学到隐向量，能反推出没出现过组合的权重。</li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>丢失了某些具体特征组合的精确记忆能力。</li>
</ol>
<h2 id="ffm-field-aware-factorization-machines">FFM-Field-aware
Factorization Machines</h2>
<p>FFM每个特征对应的不是唯一一个隐向量，而是一组隐向量。特征作用于不同的特征域有不同的隐向量：特征1与特征2交叉，则是特征1作用于特征域2:<span
class="math inline">\(w_{j_1,f_2}\)</span>乘特征2作用于特征域1:<span
class="math inline">\(w_{j_2,f_1}\)</span> <span class="math display">\[
FFM(w,x)=\sum_{j_i=1}^{n-1} \sum_{j_2=j_1+1}^n (w_{j_1,f_2}\cdot
w_{j_2,f_1})x_{j_1}x_{j_2}
\]</span> <strong>与FM区别</strong>：</p>
<p>下图中，P，下面是特征值</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230706212714465.png"
alt="image-20230706212714465" />
<figcaption aria-hidden="true">image-20230706212714465</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th></th>
<th>ESPN特征与NIKE特征交叉</th>
<th>ESPN特征与MALE特征交叉</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>FM</td>
<td><span class="math inline">\(w_{ESPN}\cdot w_{NIKE}\)</span></td>
<td><span class="math inline">\(w_{ESPN}\cdot w_{MALE}\)</span></td>
</tr>
<tr class="even">
<td>FFM</td>
<td><span class="math inline">\(w_{ESPN,A}\cdot w_{NIKE,P}\)</span></td>
<td><span class="math inline">\(w_{ESPN,G}\cdot w_{MALE,P}\)</span></td>
</tr>
</tbody>
</table>
<p>计算复杂度：需要学习n个特征在f个特征域上的k维隐向量，参数数量：<span
class="math inline">\(n\cdot k\cdot
f\)</span>,二次项不能像FM一样简化，复杂度是<span
class="math inline">\(kn^2\)</span>。</p>
<p><strong>注意，n&gt;f,一个特征域有可能有多个特征，例如性别特征域有两种特征：男和女。我们只需要学习NIKE特征在性别特征域的1个隐向量，不需要具体学习NIKE对男性的隐向量或NIKE对女性的。这样参数量还是比POLY2少很多。</strong></p>
<h2 id="gbdtlr">GBDT+LR</h2>
<p>POLY2，再提高交叉维度会产生组合爆炸。</p>
<p>GBDT+LR：就是利用GBDT自动进行特征筛选和组合，生成新的离散特征向量，再把特征向量当做LR模型输入。</p>
<p>以前特征组合要么人工筛选，要么通过改造目标函数筛选，GBDT+LR实现了end2end用模型筛选。</p>
<h3 id="gbdt进行特征筛选组合">GBDT进行特征筛选组合</h3>
<p>决策树的每一层都在划分重要特征（划分后label纯度提高），如果决策树深度为2层则意味着抉择树挑选了两个重要特征进行特征交叉。</p>
<p>训练sample在输入GBDT的某一子树后会根据每个节点的规则落入叶子节点，把所有叶子节点组成的向量为该棵树的特征。</p>
<p>e.g.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720173011264.png"
alt="image-20230720173011264" />
<figcaption aria-hidden="true">image-20230720173011264</figcaption>
</figure>
<h2 id="ls-plmctr">LS-PLM（CTR）</h2>
<p>参考：<a
href="https://zhuanlan.zhihu.com/p/406615820">经典推荐算法学习（四）|
阿里LS-PLM（MLR）模型原理解析 - 知乎 (zhihu.com)</a></p>
<p>在逻辑回归的基础上加入分片的思想，其灵感来自对广告推荐领域样本特点的观察。</p>
<p>举例来说，如果CTR模型要预估的是女性受众点击女装广告的CTR,那么显然，我们不希望把男性用户点击数码类产品的样本数据也考虑进来，因为这样的样本不仅与女性购买女装的广告场景毫无相关性，甚至会在模型训练过程中扰乱相关特征的权重。</p>
<h3 id="method">METHOD</h3>
<p>其实就是一个类似attention结构去捕捉用户的兴趣。</p>
<p>公式如下： <span class="math display">\[
p(y=1|x) = g(\sum_{j=1}^m\sigma(u_j^Tx)\eta(w_j^Tx))
\]</span></p>
<p><span class="math display">\[
p(y=1|x)=\sum_{i=1}^m\frac{exp(u_i^Tx)}{\sum_{j=1}^mexp(u_i^Tx)}\cdot
\frac{1}{1+exp(-w_i^Tx)}
\]</span></p>
<p>如上述公式所示，LS-PLM在表达上非常朴实，拆开来看就是常见的softmax和LR
。<span class="math inline">\(u^T,w^T\)</span>是可训练参数</p>
<p><span class="math inline">\(sigma(u_j^Tx)\)</span>
:SoftMax部分，负责将特征切分到m个不同的空间。</p>
<p><span class="math inline">\(\eta(w_j^Tx)\)</span>
:LR部分则负责对m个空间的特征分片的进行预测</p>
<p><span class="math inline">\(g(\cdot )\)</span>
:sigma函数，作用则是使得模型符合概率函数定义。</p>
<h3 id="特点">特点</h3>
<ol type="1">
<li><strong>Nonlinearity.</strong> 具备任意强非线性拟合能力；</li>
<li><strong>Sparsity.</strong>具备特征选择能力，使得模型具备稀疏性。</li>
<li><strong>Scalability.</strong>
具备从大规模稀疏数据中挖掘出具有推广性的非线性模式</li>
</ol>
<h4 id="non-linear">Non-linear</h4>
<p>通过控制分片数m，使得LS-PLM便具备拟合任意强度高维空间的非线性分类面能力。</p>
<p>如图1，假设训练数据是一个菱形分类面，基于LR的模型能做到的效果如图1.B)，LS-PLM则可以做到用4个分片完美的拟合训练集合，如图1.C)。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720180543134.png"
alt="image-20230720180543134" />
<figcaption aria-hidden="true">image-20230720180543134</figcaption>
</figure>
<p>可以简单理解为通过前面的softmax部分把sample分到不同的LR
function去进行计算，就可以拟合出上图结果</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720180730815.png"
alt="image-20230720180730815" />
<figcaption aria-hidden="true">image-20230720180730815</figcaption>
</figure>
<p>但m增加则容易过拟合，一般阿里选m=12.</p>
<h4 id="sparsityscalability">Sparsity+Scalability</h4>
<p>引入L1正则化进行得到稀疏解，引入L2,1正则化提高泛化能力避免过拟合</p>
<h1 id="深度学习">深度学习</h1>
<h2
id="autorec-利用自编码器对共现矩阵泛化">AutoRec-利用自编码器对共现矩阵泛化</h2>
<p>利用协同过滤中的共现矩阵，完成物品向量或者用户向量的<strong>自编码</strong>。</p>
<p>假设有m个用户n个物品，我们能得到一个（m,n)的评分矩阵。</p>
<h3 id="i-autorec">I-AutoRec</h3>
<h4 id="训练">训练</h4>
<p>对于物品i，所有m个用户对它的评分可以行程一个m维向量r，构建一个三层网络：</p>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720215757791.png"
alt="image-20230720215757791" /> <span class="math display">\[
h(r,\theta) = f(W\cdot g(Vr+\mu)+b)
\]</span> g,f为激活函数</p>
<p>Loss function： <span class="math display">\[
Loss=min_\theta^n||r^{(i)}-h(r^{(i)},\theta)||^2+\frac{\lambda}{2}(||W||_F^2+||V||_F^2)
\]</span></p>
<h4 id="预测">预测</h4>
<p>当输入物品i评分向量<span
class="math inline">\(r^{(i)}\)</span>时，模型输出<span
class="math inline">\(h(r^{(i)},\theta)\)</span>就是所有用户对物品i的评分，那么其中的第u维就是用户u对物品i的预测.
<span class="math display">\[
R_{ui} = (h(r,\theta))_u
\]</span> 其实就是一个泛化过程，重建函数<span
class="math inline">\(h(r,\theta)\)</span>中存储了所有数据向量的精华，经过自编码器生成的输出向量不会完全等同于输入向量，所以会具备了一定的缺失维度的预测能力。</p>
<h3 id="u-autorec">U-AutoRec</h3>
<p>把用户评分向量作为输入向量，但是用户向量稀疏性可能会影响模型效果。</p>
<h2
id="neuralcf-在cf思想上使用深度学习方法">NeuralCF-在CF思想上使用深度学习方法</h2>
<p>传统矩阵分解欠拟合，因为score层太简单</p>
<p>将矩阵分解（CF的扩展）中的scoring层用多层神经网络取代</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725215426788.png"
alt="image-20230725215426788" />
<figcaption aria-hidden="true">image-20230725215426788</figcaption>
</figure>
<p>NeuralCF还提出了将传统矩阵分解方法和深度学习方法融合的模型：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725220107980.png"
alt="image-20230725220107980" />
<figcaption aria-hidden="true">image-20230725220107980</figcaption>
</figure>
<p>左边MF为传统矩阵分解学习的向量，通过元素积让向量在各个维度上成分交叉（取代原来的直接内积）；</p>
<p>右边则是深度学习矩阵分解，最后将两个处理后向量连接再进行评分。</p>
<h2 id="deep-crossing模型-利用dnn自动学习特征交叉">Deep
Crossing模型-利用DNN自动学习特征交叉</h2>
<p>输入特征：</p>
<ol type="1">
<li><p>可以被处理为one-hot或者multi-hop的类别特征</p></li>
<li><p>数组特征</p></li>
<li><p>需要进一步处理的特征</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725112028369.png"
alt="image-20230725112028369" />
<figcaption aria-hidden="true">image-20230725112028369</figcaption>
</figure></li>
</ol>
<p>模型结构：</p>
<ol type="1">
<li>Embedding层：稀疏特征向量转稠密特征向量（有的特征需要，有的特征不需要e.g.数值特征）</li>
<li>Stacking层：把特征embedding拼接在一起（concatenate）</li>
<li>Multiple Residual Units层： 多层MLP＋残差网络</li>
<li>Scoring层：根据具体任务的评分层。CTR问题二分类用逻辑回归模型，多分类用Softmax。</li>
</ol>
<p>意义：</p>
<ol type="1">
<li>无人工参加特征筛选</li>
<li>模型能自动学习特征交叉，模型越深，交叉越深</li>
</ol>
<h2 id="pnn模型-加强特征交叉能力">PNN模型-加强特征交叉能力</h2>
<p>利用乘积层（Product Layer）取代了DeepCrossing中的Stacking层。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725221009996.png"
alt="image-20230725221009996" />
<figcaption aria-hidden="true">image-20230725221009996</figcaption>
</figure>
<p>不同特征的Embedding不再是简单的拼接，而是在Product层进行两两交互，更有针对性的获取特征之间的交互信息。</p>
<p>乘积特征交叉部分又分为内积操作IPNN和外积OPNN操作，其中OPNN在进行外积后得到的是一个矩阵，PNN把所有两两特征Embedding向量外积互操作的结果叠加进行降维。IPNN则是内积得到一个值后concatenate后变成一个向量。</p>
<p>优点：</p>
<p>加强不同特征之间交叉交互。</p>
<p>缺点：</p>
<p>OPNN中粗暴的简化操作可能会丢失信息。</p>
<p>无差别价差特征一定程度上忽略原始特征向量中包含的有价值的信息。</p>
<h2
id="widedeep-记忆能力与泛化能力的综合">Wide&amp;Deep-记忆能力与泛化能力的综合</h2>
<p>wide-让模型更有记忆能力-模型结构简单，原始数据王位可以直接影响推荐结果。</p>
<p>记忆能力可以理解为模型直接学习并利用历史数据中物品或者特征的“共现频率”能力（哪些关键特征会直接导致什么必然结果，e.g.如果点击过A则大概率会点击B）</p>
<p>deep-让模型更有泛化能力</p>
<p>泛化能力可以理解为模型传递特征的相关性以及挖掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726214649249.png"
alt="image-20230726214649249" />
<figcaption aria-hidden="true">image-20230726214649249</figcaption>
</figure>
<p>什么特征输入到Deep什么输入到Wide需要深刻理解应用场景后人工设计，例子：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726214719704.png"
alt="image-20230726214719704" />
<figcaption aria-hidden="true">image-20230726214719704</figcaption>
</figure>
<p>所有特征都被输入到Deep去挖掘深层次关系，只有已安装应用和曝光应用这种直接粗暴对结论有重要直接影响的特征。</p>
<p>在Wide层，Geogle用的交叉积变换处理：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726215115342.png"
alt="image-20230726215115342" />
<figcaption aria-hidden="true">image-20230726215115342</figcaption>
</figure>
<p><span
class="math inline">\(c^{ki}\)</span>是一个布尔变量，当第i个特征属于第k
个组合特征时，c的值为1，否则为0;</p>
<p>x是第i个特征的值。</p>
<p>例如，对于“AND(user_installed app=netflix.impression
app=pandora)”这个组合特征来说只有当“user installed
app=netflix和“impression_app=pandora”这两个特征同时为1时，其对应的交叉积变换层的结果才为1，否则为0。</p>
<h2 id="widecross模型">Wide&amp;Cross模型</h2>
<p>用Cross网络取代Wide&amp;Deep中原来Wide部分，Deep部分没变。</p>
<p>Cross网络能增加特征之间的交互力度</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230727160456625.png"
alt="image-20230727160456625" />
<figcaption aria-hidden="true">image-20230727160456625</figcaption>
</figure>
<p>Cross网络使用多层交叉层，假设第l层输出为<span
class="math inline">\(x_l\)</span>，那么第l+1层输出为： <span
class="math display">\[
x_{l+1}=x_0x_l^TW_l+b_l+x_l
\]</span> 这里的<span
class="math inline">\(x_0\)</span>是将所有输入特征处理好之后concatenate起来的一个向量，不同的维度代表不同的特征。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230727160827480.png"
alt="image-20230727160827480" />
<figcaption aria-hidden="true">image-20230727160827480</figcaption>
</figure>
<p>cross layer的每一层其实是将两个向量A、B矩阵相乘为一个矩阵M，<span
class="math inline">\(M_{ij}\)</span>代表A向量的第i维度与B向量第j维度相乘，这样就将两个向量的每个维度两两相乘，而向量<span
class="math inline">\(x_0\)</span>中的不同维度代表不同特征，也就是让不同特征充分交互。</p>
<p>cross network为1层的时候，我们可以得到的最高是2维的特征交叉；cross
network为2层的时候，我们得到的是最高3维的特征交叉；cross
network为3层的时候，我们得到的是最高4维的特征交叉；以此类推。。。</p>
<p>因此cross
network以一种参数共享的方式，通过对叠加层数的控制，可以高效地学习出低维的特征交叉组合，避免了人工特征工程。</p>
<p>交叉后过一个MLP层，最后再加上交叉前的l层输入，其实就是为了学习残差。</p>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>BasicTurtorial</category>
      </categories>
  </entry>
  <entry>
    <title>Relation-enhance Rec</title>
    <url>/2023/06/17/Relation-enhance_Rec/</url>
    <content><![CDATA[<p>relation-enhance KG</p>
<span id="more"></span>
<h1 id="re-kgr">RE-KGR</h1>
<p>Paper: RE-KGR: Relation-Enhanced Knowledge Graph Reasoning for
Recommendation</p>
<p>总结：把relation当做向量空间，同时考虑relation的方向性，最后基于路径概率预测</p>
<h2 id="methodology">Methodology</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617151926949.png"
alt="image-20230617151926949" />
<figcaption aria-hidden="true">image-20230617151926949</figcaption>
</figure>
<p>given a CKG</p>
<h3 id="embedding-layer">Embedding Layer</h3>
<p>for every entity and relation, one-hot to dense vector</p>
<h3 id="rgc-layer">RGC Layer</h3>
<p><strong>First-order Aggregation</strong>:</p>
<p>project each entity t to a different semantic space conditioned to
the relation r:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153022663.png"
alt="image-20230617153022663" />
<figcaption aria-hidden="true">image-20230617153022663</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153033948.png"
alt="image-20230617153033948" />
<figcaption aria-hidden="true">image-20230617153033948</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153045142.png"
alt="image-20230617153045142" />
<figcaption aria-hidden="true">image-20230617153045142</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153143790.png"
alt="image-20230617153143790" />
<figcaption aria-hidden="true">image-20230617153143790</figcaption>
</figure>
<p>Here, <span class="math inline">\(M_{r−1}\)</span>, <span
class="math inline">\(M_r\)</span> are mapping matrices, and r and r−1
are a pair of inverse relations,such as AuthorOf and WrittenBy.</p>
<p><strong>High-order Aggregation</strong>:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153235776.png"
alt="image-20230617153235776" />
<figcaption aria-hidden="true">image-20230617153235776</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153301643.png"
alt="image-20230617153301643" />
<figcaption aria-hidden="true">image-20230617153301643</figcaption>
</figure>
<p>Here, is the concatenation operator, and e(0) denotes initial
embeddings.(dense connectivity)</p>
<h3 id="local-similarity-layer">Local Similarity Layer</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153403760.png"
alt="image-20230617153403760" />
<figcaption aria-hidden="true">image-20230617153403760</figcaption>
</figure>
<h3 id="prediction-layer">Prediction Layer</h3>
<p>Predict Based on path:</p>
<p>use <span class="math inline">\(P_{UIIP}={(h,r,t)|(h,r,t)\in
G}\)</span> to describe an acyclic UIIP, the probability of the UIIP
is:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153641218.png"
alt="image-20230617153641218" />
<figcaption aria-hidden="true">image-20230617153641218</figcaption>
</figure>
<p>we use Pui to denote all acyclic UIIPs that start and end with user u
and item i.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617153723353.png"
alt="image-20230617153723353" />
<figcaption aria-hidden="true">image-20230617153723353</figcaption>
</figure>
<h1 id="pern">PeRN</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230627183244905.png"
alt="image-20230627183244905" />
<figcaption aria-hidden="true">image-20230627183244905</figcaption>
</figure>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>RippleNet</title>
    <url>/2023/03/02/RippleNet/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="background">Background</h1>
<p><strong>CF</strong>: sparsity, cold start</p>
<p><strong>KG-benefit</strong>:</p>
<ol type="1">
<li>KG introduces semantic relatedness among items, which can help find
their latent connections and improve the <em>precision</em> of
recommended items;</li>
<li>KG consists of relations with various types, which is helpful for
extending a user’s interests reasonably and increasing the
<em>diversity</em> of recommended items;</li>
<li>KG connects a user’s historical records and the recommended ones,
thereby bringing <em>explainability</em> to recommender systems.</li>
</ol>
<p><strong>Existing KG model</strong>:</p>
<ol type="1">
<li><strong>embedding-based method</strong>: DKN, CKE, SHINE, but more
suitable for in-graph applications</li>
<li><strong>path-based method</strong>: rely heavily on manually
designed meta-paths</li>
</ol>
<p>so the author proposes RippleNet:</p>
<ol type="1">
<li>combine embedding-based and path-based() methods
<ol type="1">
<li>RippleNet incorporates the KGE methods into recommendation naturally
by preference propagation;<br />
</li>
<li>RippleNet can automatically discover possible paths from an item in
a user’s history to a candidate item.</li>
</ol></li>
</ol>
<h1 id="method">Method</h1>
<p>专注于挖掘KG中用户感兴趣的实体！！</p>
<h2 id="input">Input</h2>
<p>interaction matrix <strong>Y</strong> <em>and knowledge graph</em>
<strong>G</strong></p>
<h2 id="some-definition">Some definition</h2>
<h3 id="relevant-entity">Relevant entity</h3>
<p>the set of <strong>k</strong>-hop relevant entities for user
<strong>u</strong> is defined as</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302155703683.png"
alt="image-20230302155703683" />
<figcaption aria-hidden="true">image-20230302155703683</figcaption>
</figure>
<p><span class="math inline">\(\varepsilon_u^0=V_u =
\{v|y_{uv}=1\}\)</span> is the items which the user interacts with, and
they can link with entities in knowledge graph</p>
<p>can be seen as the seed set of user u in
KG(就是user如何参与到KG中)</p>
<h3 id="ripple-set">Ripple set</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302155653732.png"
alt="image-20230302155653732" />
<figcaption aria-hidden="true">image-20230302155653732</figcaption>
</figure>
<h2 id="model">Model</h2>
<h3 id="first-layer-propagation">First layer propagation</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302163505799.png"
alt="image-20230302163505799" />
<figcaption aria-hidden="true">image-20230302163505799</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302165453023.png"
alt="image-20230302165453023" />
<figcaption aria-hidden="true">image-20230302165453023</figcaption>
</figure>
<p>v: embedding of item. Item embedding can incorporate one-hot ID ,
attributes of an item, based on the application scenario.</p>
<p>r: embedding of relation between head entity and tail entity.</p>
<p>h: embedding of head entity.</p>
<p>t: embedding of tail entity.</p>
<p>attention weight <span class="math inline">\(p_i\)</span> can be
regarded as the similarity of item <strong>v</strong> and the entity
<span class="math inline">\(h_i\)</span> measured in the space of
relation <span class="math inline">\(r_i\)</span>.</p>
<p><span class="math inline">\(r_i\)</span> is important, since an
item-entity pair may have different similarities when measured by
different relations</p>
<h3 id="multi-layer">Multi-layer</h3>
<p>the second layer just replace v with <span
class="math inline">\(o_u^1\)</span></p>
<p><span class="math display">\[
p_i = softmax(o_u^{1T}R_ih_i) =
\frac{exp(o_u^{1T}T_ih_i)}{\sum_{(h,r,t)\in S_u^2}exp(o_u^{1T}Rh)}
\]</span></p>
<p><span class="math display">\[
o_u^2 = \sum_{(h_i,r_i,t_i)\in S_u^2}p_it_i
\]</span></p>
<p>and third layer replace <span class="math inline">\(o_u^1\)</span>
with <span class="math inline">\(o_u^2\)</span></p>
<p>while</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302165932080.png"
alt="image-20230302165932080" />
<figcaption aria-hidden="true">image-20230302165932080</figcaption>
</figure>
<h3 id="predict">predict</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230302170052985.png"
alt="image-20230302170052985" />
<figcaption aria-hidden="true">image-20230302170052985</figcaption>
</figure>
<h3 id="whole-process">Whole process</h3>
<p><strong>Propagation only used in KG-graph</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/6C506EFAADC22D9AC38B07273F102601.png"
alt="6C506EFAADC22D9AC38B07273F102601" />
<figcaption
aria-hidden="true">6C506EFAADC22D9AC38B07273F102601</figcaption>
</figure>
<p>模型不断扩散，不断获取更高层数neighbor的信息，最后通过加在一起汇总</p>
<p>所以与曾经互动过的item有关系的实体信息（KG信息）汇总为user
embedding，最后再与没互动过的item计算估计互动概率，</p>
<p>所以是否能理解为user汇总的KG信息</p>
<h3 id="loss-function还没想明白">Loss Function（还没想明白）</h3>
<p>别人的笔记：：</p>
<p>这里的分成三个部分：分别是预测分数的交叉熵损失，知识图谱特征表示的损失，参数正则化的损失：</p>
<p>预测部分的损失很好理解，就是用户和该item之间的预测值和真实值的loss</p>
<p>知识图谱特征表示的损失：我们在计算每个阶段的加权求和时上面说了，假设前提是hR=t，这是假设，所以我们需要设一个loss让模型学习，学习的内容就是hR和t之间计算相似度后，预测0,1是否相似</p>
<p>l2正则化损失：每一个hop中h，r，t分别和自己相乘后，求和再求均值得到一个值，即为该loss（这里我理解的不是很深，有了解的可以评论区说说）</p>
<h1 id="experiment">Experiment</h1>
<h1 id="other">Other</h1>
<ol type="1">
<li><p>ripple set 可能太大，</p>
<p>在RippleNet中，我们可以对固定大小的邻居集进行采样，而不是使用完整的纹波集来进一步减少计算开销。</p></li>
</ol>
]]></content>
      <categories>
        <category>RecSys</category>
        <category>KGRec</category>
      </categories>
  </entry>
  <entry>
    <title>Traditional Machine Learning</title>
    <url>/2023/07/10/TraditionalMachineLearning/</url>
    <content><![CDATA[<p>传统机器学习方法</p>
<span id="more"></span>
<h1 id="tree">Tree</h1>
<h2 id="single-tree">Single Tree</h2>
<h3 id="decision-tree">Decision Tree</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230712165541790.png"
alt="image-20230712165541790" />
<figcaption aria-hidden="true">image-20230712165541790</figcaption>
</figure>
<p>决策树重点：挑选重要的特征，越重要的特征放的越接近根节点。</p>
<h4 id="id3">ID3</h4>
<p>ID3算法使用Information Gain信息增益作为挑选特征指标。</p>
<h5 id="entropy-熵">Entropy-熵</h5>
<p>在数学与物理上，熵指混乱程度，或者说值得是变量X的自由度和不确定性。</p>
<p>在计算机理论中，熵度量给定数据中的杂质。 <span
class="math display">\[
Entropy(p)=\sum_{i=1}^C-p_i*log_2(p_i)
\]</span> c : 可能出现的种类数量</p>
<p><span class="math inline">\(p_i\)</span>：第i类的概率</p>
<p>熵越小，数据越纯</p>
<p>example:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230712174626803.png"
alt="image-20230712174626803" />
<figcaption aria-hidden="true">image-20230712174626803</figcaption>
</figure>
<h5 id="information-gain">Information Gain</h5>
<p>Information
Gain计算拆分前后熵的变化，即用拆分特征前的熵减去拆分特征后的平均熵。
<span class="math display">\[
Information Gain =  Entropy(entire\_dataset)-\frac{1}{n}\sum_{i=1}^n
Entropy(child\_dataset_i)
\]</span>
上面式子表示将整个数据集依照某个特征值拆分为了n个子数据集。</p>
<p>example:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230712175543982.png"
alt="也可以" />
<figcaption aria-hidden="true">也可以</figcaption>
</figure>
<p>有的教程会写作：<strong>熵</strong>减去<strong>条件熵</strong></p>
<p>简单认识一下条件熵就好，起码知道词是个啥子意思嘛</p>
<p>熵是对事件结果不确定性的度量，但在知道有些条件时，不确定性会变小。这里的条件就是数据集中的特征。</p>
<p><strong>条件熵</strong>就是已知某个特征X的情况下，事件Y的不确定性
<span class="math display">\[
Entropy(Y|X)=\sum_{i=1}^np_i Entropy(Y|X=x_i)
\]</span> 就是特征X每个可能性的结果的熵乘以发生概率的求和。 <span
class="math display">\[
Information Gain =  Entropy(Y)- Entropy(Y|X)
\]</span></p>
<h5 id="id3缺点">ID3缺点</h5>
<ol type="1">
<li>没有剪枝策略，容易过拟合。</li>
<li>只能用于处理离散分布的特征。</li>
<li>没有考虑缺失值。</li>
<li>InformationGain对可取数值数目较多的特征有所偏好，类似‘ID’的特征其信息增益接近于1。</li>
</ol>
<h4 id="c4.5">C4.5</h4>
<p>使用Information Gain
Ratio信息增益率作为挑选指标，减少因特征值类别多导致信息增益大的问题。同时引入了剪枝策略。</p>
<h5 id="information-gain-ratio">Information Gain Ratio</h5>
<p><span class="math display">\[
IGR = \frac{IG(feature,dataset)}{Entropy(feature)}
\]</span></p>
<p>Entropy(feature):
特征的固有值，即是特征的纯度，（之前求得都是label的熵）公式如下： <span
class="math display">\[
Entropy_A(dataset) = -\sum_{i=1}^np_i*log_2(p_i)
\]</span> c : A中可能出现的种类数量</p>
<p><span class="math inline">\(p_i\)</span>：A为第i类的概率</p>
<p>这能解决ID3的第四个缺点，特征可能类别越多（越细致），纯度低，熵越高，分母越大</p>
<h5 id="剪枝策略">剪枝策略</h5>
<p>剪枝缓解决策树过拟合</p>
<h6 id="预剪枝">预剪枝</h6>
<p>生成决策树过程中剪枝</p>
<ol type="1">
<li>提前设定决策树的高度，当达到这个高度时，就停止构建决策树；</li>
<li>当达到某节点的实例具有相同的label，也可以停止树的生长；</li>
<li>提前设定某个阈值，当达到某个节点的样例个数小于该阈值的时候便可以停止树的生长，但这种方法的缺点是对数据量的要求较大，无法处理数据量较小的训练样例；</li>
<li>同样是设定某个阈值，每次扩展决策树后都计算其对系统性能的增益，若小于该阈值，则让它停止生长。</li>
</ol>
<p>预剪枝的显著缺点是视野效果。因为剪枝是伴随着构建决策树同时进行的，构建者无法预知下一步可能会发生的事，会出现某种情况，在相同标准下，当前决策树不满足要求最开始的构建要求、构建者进行了剪枝，但实际上若进行进一步构建后、决策树又满足了要求。这种情况下，预剪枝会过早停止决策树的生长。</p>
<p>C4.5算法常选择后剪枝的方法消除决策树的过度拟合</p>
<h6 id="后剪枝">后剪枝</h6>
<p>在已经生成的决策树上剪枝</p>
<p>用递归的方式从低往上针对每一个非叶子节点，评估用一个叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。C4.5
通过训练数据集上的错误分类数量来估算未知样本上的错误率。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h5 id="优点">优点</h5>
<ol type="1">
<li><p>解决特征值类别多导致信息增益大的问题</p></li>
<li><p>引入剪枝</p></li>
<li><p>增加对连续特征值的处理：将连续特征离散化，假设 n 个样本的连续特征
A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1
个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</p></li>
<li><p>增加对缺失值处理：</p>
<ol type="1">
<li><p>在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）</p>
<p>C4.5
的做法是：对于具有缺失值特征，用没有缺失的样本子集占整个数据集的比重来折算；</p></li>
<li><p>选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）</p>
<p>C4.5
的做法是：将样本同时划分到所有子节点。不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p></li>
</ol></li>
</ol>
<h5 id="缺点">缺点</h5>
<ol type="1">
<li>依然不能处理回归问题</li>
<li>使用的熵模型拥有大量耗时的对数运算，连续值还有排序运算；</li>
<li>用的是多叉树，用二叉树效率更高；</li>
<li>在构造树的过程中，对数值属性值需要按照其大小进行排序，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ol>
<h3 id="cart--classification-and-regression-tree">CART- classification
and regression tree</h3>
<p>CART是决策树的延伸，也可以看作特殊的决策树。他建立起来的是二叉树，而不是多叉树。</p>
<p>可以不仅可以解决分类问题，还可以觉得回归问题</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230717124658992.png"
alt="image-20230717124658992" />
<figcaption aria-hidden="true">image-20230717124658992</figcaption>
</figure>
<h4 id="classification">Classification</h4>
<p>特征挑选指标：Gini index</p>
<p>基尼系数越小，纯度越高，特征越好。</p>
<h5 id="gini值">Gini值</h5>
<p>Gini值反应了从数据集D中随机抽取两个样本，其类别不一样的概率。 <span
class="math display">\[
Gini(D) = \sum_{i=1}^np(x_i)*(1-p(x_i))=1-\sum_{i=1}^np(x_i)^2
\]</span> <span class="math inline">\(p(x_i)\)</span>: <span
class="math inline">\(x_i\)</span>出现的概率</p>
<p>n：类别数量</p>
<h5 id="分类树的构造">分类树的构造</h5>
<p>递归生成二叉树，以Gini值最小化作为准则。</p>
<ol type="1">
<li><p>遍历所有特征<span class="math inline">\(A\)</span>,遍历特征<span
class="math inline">\(A\)</span>所有的可能取值<span
class="math inline">\(a\)</span>，根据特征A
是否取某一可能值a，把样本D分成两部分<span
class="math inline">\(D_1\)</span>和<span
class="math inline">\(D_2\)</span>。计算Gini值，将Gini值最小的<span
class="math inline">\(A,a\)</span>作为最优特征与最优切分点。 <span
class="math display">\[
D_1 = (x,y)\in D |A(x)=a,D_2 = D-D_1
\]</span></p>
<p><span class="math display">\[
Gini(D|A=a) = \frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)
\]</span></p></li>
<li><p>循环1步骤</p></li>
</ol>
<h4 id="regression">Regression</h4>
<p>递归生成二叉树，使用平方误差最小化作为准则。</p>
<p>假设有n个样本<span
class="math inline">\(D={(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)}\)</span>,其中x是d维向量，代表d个特征，y是连续值。</p>
<p>CART回归树生成算法：</p>
<ol type="1">
<li><p>遍历所有特征<span
class="math inline">\(d_i\)</span>,遍历n个样本在<span
class="math inline">\(d_i\)</span>特征的取值x，取相邻两样本值x(排序后)的平均数s作为划分点，利用s作为划分两个区域的阈值：
<span class="math display">\[
R_1 = \{y_i|x_{i,d_i}&lt;=s\},R_2 = \{y_i|x_{i,d_i}&gt;s\}
\]</span> 每个区域内样本<span
class="math inline">\(y_i\)</span>的均值作为该区域的预测值<span
class="math inline">\(c_1,
c_2\)</span>，计算样本真实值和预测值的平方误差之和,并找到能使平方误差最小的<span
class="math inline">\(d_i\)</span>和<span
class="math inline">\(s\)</span>: <span class="math display">\[
c_1 = \frac{1}{n}\sum_{x_i\in R_1}y_i,c_2 = \frac{1}{n}\sum_{x_i\in
R_2}y_i,
\]</span></p>
<p><span class="math display">\[
\min_{d_i,s}\{\sum_{x_i\in R_1(d_i,s)}(y_i-c_1)^2+\sum_{x_i\in
R_2(d_i,s)}(y_i-c_2)^2\}
\]</span></p></li>
<li><p>重复1直到满足停止条件</p></li>
<li><p>最后划分为M区域<span
class="math inline">\(R_1,R_2,\cdots,R_M\)</span>,生成决策树,预测值为：
<span class="math display">\[
f(x)=\sum_{i=1}^Mc_iI(x\in R_i)
\]</span> 这里的<span class="math inline">\(I(x\in
R_i)\)</span>值，满足条件返回值为1，否则为0</p></li>
</ol>
<h2 id="several-tree">Several tree</h2>
<h3 id="bagged-decision-tree">Bagged Decision Tree</h3>
<p>单棵的决策树高方差（不同训练集训练的预测结果差很多，不稳定），Bagged
Decisoin Tree要解决这个问题。</p>
<p>使用Bootstrap生成多个训练集。它基于有放回地从原始训练数据集中抽取样本，构成一个新的训练集。通过对原始数据集的多次重采样，可以生成多个不同的训练集，每个训练集都是原始数据集的一部分。接着将每轮未抽取的数据合并形成<strong>袋外数据集</strong>（Out
of Bag, OOB），用于模型中的测试集。</p>
<p>使用Bagging进行训练和预测。通过在 Bootstrap
生成的多个训练集上训练多个独立的基础模型，并将它们的预测结果进行平均或投票来进行最终预测。每个基础模型都是独立训练的，它们之间没有依赖关系。Bagging
可以减少模型的方差，提高模型的稳定性和泛化能力。</p>
<h3 id="random-forest">Random Forest</h3>
<p>随机森林使用的方法与Bagged Decision
Tree一样使用Bootstrap和Bagging方法，但做出了改进。</p>
<p>决策树使用的是贪心策略，每一步都是局部最优解，但每次的局部最优解不一定能得到全局最优解。而且Bagging后，我们可能会得到几个非常相似的局部最优解树。</p>
<p>所以随机森林加入随机策略，鲁棒性会更强。</p>
<h4 id="构建随机森林">构建随机森林</h4>
<ol type="1">
<li>使用Bootstrap策略，有放回的抽取sample生成N个训练集，每个训练集可以训练出一个子模型。</li>
<li>训练单棵决策树
<ol type="1">
<li>每个sample有M个特征，在决策树的每个节点需要分裂的时候，随机从M个特种中选取m个特征，满足条件m
&lt;&lt;
M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。（这样让决策树不要过分关心一个重要特征，鲁棒性更强）</li>
<li>循环1步骤</li>
</ol></li>
</ol>
<h3 id="gbdt">GBDT</h3>
<p>使用Boosting思想，以决策树为基函数的提升方法称为提升决策树。保证每棵树都是低方差，高偏差。</p>
<p><a
href="https://zhuanlan.zhihu.com/p/280222403">GBDT的原理、公式推导、Python实现、可视化和应用
- 知乎 (zhihu.com)</a></p>
<h4 id="算法">算法</h4>
<p>!<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720171728041.png"
alt="image-20230720171728041" />]</p>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>常见激活函数</title>
    <url>/2023/02/28/activate_function/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="常见激活函数">常见激活函数</h1>
<p>激活函数作用：加入非线性因素</p>
<h2 id="sigmoid">Sigmoid</h2>
<p><span class="math display">\[
\sigma(x) = \frac{1}{1+exp(-x)}
\]</span></p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230228224935533.png" alt="image-20230228224935533" style="zoom:40%;" /></p>
<p>输出的值范围在[0,1]之间。但是<code>sigmoid</code>型函数的输出存在<strong>均值不为0</strong>的情况，并且存在<strong>梯度消失的问题</strong>，在深层网络中被其他激活函数替代。在<strong>逻辑回归</strong>中使用的该激活函数用于输出<strong>分类</strong>。</p>
<h3 id="求导公式">求导公式</h3>
<p>链式法则</p>
<h3 id="梯度消失原因">梯度消失原因：</h3>
<p><span class="math display">\[
\sigma&#39;(x) = \sigma\space \cdot (1-\sigma)
\]</span></p>
<ol type="1">
<li>sigmoid函数两边的斜率趋向0，很难继续学习</li>
<li>sigmoid导数两个部分都小于1，在深层神经网络中，靠前layer参数会因为后面多层sigmoid导数叠加（链式法则）导致更新的特别慢。</li>
</ol>
<h3 id="缺点解决办法">缺点解决办法</h3>
<ol type="1">
<li>在深层网络中被其他激活函数替代。如<code>ReLU(x)</code>、<code>Leaky ReLU(x)</code>等</li>
<li>在分类问题中，sigmoid做激活函数时，使用交叉熵损失函数替代均方误差损失函数。</li>
<li>采用正确的权重初始化方法（让初始化的数据尽量不要落在梯度消失区域）</li>
<li>加入BN层（同上，避免数据落入梯度消失区）</li>
<li>分层训练权重</li>
</ol>
<h2 id="tanh">tanh</h2>
<p><span class="math display">\[
tanh(x) = \frac{e^x-e^{(-x)}}{e^x+e^{(-x)}} =\frac{e^{2x}-1}{e^{2x}+1}=
2 \cdot sigmoid(2x)-1
\]</span></p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194241514.png" alt="image-20230307194241514" style="zoom:67%;" /></p>
<p><code>tanh(x)</code>型函数可以解决<code>sigmoid</code>型函数的<strong>期望（均值）不为0</strong>的情况。函数输出范围为(-1,+1)。但<code>tanh(x)</code>型函数依然存在<strong>梯度消失的问题</strong>。</p>
<p>在LSTM中使用了<code>tanh(x)</code>型函数。</p>
<h2 id="relu">Relu</h2>
<p><code>ReLU(x)</code>型函数可以有效避免<strong>梯度消失的问题</strong>，公式如下：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230228222815687.png"
alt="image-20230228222815687" />
<figcaption aria-hidden="true">image-20230228222815687</figcaption>
</figure>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194352199.png" alt="image-20230307194352199" style="zoom:67%;" /></p>
<p><code>ReLU(x)</code>型函数的缺点是<strong>负值成为“死区”</strong>，神经网络无法再对其进行响应。Alex-Net使用了<code>ReLU(x)</code>型函数。当我们训练深层神经网络时，最好使用<code>ReLU(x)</code>型函数而不是<code>sigmoid(x)</code>型函数。</p>
<p>ReLU梯度稳定，值还比sigmoid大，所以<strong>可以加快网络训练</strong>。</p>
<p>但是要注意，我们在输入图像时就要注意，应该使用Min-Max归一化，而不能使用Z-score归一化。（避免进入死区）</p>
<h3 id="在0点不可导">在0点不可导</h3>
<p>人为将梯度规定为0（源码就是这么写的）</p>
<h2 id="relu6">Relu6</h2>
<p>Relu的正值输出是[0，无穷大]，但计算机内存优先，所以限定relu最大值为6</p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194457525.png" alt="image-20230307194457525" style="zoom:67%;" /></p>
<h2 id="leakyrelu">LeakyRelu</h2>
<p>为<strong>负值增加了一个斜率</strong>，缓解了“死区”现象，公式如下：</p>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194659126.png" alt="image-20230307194659126" style="zoom:67%;" /></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230228222900735.png"
alt="image-20230228222900735" />
<figcaption aria-hidden="true">image-20230228222900735</figcaption>
</figure>
<p><code>Leaky ReLU(x)</code>型函数缺点是，<strong>超参数a（阿尔法）合适的值不好设定</strong>。当我们想让神经网络能够学到负值信息，那么使用该激活函数。</p>
<h2 id="p-relu-参数化relu">P-Relu 参数化Relu</h2>
<p>数化ReLU（P-ReLU）。参数化ReLU为了解决超参数a（阿尔法）合适的值不好设定的问题，干脆将这个参数也融入模型的整体训练过程中。也使用误差反向传播和随机梯度下降的方法更新参数。</p>
<h2 id="r-relu-随机化relu">R-Relu 随机化Relu</h2>
<p>就是超参数a（阿尔法）随机化，<strong>让不同的层自己学习不同的超参数</strong>，但随机化的超参数的分布符合均值分布或高斯分布。</p>
<h2 id="mish激活函数">Mish激活函数</h2>
<p><img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194824945.png" alt="image-20230307194824945" style="zoom:67%;" />
<span class="math display">\[
Mish(x) = x\cdot tanh(log(1+e^x))
\]</span></p>
<p>在负值中，允许有一定的梯度流入。</p>
<h2 id="elu指数化线性单元">ELU指数化线性单元</h2>
<p>也是为了解决死区问题，公式如下：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307194918301.png"
alt="image-20230307194918301" />
<figcaption aria-hidden="true">image-20230307194918301</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230228224119801.png"
alt="image-20230228224119801" />
<figcaption aria-hidden="true">image-20230228224119801</figcaption>
</figure>
<p>缺点是<strong>指数计算量大</strong>。</p>
<h2 id="maxout">Maxout</h2>
<p>就是用一个MLP层作为激活函数。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307195003327.png"
alt="image-20230307195003327" />
<figcaption aria-hidden="true">image-20230307195003327</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307195013184.png"
alt="image-20230307195013184" />
<figcaption aria-hidden="true">image-20230307195013184</figcaption>
</figure>
<p>与常规的激活函数不同，<strong>Maxout</strong>是一个可以学习的<strong>分段线性函数</strong>。其原理是，任何ReLU及其变体等激活函数都可以看成分段的线性函数，而Maxout加入的一层神经元正是一个可以学习参数的分段线性函数。</p>
<p>优点是其拟合能力很强，理论上可以拟合任意的凸函数。缺点是参数量激增！在Network-in-Network中使用的该激活函数。</p>
<h1 id="softmax求导">Softmax求导</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307195822249.png"
alt="image-20230307195822249" />
<figcaption aria-hidden="true">image-20230307195822249</figcaption>
</figure>
<p>要结合交叉熵loss函数考虑</p>
<p><span class="math inline">\(\frac{dL}{dz}=\frac{dL}{da}\cdot
\frac{da}{dz}\)</span></p>
<p>假设第j个类别是正确的，<span
class="math inline">\(y_j=1\)</span>,其它为0</p>
<p><span class="math inline">\(L = -\sum_{i=1}^ny_iln(a_i)\)</span></p>
<p><span class="math inline">\(\frac{dL}{da} =
-y_iln(a_j)=-ln(a_j)\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307200559541.png"
alt="image-20230307200559541" />
<figcaption aria-hidden="true">image-20230307200559541</figcaption>
</figure>
<p>所以最终Loss只跟label类别有关</p>
<p>所以当i=j：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307201705230.png"
alt="image-20230307201705230" />
<figcaption aria-hidden="true">image-20230307201705230</figcaption>
</figure>
<p>当i!=j:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307201737792.png"
alt="image-20230307201737792" />
<figcaption aria-hidden="true">image-20230307201737792</figcaption>
</figure>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>算法</title>
    <url>/2023/02/13/algorithm/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="二叉树">二叉树</h1>
<h2 id="完全二叉树">完全二叉树</h2>
<ol type="1">
<li>树的深度=一直遍历最左节点的长度</li>
<li>左子树深度==右子树深度，左子树是全满的完全二叉树，如果左子树深度大于右子树深度，右子树是全满的完全二叉树</li>
</ol>
<h2 id="平衡二叉树">平衡二叉树</h2>
<p>所有节点左右子树高度不大于1</p>
<h1 id="字典序">字典序</h1>
<p>就是按照字典排列顺序，英文字母按下面方式排列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ABCDEFG HIJKLMN OPQRST UVWXYZ</span><br><span class="line">abcdefg hijklmn opqrst uvwxyz</span><br></pre></td></tr></table></figure>
<h1 id="回溯">回溯</h1>
<h2 id="显回溯">显回溯</h2>
<p>pre是公共变量，遍历完这种情况要记得pop（），加入结果时记得copy（）</p>
<h2 id="隐回溯">隐回溯</h2>
<p>pre是函数内传递的变量，直接传就ok</p>
<h2 id="去重">去重</h2>
<h3 id="去res中重复元素">去res中重复元素</h3>
<ol type="1">
<li><p>排序数组</p>
<p>可以用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">num[i]=num[i-1]跳过同层重复元素的选取（注意：子层不跳过）</span><br></pre></td></tr></table></figure></li>
<li><p>set去重</p></li>
</ol>
<h3 id="排序问题去重">排序问题去重</h3>
<p>使用used数组</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">used=[True, ..., False, False]</span><br></pre></td></tr></table></figure>
<h1 id="位运算">位运算</h1>
<h2 id="基础操作">基础操作</h2>
<h3 id="取反">取反</h3>
<p>异或操作，要取反的区域为1，不取反区域为0</p>
<h1 id="优先队列">优先队列</h1>
<ol type="1">
<li><p>使用heapq实现</p>
<p><a
href="https://docs.python.org/2/library/heapq.html#basic-examples">8.4.
heapq — Heap queue algorithm — Python 2.7.18 documentation</a></p></li>
</ol>
<p>​ 只能实现最小堆，通过再所有元素前加-号这个trick可实现最大堆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pq=[]</span><br><span class="line">heapq.heappush(pq,a)</span><br><span class="line">heapq.heappop(pq)</span><br></pre></td></tr></table></figure>
<p>​ 优先队列的元素可以是tuple</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; h = []</span><br><span class="line">&gt;&gt;&gt; heappush(h, (5, &#x27;write code&#x27;))</span><br><span class="line">&gt;&gt;&gt; heappush(h, (7, &#x27;release product&#x27;))</span><br><span class="line">&gt;&gt;&gt; heappush(h, (1, &#x27;write spec&#x27;))</span><br><span class="line">&gt;&gt;&gt; heappush(h, (3, &#x27;create tests&#x27;))</span><br><span class="line">&gt;&gt;&gt; heappop(h)</span><br><span class="line">(1, &#x27;write spec&#x27;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
  </entry>
  <entry>
    <title>蛋糕烘焙</title>
    <url>/2023/02/14/bakery/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="巴斯克">巴斯克</h1>
<h2 id="抹茶巴斯克">抹茶巴斯克</h2>
<p>6寸模具(直径15cm)</p>
<h3 id="材料">材料</h3>
<p>白巧克力：120g</p>
<p>抹茶：23g</p>
<p>奶油奶酪：230g</p>
<p>细砂糖60g</p>
<p>常温鸡蛋：3个</p>
<p>蛋黄：1个</p>
<p>马斯卡彭50g</p>
<p>淡奶油：230g</p>
<h3 id="做法">做法</h3>
<ul>
<li>120g白巧克力隔水融化</li>
<li>加入23g抹茶粉搅拌均匀</li>
<li>230g奶油奶酪隔水融化，搅拌丝滑</li>
<li>加入50g白砂糖搅拌均匀</li>
<li>加入鸡蛋、蛋黄、马斯卡彭、淡奶油搅拌均匀</li>
<li>加入抹茶巧克力搅拌均匀</li>
<li>过筛，倒入模具</li>
<li>230度烤19~21分钟左右，上色满意盖上锡纸</li>
</ul>
<h3 id="要点">要点</h3>
<p>奶油奶酪选用很重要，铁塔牌更酸一点，kiri没那么酸</p>
]]></content>
      <categories>
        <category>baked food</category>
      </categories>
  </entry>
  <entry>
    <title>Hyper Knowledge Graph</title>
    <url>/2023/06/17/hyper-knowledgegraph/</url>
    <content><![CDATA[<p>Hypergraph knowledge graph</p>
<span id="more"></span>
<h1 id="khnn">KHNN</h1>
<p>Paper: Knowledge-Aware Hypergraph Neural Network for Recommender
Systems</p>
<p>总结：用CKAN方法表示user和item，用hyperedge将l-hop的node全部连在一起，用（l-1）hop和l-hop
concate卷积计算出l-hop节点的权重与l-hop节点相乘，再做conv最后得到该层的一维embedding，然后再aggregation</p>
<h2 id="methodology">Methodology</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617154902916.png"
alt="image-20230617154902916" />
<figcaption aria-hidden="true">image-20230617154902916</figcaption>
</figure>
<h3 id="knowledge-aware-hypergraph-construction">Knowledge-Aware
Hypergraph Construction</h3>
<p><strong>Initial Hyperedge Construction</strong></p>
<p>use user’s interacted items to represent user u</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617155650437.png"
alt="image-20230617155650437" />
<figcaption aria-hidden="true">image-20230617155650437</figcaption>
</figure>
<p>use items, which have been watched by the same user, to construct the
initial item set of item v</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617155746509.png"
alt="image-20230617155746509" />
<figcaption aria-hidden="true">image-20230617155746509</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617155754397.png"
alt="image-20230617155754397" />
<figcaption aria-hidden="true">image-20230617155754397</figcaption>
</figure>
<p><strong>Knowledge Hyperedge Construction</strong></p>
<p>让l-hop neighbor 与(l-1)-hop
neighbor在相连，即所有节点被一条hyper-edge相连，主要服务于下面的neighborhood
convolution</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617161110960.png"
alt="image-20230617161110960" />
<figcaption aria-hidden="true">image-20230617161110960</figcaption>
</figure>
<h3 id="knowledge-aware-hypergraph-convolution"><strong>Knowledge-Aware
Hypergraph Convolution</strong></h3>
<p><strong>Neighborhood Convolution</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162200596.png"
alt="image-20230617162200596" />
<figcaption aria-hidden="true">image-20230617162200596</figcaption>
</figure>
<ol type="1">
<li><p>learn the transform matrix T from the entity vectors in both
l-order and l-1-order hyperedges for vector permutation and
weighting(entity vectors in l-order) . use 1-d conv to generate T , use
another 1-d conv to aggregate the transformed vectors.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162545551.png"
alt="image-20230617162545551" />
<figcaption aria-hidden="true">image-20230617162545551</figcaption>
</figure>
<p><em>conv</em>1 and <em>conv</em>2 are 1-dimension convolution but
withdifffferent out channels.</p></li>
<li><p>for the initial hyper-edge</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162625945.png"
alt="image-20230617162625945" />
<figcaption aria-hidden="true">image-20230617162625945</figcaption>
</figure></li>
<li><p>add item v information</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162651714.png"
alt="image-20230617162651714" />
<figcaption aria-hidden="true">image-20230617162651714</figcaption>
</figure></li>
<li><p>combine</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162708343.png"
alt="image-20230617162708343" />
<figcaption aria-hidden="true">image-20230617162708343</figcaption>
</figure></li>
<li><p>aggregation</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617162731699.png"
alt="image-20230617162731699" />
<figcaption aria-hidden="true">image-20230617162731699</figcaption>
</figure></li>
</ol>
<h1 id="lgcl">LGCL</h1>
<p>Paper：Line Graph Contrastive Learning for Link Prediction</p>
<h2 id="methodology-1">Methodology</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617174642449.png"
alt="image-20230617174642449" />
<figcaption aria-hidden="true">image-20230617174642449</figcaption>
</figure>
<h1 id="hpr">HPR</h1>
<p>Paper: Empowering Knowledge Graph Construction with Hyper-graph for
Personalized Recommendation</p>
<p>basic idea: You might like something that someone with similar
preferences likes you.</p>
<p>总结：将相似度高的user作为hyper-edge（本质上是扩展了target
user的1-hop neighbor），通过计算user的l-hop neighbor与target
item的相似度来计算出user的embedding</p>
<h2 id="methodology-2">Methodology</h2>
<p>we would like to calculate the probability of <span
class="math inline">\(u_1\)</span> will interact with <span
class="math inline">\(i\)</span></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617144000884.png"
alt="image-20230617144000884" />
<figcaption aria-hidden="true">image-20230617144000884</figcaption>
</figure>
<h3 id="hyper-graph-learning">Hyper-graph learning</h3>
<ol type="1">
<li>adopt the cosine similarity to estimate the relevance between
users.</li>
<li>select some users with the highest similarity as the
hyper-edge.</li>
</ol>
<p>这里假设u1与u2最为相似，所以将u1、u2成为一条hypergraph</p>
<h3 id="knowledge-graph-construction">Knowledge Graph Construction</h3>
<p>given:</p>
<p><span class="math inline">\(\vec{i}\)</span>: the embedding of item
i</p>
<p><span class="math inline">\(S_{u_l}^1\)</span>​ : the l-hop neighbor
of user1, which takes the entities which with implicit interaction
behaviour with users as head entities.</p>
<p><span class="math inline">\(S_{u_2}^l\)</span> : the l-hop neighbor
of user2, because there is a hyperedge consist of u1 and u2</p>
<p>1-hop cal:</p>
<p>gain information between item-i and the 1-hop neighbor of user</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617151011714.png"
alt="image-20230617151011714" />
<figcaption aria-hidden="true">image-20230617151011714</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617150959919.png"
alt="image-20230617150959919" />
<figcaption aria-hidden="true">image-20230617150959919</figcaption>
</figure>
<p><span class="math inline">\(N_u^1:S^1_{u_1} \or S^1_{u_2}\)</span>
user one-hop neighbor (include hyperedge)</p>
<p>multi-hop cal: get <span class="math inline">\(q_u^{l}\)</span></p>
<p>the user embedding:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617151325200.png"
alt="image-20230617151325200" />
<figcaption aria-hidden="true">image-20230617151325200</figcaption>
</figure>
<p>predict:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230617151352536.png"
alt="image-20230617151352536" />
<figcaption aria-hidden="true">image-20230617151352536</figcaption>
</figure>
<h1 id="hype">HypE</h1>
<p>Paper:Knowledge Hypergraphs: Extending Knowledge Graphs Beyond Binary
Relations</p>
<p>score： convolution-based embedding method for knowledge
hypergraph</p>
<p>总结：做KG图的连接预测，无GNN方法，主要是embedding计算方法。考虑到entity在triple中的i个位置，在这个位置有训练出来的filter，对embbeding进行转换，最后计算概率score，</p>
<p>计算成本较低。</p>
]]></content>
      <categories>
        <category>GNN</category>
        <category>hypergraph</category>
      </categories>
  </entry>
  <entry>
    <title>常见损失函数</title>
    <url>/2023/02/28/loss_function/</url>
    <content><![CDATA[<p>常见损失函数及常见问题</p>
<span id="more"></span>
<h1 id="常见损失函数">常见损失函数</h1>
<p><strong>损失函数</strong>用来评价模型的<strong>预测值</strong>和<strong>真实值</strong>不一样的程度，在模型正常拟合的情况下，损失函数值越低，模型的性能越好。不同的模型用的损失函数一般也不一样。</p>
<p><strong>损失函数</strong>分为<strong>经验风险损失函数</strong>和<strong>结构风险损失函数</strong>。经验风险损失函数指<strong>预测结果</strong>和<strong>实际结果</strong>的差值，结构风险损失函数是指<strong>经验风险损失函数</strong>加上<strong>正则项</strong>。</p>
<h2 id="常用">常用</h2>
<h3 id="用于回归">用于<strong>回归</strong>：</h3>
<h4 id="绝对值损失函数">绝对值损失函数</h4>
<p><span class="math display">\[
L(Y,f(x)) = |Y-f(x)|
\]</span></p>
<h4 id="平方损失函数">平方损失函数</h4>
<p><span class="math display">\[
L(Y,f(x)) = (Y-f(x))^2
\]</span></p>
<p>对n个数据求平方损失后加和求平均叫<strong>均方误差MSE</strong>，常在<strong>线性回归</strong>使用
<span class="math display">\[
\frac{1}{N}\sum_n(Y-f(x))^2
\]</span></p>
<h3 id="用于分类">用于分类</h3>
<h4 id="损失函数zero-one-loss">0-1损失函数（zero-one loss）</h4>
<p><span class="math display">\[
L(Y,f(x)) = \left\{
\begin{array}{rcl}
1   &amp;   &amp;{Y!=f(x)}\\
0   &amp;   &amp;{Y=f(x)}
\end{array} \right.
\]</span></p>
<p>非黑即白，过于严格，用的很少，比如<strong>感知机</strong>用。</p>
<p>可通过设置阈值放宽条件 <span class="math display">\[
L(Y,f(x)) = \left\{
\begin{array}{rcl}
1   &amp;   &amp;{|Y-f(x)&gt;=T}\\
0   &amp;   &amp;{|Y-f(x)&lt;T}
\end{array} \right.
\]</span></p>
<h4 id="对数损失函数log-loss">对数损失函数（log loss）</h4>
<p><span class="math display">\[
L(Y,P(Y|X)) = -logP(Y|X)
\]</span></p>
<p>Y为真实分类，<span
class="math inline">\(P(Y|X)\)</span>为X条件下分类为Y的概率。用于最大似然估计，等价于交叉熵损失函数</p>
<p>加负号原因：习惯在模型更准确的情况下，loss函数越小</p>
<p>加log原因：这和最大（极大）似然估计有关，对数损失是用于最大似然估计的。</p>
<p><strong>最大似然估计</strong>：<strong>利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值</strong>。</p>
<p>我们假定一组参数（<span
class="math inline">\(\Theta\)</span>）在一堆数据（样本结果<span
class="math inline">\(x_1,x_2...\)</span>）下的<strong>似然值</strong>为<code>P(θ|x1,x2,...,xn)=P(x1|θ)*P(x2|θ)*...*P(xn|θ)</code>，可以看出来，似然值等于每一条数据在这组参数下的条件概率<strong>之积</strong>。求概率是<strong>乘性</strong>，而求损失是<strong>加性</strong>，所以才需要借助log（对数）来<strong>转积为和</strong>，另一方面也是为了简化运算。</p>
<p>对数损失在<strong>逻辑回归</strong>和<strong>多分类任务</strong>上广泛使用。交叉熵损失函数的标准型就是对数损失函数，本质没有区别。</p>
<h4 id="交叉熵损失函数">交叉熵损失函数</h4>
<p>双分类： <span class="math display">\[
L(Y,f(x)) = -[Ylnf(x)+(1-y)ln(1-f(x))]
\]</span> 多分类： <span class="math display">\[
L(Y,f(x)) = -Ylnf(x)
\]</span></p>
<h4 id="合页损失函数hinge-loss">合页损失函数(hinge loss)</h4>
<p><span class="math display">\[
L(Y,f(x)) = max(0, 1-Y\cdot f(x))
\]</span></p>
<p>SVM就是使用的合页损失，还加上了正则项。公式意义是，当样本被正确分类且函数间隔大于1时，合页损失是0，否则损失是<span
class="math inline">\(1-Y\cdot f(x)\)</span>.</p>
<p>SVM中<span class="math inline">\(Y\cdot
f(x)\)</span>为函数间隔，对于函数间隔：</p>
<ol type="1">
<li><p>正负</p>
<p>当样本被正确分类时，<span class="math inline">\(Y\cdot
f(x)&gt;0\)</span>；当样本被错误分类时，<span
class="math inline">\(Y\cdot f(x)&lt;0\)</span>。</p></li>
<li><p>大小</p>
<p><span class="math inline">\(Y\cdot
f(x)\)</span>的绝对值代表样本距离决策边界的远近程度。<span
class="math inline">\(Y\cdot
f(x)\)</span>的绝对值越大，表示样本距离决策边界越远。因此，我们可以知道：</p></li>
</ol>
<p>​ 当<span class="math inline">\(Y\cdot f(x)&gt;0\)</span>时，<span
class="math inline">\(Y\cdot
f(x)\)</span>的绝对值越大表示决策边界对样本的区分度越好</p>
<p>​ 当<span class="math inline">\(Y\cdot f(x)&lt;0\)</span>时，<span
class="math inline">\(Y\cdot
f(x)\)</span>的绝对值越大表示决策边界对样本的区分度越差</p>
<h4 id="指数损失函数exponential-loss">指数损失函数(exponential
loss)</h4>
<p><span class="math display">\[
L(Y,f(x)) = exp(-Y\cdot f(x)) = \frac{exp(f(x))}{exp(Y)}
\]</span></p>
<p>常用于AdaBoost算法，</p>
<p><strong>那么为什么AdaBoost算法使用指数损失函数，而不使用其他损失函数呢？</strong></p>
<p>这是因为，当<strong>前向分步算法的损失函数是指数损失函数</strong>时，其学习的具体操作等价于AdaBoost算法的学习过程。</p>
<h3 id="用于分割">用于分割</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230221201538734.png"
alt="image-20230221201538734" />
<figcaption aria-hidden="true">image-20230221201538734</figcaption>
</figure>
<h3 id="用于检测">用于检测</h3>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230228205041367.png"
alt="image-20230228205041367" />
<figcaption aria-hidden="true">image-20230228205041367</figcaption>
</figure>
<h1 id="常见损失函数问题">常见<strong>损失函数问题</strong></h1>
<h2 id="交叉熵相关">交叉熵相关</h2>
<h3
id="交叉熵函数与最大似然函数的联系和区别">交叉熵函数与最大似然函数的联系和区别？</h3>
<p><strong>区别</strong>：</p>
<p><strong>交叉熵函数</strong>使用来描述模型预测值和真实值的差距大小，越大代表越不相近；</p>
<p><strong>极大似然</strong>就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！即“模型已定，参数未知”</p>
<p><strong>联系</strong>：</p>
<p><strong>交叉熵函数</strong>可以由<strong>最大似然函数</strong>在<strong>伯努利分布</strong>的条件下推导出来，或者说<strong>最小化交叉熵函数</strong>的本质就是<strong>对数似然函数的最大化</strong>。</p>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/IMG_0115(20230224-203706).PNG" /></p>
<h3
id="在用sigmoid作为激活函数的时候为什么要用交叉熵损失函数而不用均方误差损失函数">在用sigmoid作为激活函数的时候，为什么要用交叉熵损失函数，而不用均方误差损失函数？</h3>
<p>另一个问法其实是在分类问题中为什么不用均方误差做损失函数。</p>
<ol type="1">
<li><p><strong>sigmoid</strong>作为激活函数的时候，如果采用<strong>均方误差损失函数</strong>，那么这是一个<strong>非凸优化</strong>问题，不宜求解。而采用<strong>交叉熵损失函数</strong>依然是一个<strong>凸优化</strong>问题，更容易优化求解。（凸优化问题中局部最优解同时也是全局最优解）。而且<span
class="math inline">\(\frac{dL}{dW}\)</span>中，有地方为0，如果参数刚好导致<span
class="math inline">\(\frac{dL}{dW}\)</span>为0，参数就不会更新。</p>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224210154928.png" /></p></li>
</ol>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224211215148.png"
alt="image-20230224211215148" />
<figcaption aria-hidden="true">image-20230224211215148</figcaption>
</figure>
<ol start="2" type="1">
<li>因为<strong>交叉熵损失函数</strong>可以<strong>完美解决平方损失函数权重更新过慢</strong>的问题，具有“误差大的时候，权重更新快；误差小的时候，权重更新慢”的良好性质。</li>
</ol>
<p>​ 方损失函数权重更新过慢原因：</p>
<p>​ 梯度更新公式为：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224211408952.png"
alt="image-20230224211408952" />
<figcaption aria-hidden="true">image-20230224211408952</figcaption>
</figure>
<p>这里a是预测值，y是实际值</p>
<p>有<span
class="math inline">\(\sigma&#39;(z)\)</span>这一项而sigmoid函数两端梯度很小，导致参数更新缓慢。</p>
<p>而交叉熵函数不会有这个问题虽然有<span
class="math inline">\(\sigma(z)\)</span>但没有<span
class="math inline">\(\sigma&#39;(z)\)</span>,求导detail如下：</p>
<details>
<img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224211928602.png" >
</details>
<h3 id="交叉熵和均分函数区别">交叉熵和均分函数区别</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224212504307.png"
alt="image-20230224212504307" />
<figcaption aria-hidden="true">image-20230224212504307</figcaption>
</figure>
<h3 id="如何推导出交叉熵函数">如何推导出交叉熵函数</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230224215208050.png"
alt="image-20230224215208050" />
<figcaption aria-hidden="true">image-20230224215208050</figcaption>
</figure>
<h3 id="为什么交叉熵函数有log项">为什么交叉熵函数有log项</h3>
<p>第一种：因为是公式推导出来的，比如第六题的推导，推导出来的有log项。</p>
<p>第二种：通过最大似然估计的方式求得交叉熵公式，这个时候引入log项。这是因为似然函数（概率）是乘性的，而loss函数是加性的，所以需要引入log项“<strong>转积为和</strong>”。而且也是为了<strong>简化运算</strong>。</p>
<h3 id="交叉熵的设计思想">交叉熵的设计思想</h3>
<p><strong>交叉熵函数</strong>的本质是对数函数。</p>
<p><strong>交叉熵函数</strong>使用来描述模型预测值和真实值的差距大小，越大代表越不相近。</p>
<p><strong>交叉熵损失函数</strong>可以<strong>完美解决平方损失函数权重更新过慢</strong>的问题，具有“误差大的时候，权重更新快；误差小的时候，权重更新慢”的良好性质。</p>
<p>对数损失在<strong>逻辑回归</strong>和<strong>多分类任务</strong>上广泛使用。交叉熵损失函数的标准型就是对数损失函数，本质没有区别。</p>
<h2 id="cv相关">CV相关</h2>
<h3 id="yolo损失函数">Yolo损失函数</h3>
<p>Yolo是用于模板检测的模型</p>
<p>Yolo的损失函数由四部分组成：</p>
<figure>
<img
src="https://uploadfiles.nowcoder.com/images/20210419/675098158_1618823639975/8B2446F6E2BC3932829E4B801BDBDF05"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ol type="1">
<li>对预测的中心坐标做损失</li>
</ol>
<figure>
<img
src="https://uploadfiles.nowcoder.com/images/20210419/675098158_1618823762782/488A1D20613F3E03B97A925F2C63D9AF"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ol type="1">
<li>对预测边界框的宽高做损失</li>
</ol>
<figure>
<img
src="https://uploadfiles.nowcoder.com/images/20210419/675098158_1618823867484/DE22034D2077B5200B2C5440D47249FC"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ol type="1">
<li>对预测的类别做损失</li>
</ol>
<figure>
<img
src="https://uploadfiles.nowcoder.com/images/20210419/675098158_1618823980181/9CE8A218F55F619B9EAEBCDFCFBF6446"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ol type="1">
<li>对预测的置信度做损失</li>
</ol>
<figure>
<img
src="https://uploadfiles.nowcoder.com/images/20210419/675098158_1618824075778/79B60A7E11ACBF428FD0510200949CFC"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们发现每一项loss的计算都是L2
loss（平方差），即使是分类问题也是。所以说yolo是把<strong>分类</strong>问题转为了<strong>回归</strong>问题。</p>
<h3 id="iou与miou计算">IOU与MIOU计算</h3>
<p>IOU（Intersection over Union），交集占并集的大小。</p>
<figure>
<img
src="https://www.nowcoder.com/equation?tex=%0A%20%20IOU%3DJaccard%20%3D%5Cfrac%7B%7CA%5Ccap%20B%7C%7D%20%7B%7CA%5Ccup%20B%7C%7D%3D%5Cfrac%7B%7CA%5Ccap%20B%7C%7D%20%7B%7CA%7C%2B%7CB%7C-%7CA%5Ccap%20B%7C%7D%20%5C%5C%0A%20%20%5Ctag%7B.%7D%0A%20%20&amp;preview=true"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>mIOU一般都是基于类进行计算的，将每一类的IOU计算之后累加，再进行平均，得到的就是mIOU。</p>
<h2 id="其它">其它</h2>
<h3 id="kl散度">KL散度</h3>
<p>相对熵（relative
entropy），又被称为Kullback-Leibler散度（Kullback-Leibler
divergence）或信息散度（information
divergence），是<strong>两个概率分布（probability
distribution）间差异的非对称性度量</strong>
。在信息理论中，<strong>相对熵等价于两个概率分布的信息熵（Shannon
entropy）的差值</strong>。</p>
<p>设<img
src="https://www.nowcoder.com/equation?tex=P(x)&amp;preview=true"
alt="img" />，<img
src="https://www.nowcoder.com/equation?tex=Q(x)&amp;preview=true"
alt="img" />是随机变量<img
src="https://www.nowcoder.com/equation?tex=X&amp;preview=true"
alt="img" />上的两个概率分布，则在离散和连续随机变量的情形下，相对熵的定义分别为：</p>
<figure>
<img
src="https://www.nowcoder.com/equation?tex=%0AKL(P%7C%7CQ)%3D%5Csum%7BP(x)log%20%5Cfrac%7BP(x)%7D%7BQ(x)%7D%7D%20%5C%5C%0AKL(P%7C%7CQ)%3D%5Cint%7BP(x)log%20%5Cfrac%7BP(x)%7D%7BQ(x)%7Ddx%7D%20%5C%5C%0A%5Ctag%7B.%7D%0A&amp;preview=true"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img
src="https://www.nowcoder.com/equation?tex=Q(x)&amp;preview=true"
alt="img" />为<strong>理论概率分布</strong>，<img
src="https://www.nowcoder.com/equation?tex=P(x)&amp;preview=true"
alt="img" />为模型<strong>预测概率分布</strong>，而KL就是度量这两个分布的差异性，当然差异越小越好，所以KL也可以用作损失函数。</p>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>常见优化函数</title>
    <url>/2023/03/07/optimizer/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="常见优化函数">常见优化函数</h1>
<h2 id="梯度下降gd决定优化方向">梯度下降GD(决定优化方向)</h2>
<p><strong>梯度下降的核心思想：负梯度方向是使函数值下降最快的方向</strong></p>
<h3 id="批次梯度下降bgd">批次梯度下降BGD</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307202943629.png"
alt="image-20230307202943629" />
<figcaption aria-hidden="true">image-20230307202943629</figcaption>
</figure>
<p><strong>优点</strong>：在梯度下降法中，因为每次都遍历了完整的训练集，<strong>其能保证结果为全局最优</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307204257470.png"
alt="image-20230307204257470" />
<figcaption aria-hidden="true">image-20230307204257470</figcaption>
</figure>
<p><strong>缺点</strong>：我们需要对于每个参数求偏导，且在对每个参数求偏导的过程中还需要对训练集遍历一次，当训练集（m）很大时，计算费时</p>
<p><strong>解决方法</strong>：使用minibatch去更新</p>
<h3 id="随机梯度下降">随机梯度下降</h3>
<p>为了解决BGD耗时过长，它是利用单个样本的损失函数对θ求偏导得到对应的梯度，来更新θ，更新过程如下：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307204324179.png"
alt="image-20230307204324179" />
<figcaption aria-hidden="true">image-20230307204324179</figcaption>
</figure>
<p>速度快，但受抽样影响大，<strong>噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307204553630.png"
alt="image-20230307204553630" />
<figcaption aria-hidden="true">image-20230307204553630</figcaption>
</figure>
<p>因为每一次迭代的梯度受抽样的影响比较大，学习率需要逐渐减少，否则模型很难收敛。在实际操作中，一般采用线性衰减：
<span class="math display">\[
\eta_k=(1-\alpha)\eta_0+\alpha\eta_{\tau}
\]</span></p>
<p><span class="math display">\[
\alpha=\frac{k}{\tau}
\]</span></p>
<p><span class="math inline">\(\eta_0\)</span>:初始学习率</p>
<p><span class="math inline">\(\eta_{\tau}\)</span>：
最后一次迭代的学习率</p>
<p><span class="math inline">\(\tau\)</span>：自然迭代次数</p>
<p><span class="math inline">\(\eta_{\tau}\)</span>设为<span
class="math inline">\(\eta_0\)</span>的1%，k一般设为100的倍数。</p>
<p><strong>优点</strong>：收敛速度快</p>
<p><strong>缺点</strong>：</p>
<ol type="1">
<li><p>训练不稳定：噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p></li>
<li><p>选择适当的学习率可能很困难。
太小的学习率会导致收敛性缓慢，而学习速度太大可能会妨碍收敛，并导致损失函数在最小点波动。</p></li>
<li><p>无法逃脱鞍点</p></li>
</ol>
<details>
在数学中，鞍点或极小值点是函数图形表面上的一个点，其正交方向上的斜率(导数)均为零(临界点)，但不是函数的局
部极值。一句话概括就是：一个不是局部极值点的驻点称为鞍点。
*驻点：函数在一点处的一阶导数为零。
<img src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307205942585.png">
<details>
<h3 id="min-batch-小批量梯度下降mbgd">min-batch 小批量梯度下降MBGD</h3>
<p><strong>算法的训练过程比较快，而且也要保证最终参数训练的准确率</strong></p>
<p>m表示一个批次的数据个数</p>
<h2 id="动量方法">动量方法</h2>
<h3 id="momentum随机梯度下降">Momentum随机梯度下降</h3>
<p>核心思想：Momentum借用了物理中的<strong>动量</strong>概念,即前一次的梯度也会参与运算。为了表示动量，引入了<strong>一阶动量</strong>m。<img
src="https://www.nowcoder.com/equation?tex=m&amp;preview=true"
alt="img" />是之前的梯度的累加,但是每回合都有一定的衰减。公式如下：
<span class="math display">\[
m_t=\beta m_{t-1}+(1-\beta)\cdot g_t
\]</span></p>
<p><span class="math display">\[
w_{t+1}=w_t-\eta \cdot m_t
\]</span></p>
<p><span class="math inline">\(g_t\)</span>：
为第t次计算的梯度（就是现在要算这次）</p>
<p><span class="math inline">\(m_{t-1}\)</span>: 为之前梯度的累加</p>
<p><span class="math inline">\(\beta\)</span>: 动量因子</p>
<p>所以当前权值的改变受上一次改变的影响，类似加上了<strong>惯性</strong>。</p>
<p>优点：momentum能够加速SGD收敛，抑制震荡。并且动量有机会逃脱局部极小值(鞍点)。</p>
<ol type="1">
<li>在梯度方向改变时，momentum能够降低参数更新速度，从而减少震荡；</li>
<li>在梯度方向相同时，momentum可以加速参数更新， 从而加速收敛。</li>
</ol>
<h3 id="nesterov动量随机梯度下降法">Nesterov动量随机梯度下降法</h3>
<p>Nesterov是Momentum的变种。与Momentum唯一区别就是，计算梯度的不同。Nesterov动量中，先用当前的速度临时更新一遍参数，在用更新的临时参数计算梯度。</p>
<p>在momentum更新梯度时加入对当前梯度的校正，让梯度“多走一步”，可能跳出局部最优解：
<span class="math display">\[
w_t^*=\beta m_{t-1}+w_t
\]</span></p>
<p><span class="math display">\[
m_t=\beta m_{t-1}+(1-\beta)\cdot g_t
\]</span></p>
<p><span class="math display">\[
w_{t+1}=w_t-\eta \cdot m_t
\]</span></p>
<p>这里的<span class="math inline">\(g_t\)</span>用临时点<span
class="math inline">\(w_t^*\)</span>计算的</p>
<h2 id="更新学习率方法">更新学习率方法</h2>
<h3 id="adagrad">Adagrad</h3>
<p>引入<strong>二阶动量</strong>，根据训练轮数的不同，对学习率进行了动态调整：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307213914026.png"
alt="image-20230307213914026" />
<figcaption aria-hidden="true">image-20230307213914026</figcaption>
</figure>
<p><strong>缺点</strong>：仍然需要人为指定一个合适的全局学习率，同时网络训练到一定轮次后，分母上梯度累加过大使得学习率为0而导致训练提前结束。</p>
<h3 id="adadelta不是很懂">Adadelta(不是很懂)</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307215135905.png"
alt="image-20230307215135905" />
<figcaption aria-hidden="true">image-20230307215135905</figcaption>
</figure>
<h3 id="rmsprop">RMSProp</h3>
<p>AdaGrad算法在迭代后期由于学习率过小，可能较难找到一个有用的解。为了解决这一问题，RMSprop算法对Adagrad算法做了一点小小的修改，RMSprop使用指数衰减只保留过去给定窗口大小的梯度，使其能够在找到凸碗状结构后快速收敛。RMSProp法可以视为Adadelta法的一个特例，即依然使用全局学习率替换掉Adadelta法中的<span
class="math inline">\(s_t\)</span>:</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230307215341546.png"
alt="image-20230307215341546" />
<figcaption aria-hidden="true">image-20230307215341546</figcaption>
</figure>
<p>推荐<span
class="math inline">\(\eta_{global}=1,\rho=0.9,\epsilon=10^{-6}\)</span></p>
<p>缺点：依然使用了全局学习率，需要根据实际情况来设定 优点：</p>
<ol type="1">
<li>分母不再是一味的增加，它会重点考虑距离它较近的梯度（指数衰减的效果）</li>
<li>只用了部分梯度加和而不是所有，这样避免了梯度累加过大使得学习率为0而导致训练提前结束。</li>
</ol>
<h3 id="adam">Adam</h3>
<p>https://zhuanlan.zhihu.com/p/377968342</p>
<p>Adam公式如下： <span class="math display">\[
m_t:=beta_1*m_{t-1}+(1-beta_1)*g
\]</span></p>
<p><span class="math display">\[
v_t:=beta_2*v_{t-1}+(1-beta_2)*g*g
\]</span></p>
<p><span class="math display">\[
variable:=variable-lr_t*\frac{m_t}{\sqrt{v_t+\epsilon}}
\]</span></p>
<p><span
class="math inline">\(m_t\)</span>可以理解为求历史梯度加强平均，思想来自动量方法，防止震荡。</p>
<p><span class="math inline">\(v_t\)</span>则是用于调整lr的，即是<span
class="math inline">\(\frac{lr}{\sqrt{v_t+\epsilon}}\)</span>,</p>
<p>在迭代过程中，如果某一维度一直以很小的梯度进行更新，证明此方向梯度变换较为稳定，因此可以加大学习率，以较大的学习率在此维度更新，体现在公式上就是：对历史梯度平方进行一阶指数平滑后，公式2会得到一个很小的值，公式3中的自适应学习率会相对较大</p>
<p>相反，某一维度在迭代过程中一直以很大的梯度进行更新，明此方向梯度变换较为剧烈（不稳定），因此可减小学习率，以较小的学习率在此维度更新
体现在公式上就是：对历史梯度平方进行一阶指数平滑后，公式2则会得到一个很大的值，公式3中的自适应学习率会相对较小</p>
<p><span
class="math inline">\(v_t\)</span>也可以解决<strong>梯度稀疏</strong>的问题；频繁更新的梯度将会被赋予一个较小的学习率，而稀疏的梯度则会被赋予一个较大的学习率，通过上述机制，在数据分布稀疏的场景，能更好利用稀疏梯度的信息，比标准的SGD算法更有效地收敛。</p>
<h1 id="常见优化函数问题">常见优化函数问题</h1>
<h2
id="sgd和adam谁收敛的比较快谁能达到全局最优解">SGD和Adam谁收敛的比较快？谁能达到全局最优解？</h2>
<p>SGD算法没有动量的概念，SGD和Adam相比，缺点是下降速度慢，对学习率要求严格。</p>
<p>而Adam引入了一阶动量和二阶动量，下降速度比SGD快，Adam可以自适应学习率，所以初始学习率可以很大。</p>
<p>SGD相比Adam，更容易达到全局最优解。主要是后期Adam的学习率太低，影响了有效的收敛。</p>
<p>我们可以前期使用Adam，后期使用SGD进一步调优。</p>
<h2 id="adam用到二阶矩的原理是什么">adam用到二阶矩的原理是什么</h2>
<p>引入二阶动量，根据训练轮数不同对学习率进行调整。</p>
<p>可以看出来，公式将前面的训练梯度平方加和，在网络训练的前期，由于分母中梯度的累加（<span
class="math inline">\(v_t\)</span>）较小，所以一开始的学习率<span
class="math inline">\(\eta_t\)</span>比较大；随着训练后期梯度累加较大时，<span
class="math inline">\(\eta_t\)</span>逐渐减小，而且是自适应地减小。</p>
<p>而且如果某个维度频繁震荡梯度大，学习率就降低；如果梯度小而稳定，学习率就大。</p>
<h2
id="batch的大小如何选择过大的batch和过小的batch分别有什么影响">Batch的大小如何选择，过大的batch和过小的batch分别有什么影响</h2>
<p><strong>Batch选择时尽量采用2的幂次，如8、16、32等</strong></p>
<p>在合理范围内，增大Batch_size的<strong>好处</strong>：</p>
<ol type="1">
<li>提高了<strong>内存利用率</strong>以及大矩阵乘法的并行化效率。</li>
<li>减少了跑完一次epoch(全数据集）所需要的迭代次数，加快了对于相同数据量的处理速度。</li>
</ol>
<p>盲目增大Batch_size的<strong>坏处</strong>：</p>
<ol type="1">
<li>提高了内存利用率，但是内存容量可能不足。</li>
<li>跑完一次epoch(全数据集)所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_size增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<p>Batch_size过小的<strong>影响</strong>：</p>
<ol type="1">
<li>训练时不稳定，可能不收敛</li>
<li>精度可能更高。</li>
</ol>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
  <entry>
    <title>Regularization</title>
    <url>/2023/03/14/regularization/</url>
    <content><![CDATA[<p>.</p>
<span id="more"></span>
<h1 id="什么是正则化">什么是正则化</h1>
<p>目的：防止模型过拟合</p>
<p>原理：正则化通过在损失函数中<strong>引入惩罚项来限制模型的复杂度</strong>，以防止模型过度拟合训练数据。惩罚项会在优化过程中对模型的参数进行调整，以平衡模型的拟合能力和泛化能力。</p>
<p>https://www.zhihu.com/question/20924039</p>
<p>最直接的防止过拟合的方法就是减少特征数量，就是减少0范数（向量中非零元素的个数），但是0范数很难求，所以就有了1范数，2范数。</p>
<p>作用：</p>
<ol type="1">
<li>防止过拟合</li>
<li>特征选择：l1正则化</li>
<li>改善模型稳定性</li>
</ol>
<h1 id="常见正则化">常见正则化</h1>
<h2 id="l1正则化">l1正则化</h2>
<p><span class="math display">\[
l1=\lambda||\vec{w}||_1=\sum_i|w_i|
\]</span></p>
<p><span class="math inline">\(\lambda\)</span>控制约束程度</p>
<p>l1不仅可以<strong>约束参数量</strong>，还可以使<strong>参数更稀疏</strong>。因为对目标函数经过优化后，一部分参数会变为0，另一部分参数为非零实值。<strong>非零实值说明这部分参数是最重要的特征</strong>。</p>
<p>假设参数分布是Laplace分布。</p>
<h3 id="稀疏原因">稀疏原因</h3>
<p>https://blog.csdn.net/b876144622/article/details/81276818</p>
<p>https://www.zhihu.com/question/37096933/answer/70426653</p>
<p>0处导数突变，如果此时0+导数为正，优化时放负方向跑，0-导数为负数，优化时往正方向跑，就很容易落入0</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230314211808962.png"
alt="image-20230314211808962" />
<figcaption aria-hidden="true">image-20230314211808962</figcaption>
</figure>
<h3 id="缺点">缺点</h3>
<ul>
<li>非光滑性：L1
正则化的正则化项是参数的绝对值之和，这导致目标函数在参数为零时不可导。这使得优化过程变得更加困难，特别是在使用梯度下降等基于梯度的优化算法时。在参数为零附近，梯度不连续，可能导致优化过程出现问题。</li>
<li>多重共线性：当特征之间存在高度相关性（多重共线性）时，L1
正则化倾向于选择其中一个特征，而忽略其他相关特征。这可能导致模型的解释性下降，因为被忽略的相关特征可能包含有用的信息。相比之下，L2
正则化对相关特征的惩罚更均衡，可以保留更多相关特征的权重。</li>
<li>不适用于高维问题：在高维问题中，特征数量远远大于样本数量时，L1
正则化可能不太适用。由于参数空间的维度过高，L1
正则化可能无法准确地选择特征，导致过拟合或选择不稳定的特征子集。</li>
</ul>
<h2 id="l2正则化">l2正则化</h2>
<p><span class="math display">\[
l2=\frac{1}{2}\lambda||\vec{w}||_2^2=\sum_i|w_i|^2
\]</span></p>
<p>l2正则化会使部分特征<strong>趋近于0</strong>，也就达到正则化的目的了。</p>
<p>此外，l1正则化和l2正则化也可以联合使用，这种形式也被称为“<strong>Elastic网络正则化</strong>”。</p>
<p>假设参数分布是正态分布</p>
<h2 id="dropout">Dropout</h2>
<p>在训练的时候让一定量的神经元失活，在该epoch中不参与网络训练</p>
<h3
id="dropout训练出的参数需要乘以keep-prib使用">dropout训练出的参数需要乘以keep-prib使用</h3>
<p>因为神经元预测的时候就不应该随机丢弃，一种”补偿“的方案就是每个dropout训练出的神经元的权重都乘以一个<strong>p</strong>，这样在“总体上”使得<strong>测试数据</strong>和<strong>训练数据</strong>是大致一样的。保证<strong>测试</strong>的时候把这个神经元的权重乘以<strong>p</strong>可以得到<strong>同样的期望</strong>。比如一个神经元的输出是<strong>x</strong>，那么在训练的时候它有<strong>p</strong>的概率参与训练，<strong>(1-p)</strong>的概率丢弃，那么它输出的期望是<img
src="https://www.nowcoder.com/equation?tex=p%20%5Ctimes%20x%2B(1-p)%20%5Ctimes%200%20%3D%20p%20%5Ctimes%20x&amp;preview=true"
alt="img" />。因此<strong>测试</strong>的时候把这个神经元的权重乘以<strong>p</strong>可以得到<strong>同样的期望</strong>。</p>
<p>注：目前主流是采用inverted dropout替代dropout，inverted
dropout不需要乘以keep-prib。它的做法是在训练阶段对执行了dropout操作的层，其输出激活值要<strong>除以keep_prib</strong>，而测试的模型不用再做任何改动。除以（1-p），让期望与不dropout相同。</p>
<h2 id="早停">早停</h2>
<p>每一个epoch训练结束后使用<strong>验证集</strong>验证模型效果，画出训练曲线，这样就可以判断是否过拟合了。当发现网络有点过拟合了，当然就是“<strong>早停</strong>”了，可以直接停止训练了。</p>
<h2 id="扩充数据集">扩充数据集</h2>
<p>Augmentation，增加变化增加多样性</p>
<h3 id="数据增强方法">数据增强方法</h3>
<p>数据集越大，网络泛化性能越好，所以努力扩充数据集，通过平移、翻转、旋转、放缩、随机截取、加噪声、色彩抖动等等方式。</p>
<h2 id="bnbatch-normalization">BN（Batch Normalization）</h2>
<p>目的：用于解决深度网络<strong>梯度消失</strong>和<strong>梯度爆炸</strong>的问题，加速网络收敛速度。</p>
<p>批规范化，即在模型每次随机梯度下降训练时，通过mini-batch来对每一层的输出做<strong>规范化操作</strong>，使得结果（各个维度）的<strong>均值为0</strong>，<strong>方差为1</strong>，然后在进行尺度变换和偏移。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230316191341497.png"
alt="image-20230316191341497" />
<figcaption aria-hidden="true">image-20230316191341497</figcaption>
</figure>
<p>m是mini-batch中的数据个数。前面的散步是对input数据进行白化操作（线性），<strong>最后的“尺度变换和偏移”操作是为了让BN能够在线性和非线性之间做一个权衡</strong>，而这个偏移的参数是神经网络在训练时学出来的。</p>
<p>经过BN操作，网络每一层的输出小值被“拉大”，大值被“缩小”，所以就有效避免了梯度消失和梯度爆炸。<strong>总而言之，BN是一个可学习、有参数（γ、β）的网络层</strong>。</p>
<h3 id="尺度变换和偏移的作用">尺度变换和偏移的作用：</h3>
<p>归一会影响到本层网络A所学习到的特征（比如网络中间某一层学习到特征数据本身就分布在S型激活函数的两侧，如果强制把它给归一化处理、标准差也限制在了1，把数据变换成分布于s函数的中间部分，这样就相当于这一层网络所学习到的特征分布<strong>被搞坏</strong>了）</p>
<p>于是<strong>BN</strong>最后的“<strong>尺度变换和偏移</strong>”操作，让我们的网络可以学习恢复出原始网络所要学习的特征分布（衡量线性和非线性）</p>
<h3 id="bn训练和测试有什么不同">BN训练和测试有什么不同</h3>
<p>训练时，均值和方差针对一个<strong>Batch</strong>。</p>
<p>测试时，均值和方差针对<strong>整个数据集</strong>而言。因此，在训练过程中除了正常的前向传播和反向求导之外，我们还要记录<strong>每一个Batch的均值和方差</strong>。</p>
<h3 id="bn和ln的差别">BN和LN的差别</h3>
<p>LN：Layer
Normalization，LN是“横”着来的，<strong>对一个样本，经过同一层的所有神经元</strong>做<strong>归一化</strong>。LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；LN不依赖于batch的大小和输入sequence的深度，因此可以用于<strong>batchsize为1</strong>和RNN中对边长的输入sequence的normalize操作。</p>
<p>BN：Batch
Normalization，BN是“竖”着来的，<strong>经过一个神经元的所有样本</strong>做<strong>归一化</strong>，所以与<strong>batch
size</strong>有关系。</p>
<p>二者提出的目的都是为了加快模型收敛，减少训练时间。</p>
<h3 id="如何同时使用bn和dropout">如何同时使用BN和dropout</h3>
<p>同时使用BN和Dropout会出现方差偏移的现象，原因：</p>
<p>使用Dropout：训练的时候以<strong>概率p</strong>
drop了一些节点，比如dropout设置为0.5，隐藏层共有6个节点，那训练的时候有3个节点的值被丢弃，而测试的时候这6个节点都被保留下来，这就导致了<strong>训练</strong>和<strong>测试</strong>的时候以该层节点为输入的下一层的神经网络节点获取的<strong>期望</strong>会有量级上的差异。为了解决这个问题，在训练时对当前dropout层的输出数据<strong>除以（1-p）</strong>，之后再输入到下一层的神经元节点，以作为失活神经元的补偿，以使得在训练时和测试时每一层的输入有大致相同的期望。</p>
<p>但是这样使得神经元输入期望大致相同，但是方差不一样，而BN是通过均值方差计算的，所以会导致输出不正确。</p>
<p>解决方法：</p>
<ol type="1">
<li>只<strong>在所有BN层的后面采用dropout层</strong>。</li>
<li>dropout原文提出了一种高斯dropout，论文再进一步对高斯dropout进行扩展，提出了一个<strong>均匀分布Dropout</strong>，这样做带来了一个好处就是这个形式的Dropout（又称为“Uout”）对方差的偏移的敏感度降低了</li>
</ol>
<h2 id="bagging-和bootstrap">Bagging 和Bootstrap？</h2>
<p><strong>Bootstrap</strong>是一种抽样方法，即随机抽取数据并将其放回。如一次抽取一个样本，然后放回样本集中，下次可能再抽取这个样本。接着将每轮未抽取的数据合并形成<strong>袋外数据集</strong>（Out
of Bag, OOB），用于模型中的测试集。</p>
<p><strong>Bagging算法</strong>使用<strong>Bootstrap方法</strong>从原始样本集中随机抽取样本。共提取K个轮次，得到K个独立的训练集，元素可以重复。用K个训练集训练K个模型。分类问题以结果中的多个值投票作为最终结果，回归问题以平均值作为最终结果。结果采用投票法，避免了决策树的过拟合问题。</p>
<p><strong>Boosting</strong>是为每个训练样本设置一个权重，在下一轮分类中，误分类的样本权重较大，即每轮样本相同，但样本权重不同；对于分类器来说，分类误差小的分类器权重较大，反之则小。</p>
<p><strong>采用模型融合的方式也可以避免过拟合</strong>。</p>
<h2 id="参数共享">参数共享</h2>
<p>参数共享是一种在神经网络中常用的正则化方法，特别适用于卷积神经网络（CNN）。通过在神经网络的不同层之间共享参数，可以减少模型的参数数量，提高模型的效率和泛化能力。</p>
<h2 id="数据标准化">数据标准化</h2>
<p>数据标准化是对数据进行预处理的一种方式，将数据按特征进行缩放，使得每个特征的均值为
0，标准差为
1。这有助于使不同特征之间的尺度一致，提高模型的收敛速度和性能。</p>
<ul>
<li>z-score</li>
<li>min-max</li>
</ul>
]]></content>
      <categories>
        <category>ML</category>
        <category>Basic</category>
      </categories>
  </entry>
</search>
