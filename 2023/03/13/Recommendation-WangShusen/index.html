<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content=".">
<meta property="og:type" content="article">
<meta property="og:title" content="王树森推荐系统公开课">
<meta property="og:url" content="http://example.com/2023/03/13/Recommendation-WangShusen/index.html">
<meta property="og:site_name" content="Lory&#39;s Page">
<meta property="og:description" content=".">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="c:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230626164840701.png">
<meta property="article:published_time" content="2023-03-13T20:46:26.000Z">
<meta property="article:modified_time" content="2024-05-20T05:27:22.104Z">
<meta property="article:author" content="Lory">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="c:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230626164840701.png">


<link rel="canonical" href="http://example.com/2023/03/13/Recommendation-WangShusen/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/03/13/Recommendation-WangShusen/","path":"2023/03/13/Recommendation-WangShusen/","title":"王树森推荐系统公开课"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>王树森推荐系统公开课 | Lory's Page</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Lory's Page</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%87%E6%A0%87"><span class="nav-number">1.1.</span> <span class="nav-text">指标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E6%8C%87%E6%A0%87"><span class="nav-number">1.1.1.</span> <span class="nav-text">消费指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%97%E6%9E%81%E6%98%9F%E6%8C%87%E6%A0%87"><span class="nav-number">1.1.2.</span> <span class="nav-text">北极星指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E9%93%BE%E8%B7%AF"><span class="nav-number">1.2.</span> <span class="nav-text">推荐系统链路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ab%E6%B5%8B%E8%AF%95"><span class="nav-number">1.3.</span> <span class="nav-text">AB测试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%86%E6%A1%B6"><span class="nav-number">1.3.1.</span> <span class="nav-text">随机分桶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B1%82%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.3.2.</span> <span class="nav-text">分层实验</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.</span> <span class="nav-text">召回</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4"><span class="nav-number">2.1.</span> <span class="nav-text">协同过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4-itemcf"><span class="nav-number">2.1.1.</span> <span class="nav-text">基于物品的协同过滤 ItemCF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">基本结构：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97item%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="nav-number">2.1.1.1.1.</span> <span class="nav-text">计算item相似度</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">运作基本流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#swing%E5%8F%AC%E5%9B%9E%E9%80%9A%E9%81%93"><span class="nav-number">2.1.2.</span> <span class="nav-text">Swing召回通道</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84-1"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">基本结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4usercf"><span class="nav-number">2.1.3.</span> <span class="nav-text">基于用户的协同过滤（UserCF）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84-2"><span class="nav-number">2.1.3.1.</span> <span class="nav-text">基本结构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97user%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="nav-number">2.1.3.1.1.</span> <span class="nav-text">计算User相似度</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B-1"><span class="nav-number">2.1.3.2.</span> <span class="nav-text">运作基本流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%BC%BA%E7%82%B9"><span class="nav-number">2.1.4.</span> <span class="nav-text">协同过滤缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.2.</span> <span class="nav-text">向量召回</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85-matrix-completion"><span class="nav-number">2.2.1.</span> <span class="nav-text">矩阵补充 Matrix Completion</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">2.2.1.2.</span> <span class="nav-text">训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">2.2.1.3.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B-2"><span class="nav-number">2.2.1.4.</span> <span class="nav-text">运作基本流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.2.2.</span> <span class="nav-text">双塔模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86-1"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83-1"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#pointwise"><span class="nav-number">2.2.2.2.1.</span> <span class="nav-text">Pointwise</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pairwise"><span class="nav-number">2.2.2.2.2.</span> <span class="nav-text">Pairwise</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#listwise"><span class="nav-number">2.2.2.2.3.</span> <span class="nav-text">Listwise</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B-3"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">运作基本流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9B%B4%E6%96%B0"><span class="nav-number">2.2.2.4.</span> <span class="nav-text">模型更新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.2.2.5.</span> <span class="nav-text">自监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">2.2.2.5.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#method"><span class="nav-number">2.2.2.5.2.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.2.5.2.1.</span> <span class="nav-text">特征变换方法</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83"><span class="nav-number">2.2.2.5.2.2.</span> <span class="nav-text">自监督训练</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83%E6%AD%A3%E5%B8%B8%E8%AE%AD%E7%BB%83"><span class="nav-number">2.2.2.5.2.3.</span> <span class="nav-text">自监督训练+正常训练</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E9%80%82%E5%90%88%E5%8F%AC%E5%9B%9E%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">不适合召回的模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%96%B9%E5%BC%8F%E5%8F%AC%E5%9B%9E"><span class="nav-number">2.4.</span> <span class="nav-text">其他方式召回</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9B%9D%E5%85%89%E8%BF%87%E6%BB%A4%E4%B8%8E%E9%93%BE%E8%B7%AF"><span class="nav-number">2.5.</span> <span class="nav-text">曝光过滤与链路</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#bloom-filter"><span class="nav-number">2.5.1.</span> <span class="nav-text">Bloom Filter</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8E%92%E5%BA%8F"><span class="nav-number">3.</span> <span class="nav-text">排序</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.</span> <span class="nav-text">排序模型特征</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F"><span class="nav-number">3.1.1.</span> <span class="nav-text">用户画像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F"><span class="nav-number">3.1.2.</span> <span class="nav-text">物品画像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.3.</span> <span class="nav-text">用户统计特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%94%E8%AE%B0%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.4.</span> <span class="nav-text">笔记统计特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF%E7%89%B9%E5%BE%81"><span class="nav-number">3.1.5.</span> <span class="nav-text">场景特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86"><span class="nav-number">3.1.6.</span> <span class="nav-text">特征处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B2%97%E6%8E%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">粗排模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B2%97%E6%8E%92%E7%9A%84%E4%B8%89%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.1.</span> <span class="nav-text">粗排的三塔模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.</span> <span class="nav-text">精排模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.1.</span> <span class="nav-text">多目标模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%B0%E5%80%BC%E6%A0%A1%E5%87%86"><span class="nav-number">3.3.1.2.</span> <span class="nav-text">估值校准：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-gate-mixture-of-experts-mmoe"><span class="nav-number">3.3.2.</span> <span class="nav-text">Multi-gate
Mixture-of-Experts (MMoE)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84-1"><span class="nav-number">3.3.2.1.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%81%E5%8C%96%E7%8E%B0%E8%B1%A1"><span class="nav-number">3.3.2.2.</span> <span class="nav-text">极化现象</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E4%BC%B0%E5%88%86%E6%95%B0%E8%9E%8D%E5%90%88"><span class="nav-number">3.4.</span> <span class="nav-text">预估分数融合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E6%97%B6%E9%95%BF%E5%BB%BA%E6%A8%A1"><span class="nav-number">3.5.</span> <span class="nav-text">视频播放时长建模</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%92%AD%E6%94%BE%E6%97%B6%E9%95%BF%E5%BB%BA%E6%A8%A1"><span class="nav-number">3.5.1.</span> <span class="nav-text">播放时长建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E5%AE%8C%E6%92%AD"><span class="nav-number">3.5.2.</span> <span class="nav-text">视频完播</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95"><span class="nav-number">3.5.2.1.</span> <span class="nav-text">建模方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%9E%8D%E5%85%A5%E8%9E%8D%E5%88%86%E5%85%AC%E5%BC%8F"><span class="nav-number">3.5.2.2.</span> <span class="nav-text">融入融分公式</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89"><span class="nav-number">4.</span> <span class="nav-text">特征交叉</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#factorized-machine"><span class="nav-number">4.1.</span> <span class="nav-text">Factorized Machine</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dcn"><span class="nav-number">4.2.</span> <span class="nav-text">DCN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ppnet"><span class="nav-number">4.3.</span> <span class="nav-text">PPNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#senet"><span class="nav-number">4.4.</span> <span class="nav-text">SENet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bilinear-cross"><span class="nav-number">4.5.</span> <span class="nav-text">bilinear cross</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fibinet"><span class="nav-number">4.6.</span> <span class="nav-text">FiBiNet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1"><span class="nav-number">5.</span> <span class="nav-text">用户行为序列建模</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#last-n"><span class="nav-number">5.1.</span> <span class="nav-text">Last N</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#din%E6%A8%A1%E5%9E%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">5.2.</span> <span class="nav-text">DIN模型（注意力机制）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sim%E6%A8%A1%E5%9E%8B%E9%95%BF%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1"><span class="nav-number">5.3.</span> <span class="nav-text">SIM模型（长序列建模）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="nav-number">5.3.1.</span> <span class="nav-text">模型架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E6%89%BE"><span class="nav-number">5.3.1.1.</span> <span class="nav-text">查找</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">5.3.1.2.</span> <span class="nav-text">注意力机制</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%87%8D%E6%8E%92"><span class="nav-number">6.</span> <span class="nav-text">重排</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="nav-number">6.1.</span> <span class="nav-text">相似性度量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E5%B1%9E%E6%80%A7%E6%A0%87%E7%AD%BE"><span class="nav-number">6.1.1.</span> <span class="nav-text">基于物品属性标签。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E5%90%91%E9%87%8F%E8%A1%A8%E5%BE%81"><span class="nav-number">6.1.2.</span> <span class="nav-text">基于物品向量表征。</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#maximal-margianl-relevancemmr"><span class="nav-number">6.2.</span> <span class="nav-text">Maximal Margianl
Relevance（MMR）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E7%90%86"><span class="nav-number">6.2.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%81%E7%A8%8B"><span class="nav-number">6.2.2.</span> <span class="nav-text">流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#trick%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="nav-number">6.2.3.</span> <span class="nav-text">Trick：滑动窗口</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E9%87%8D%E6%8E%92%E8%A7%84%E5%88%99%E6%8F%90%E9%AB%98%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="nav-number">6.3.</span> <span class="nav-text">通过重排规则提高多样性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8D%E6%8E%92%E8%A7%84%E5%88%99"><span class="nav-number">6.3.1.</span> <span class="nav-text">重排规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mmr%E9%87%8D%E6%8E%92%E8%A7%84%E5%88%99"><span class="nav-number">6.3.2.</span> <span class="nav-text">MMR+重排规则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dpp%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%AE%97%E6%B3%95"><span class="nav-number">6.4.</span> <span class="nav-text">DPP多样性算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E8%B6%85%E5%B9%B3%E5%BD%A2%E4%BD%93"><span class="nav-number">6.4.1.</span> <span class="nav-text">数学基础-超平形体</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4"><span class="nav-number">6.4.1.1.</span> <span class="nav-text">二维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4"><span class="nav-number">6.4.1.2.</span> <span class="nav-text">三维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%BB%B4"><span class="nav-number">6.4.1.3.</span> <span class="nav-text">多维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E5%B9%B3%E5%BD%A2%E4%BD%93%E4%BD%93%E7%A7%AF"><span class="nav-number">6.4.1.4.</span> <span class="nav-text">超平形体体积</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dpp%E5%BA%94%E7%94%A8%E4%BA%8E%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="nav-number">6.4.2.</span> <span class="nav-text">DPP应用于多样性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9A%B4%E5%8A%9B%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95"><span class="nav-number">6.4.2.1.</span> <span class="nav-text">暴力贪心算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hulu%E5%BF%AB%E9%80%9F%E7%AE%97%E6%B3%95"><span class="nav-number">6.4.2.2.</span> <span class="nav-text">Hulu快速算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dpp%E6%89%A9%E5%B1%95-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="nav-number">6.4.3.</span> <span class="nav-text">DPP扩展-滑动窗口</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%B7%E5%90%AF%E5%8A%A8"><span class="nav-number">7.</span> <span class="nav-text">冷启动</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B6%A8%E6%8C%87%E6%A0%87%E6%96%B9%E6%B3%95"><span class="nav-number">8.</span> <span class="nav-text">涨指标方法</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Lory</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/13/Recommendation-WangShusen/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Lory">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lory's Page">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="王树森推荐系统公开课 | Lory's Page">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          王树森推荐系统公开课
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-13 20:46:26" itemprop="dateCreated datePublished" datetime="2023-03-13T20:46:26+00:00">2023-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-20 05:27:22" itemprop="dateModified" datetime="2024-05-20T05:27:22+00:00">2024-05-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RecSys/" itemprop="url" rel="index"><span itemprop="name">RecSys</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RecSys/BasicTurtorial/" itemprop="url" rel="index"><span itemprop="name">BasicTurtorial</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>.</p>
<span id="more"></span>
<h1 id="基本概念">基本概念</h1>
<h2 id="指标">指标</h2>
<h3 id="消费指标">消费指标</h3>
<p>点击率=点击次数/曝光次数</p>
<p>点赞量=点赞次数/点击次数</p>
<p>收藏率=收藏次数/点击次数</p>
<p>转发率=转发次数/点击次数</p>
<p>阅读完成率=滑动到底次数/点击次数<span class="math inline">\(\times
f(笔记长度)\)</span></p>
<h3 id="北极星指标">北极星指标</h3>
<p>用户规模：日活用户数（DAU），月活用户数（MAU）</p>
<p>消费：人均使用推荐时长、人均阅读笔记数量</p>
<p>发布： 发布渗透率、人均发布量</p>
<h2 id="推荐系统链路">推荐系统链路</h2>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230313220835272.png"
alt="image-20230313220835272" />
<figcaption aria-hidden="true">image-20230313220835272</figcaption>
</figure>
<ol type="1">
<li>召回：快速从海量数据中取回几千个用户可能感兴趣的物品。</li>
<li>粗排：用小规模的模型的神经网络给召回的物品打分，然后做截断，选出分数最高的几百个物品。</li>
<li>精排：
用大规模神经网络给粗排选中的几百个物品打分，可以做截断，也可以不做截断。</li>
<li>重排：
对精排结果做多样性抽样，得到几十个物品，然后用规则调整物品的排序。</li>
</ol>
<h2 id="ab测试">AB测试</h2>
<p>完成离线测试后，使用线上小流量AB测试考察指标，或者用AB测试调参（GNN深度）</p>
<h3 id="随机分桶">随机分桶</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20231119172737630.png"
alt="image-20231119172737630" />
<figcaption aria-hidden="true">image-20231119172737630</figcaption>
</figure>
<p>在不同的桶上使用不同的策略或参数实验。</p>
<h3 id="分层实验">分层实验</h3>
<p>不同的部门都需要做AB测试，每个部门对应一个层，分层实验满足：</p>
<ol type="1">
<li><strong>同层互斥</strong>：同一个部门做实验不能使用同一个桶；例：GNN实验占了召回层4个桶，其它召回实验只能用剩下的6个桶。</li>
<li><strong>不同层正交</strong>：每一层独立随机对用户做分桶。每一层都可以独立用100%的用户做实验。</li>
</ol>
<h1 id="召回">召回</h1>
<h2 id="协同过滤">协同过滤</h2>
<h3 id="基于物品的协同过滤-itemcf">基于物品的协同过滤 ItemCF</h3>
<p>基本思想：如果用户喜欢item1,而item1与item2相似，那么用户很可能喜欢item2.</p>
<h4 id="基本结构">基本结构：</h4>
<figure>
<img
src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230313223949470.png"
alt="image-20230313223949470" />
<figcaption aria-hidden="true">image-20230313223949470</figcaption>
</figure>
<p>我们从用户历史互动知道用户对<span
class="math inline">\(item_j\)</span>，感兴趣利用下面公式计算对候选物品的兴趣分数
<span class="math display">\[
\sum_jlike(user,item_j)\times sim(item_j,item)
\]</span> 在这个例子中，用户对候选item的兴趣是：<span
class="math inline">\(2\times
0.1+1\times0.4+4\times0.2+3\times0.6=3.2\)</span>,我们计算所有item的分数，然后返回分数最高的若干个item</p>
<h5 id="计算item相似度">计算item相似度</h5>
<p>可以通过与item交互过的用户重合度计算item相似度（其中一种方法，也可以用KG）</p>
<ol type="1">
<li>方法1：不考虑用户对物品的喜欢程度</li>
</ol>
<p><span class="math display">\[
sim(i_1,i_2) = \frac{|W1 \cap W2|}{\sqrt[2]{|W1|\cdot |W2|}}
\]</span></p>
<p>其中，喜欢物品<span class="math inline">\(i_1\)</span>的用户记作<span
class="math inline">\(W_1\)</span>,喜欢物品<span
class="math inline">\(i_2\)</span>的用户记作<span
class="math inline">\(W_2\)</span>.</p>
<ol start="2" type="1">
<li><p>方法2： 考虑用户对物品的喜欢程度,使用余弦相似度！</p>
<p>把每个item用向量表示 <span class="math display">\[
i_1=[like(u_1,i_1),like(u_2,i_1),\cdots ,like(u_n,i_1)] \space u_n\in W
\]</span></p>
<p><span class="math display">\[
i_2=[like(u_1,i_2),like(u_2,i_2),\cdots ,like(u_n,i_2)] \space u_n\in W
\]</span></p>
<p><span class="math display">\[
W=W_1\cup W_2
\]</span></p>
<p>我们使用余弦相似度计算： <span class="math display">\[
similarity=cos(\theta) = \frac{A\cdot B}{||A||\space ||B||}
\]</span> 如果有用户k只喜欢其中一个物品:只喜欢<span
class="math inline">\(i_1\)</span>不喜欢<span
class="math inline">\(i_2\)</span>,那么<span
class="math inline">\(i_2[k]=0\)</span>，所以点乘后第k项为0，所以点乘只与同时喜欢<span
class="math inline">\(i_1,i_2\)</span>的用户有关系，如下面公式 <span
class="math display">\[
sim(i_1,i_2) = \frac{\sum_{v\in V}like(v,i_i)\cdot
like(v,i_2)}{\sqrt[2]{\sum_{u_1\in
W_1}like^2(u_1,i_1)}\sqrt[2]{\sum_{u_2\in W_2}like^2(u_2,i_2)}}
\]</span></p></li>
<li></li>
<li><p>皮尔逊系数 <span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_i)(R_{j,p}-\bar
R_j)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_i)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_j)^2}}
\]</span></p></li>
</ol>
<h4 id="运作基本流程">运作基本流程</h4>
<ol type="1">
<li><p>实现做离线计算，预先计算两个索引：</p>
<ol type="1">
<li><p>“user2item”：记录每个用户最近点击交互过的n个物品ID（lastN）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example 不一定是公司真实的保存方式</span></span><br><span class="line">user2item=&#123;</span><br><span class="line">    <span class="string">&#x27;u1&#x27;</span>:[[i1,like(u1,i1)],[i2,like(u1,i2)],...,[<span class="keyword">in</span>,like(u1,<span class="keyword">in</span>)]]</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>"item2item":计算物品之间两两相似度，记录每个物品最相似的k个物品。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">item2item=&#123;</span><br><span class="line">	#target item:[[similar item, similarity score]...]</span><br><span class="line">	&#x27;i1&#x27;:[[i2,0.9],[i6,0.88]...]</span><br><span class="line">	&#x27;i2&#x27;:...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol></li>
<li><p>线上做召回</p>
<ol type="1">
<li>给定用户ID，通过“user2item”找到用户近期感兴趣的物品列表(last-n)</li>
<li>对于last-n列表中每个物品，通过“item2item"找到top-k相似物品。现在有1个user，n个互动物品，nxk个候选物品。</li>
<li>计算候选物品兴趣分数</li>
<li>返回分数最高的100个物品作为推荐结果</li>
</ol></li>
</ol>
<h3 id="swing召回通道">Swing召回通道</h3>
<p>如果两个Item的重合用户来源于一个小圈子（微信群），一个小圈子用户同时与两个Item交互，不能说明两个Item相似，如果很多不相关的用户交互两个Item，说明Item相似。</p>
<h4 id="基本结构-1">基本结构</h4>
<ol type="1">
<li>计算用户重合度</li>
</ol>
<p>用户<span class="math display">\[u_1\]</span>喜欢的物品记作集合<span
class="math display">\[J_1\]</span></p>
<p>用户<span class="math display">\[u_2\]</span>喜欢的物品记作集合<span
class="math display">\[J_2\]</span></p>
<p>定义两个用户的重合度： <span class="math display">\[
overlap(u_1,u_2)=|J_1\cap J_2|
\]</span> 用户<span class="math display">\[u_1\]</span>和<span
class="math display">\[u_2\]</span>的重合度高，则他们可能来自一个小圈子，要降低他们的权重。</p>
<ol start="2" type="1">
<li>计算物品相似度</li>
</ol>
<p>喜欢物品<span class="math display">\[i_1\]</span>的用户记作集合<span
class="math display">\[W_1\]</span></p>
<p>喜欢物品<span class="math display">\[i_2\]</span>的用户记作集合<span
class="math display">\[W_2\]</span> <span class="math display">\[
V=W_1\cap W_2
\]</span></p>
<p><span class="math display">\[
sim(i_1,i_2) = \sum_{u_1\in V}\sum_{u_2\in
V}\frac{1}{\alpha+overlap(u_1,u_2)}
\]</span></p>
<p>u1u2都对物品i1i2感兴趣，这样的用户越多，说明物品越相似</p>
<p><span class="math display">\[\alpha\]</span>是超参数</p>
<h3 id="基于用户的协同过滤usercf">基于用户的协同过滤（UserCF）</h3>
<p>假设：u1与u2兴趣十分相似，u1可能会对u2交互的item感兴趣</p>
<p>何为兴趣相似：</p>
<ol type="1">
<li>点击、点赞、收藏、转发的笔记有很大重合</li>
<li>关注的作者有很大的重合</li>
</ol>
<h4 id="基本结构-2">基本结构</h4>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230525170605162.png"
alt="image-20230525170605162" /> <span class="math display">\[
\sum_jsim(user,user_j)\times like(user_j,item)
\]</span></p>
<h5 id="计算user相似度">计算User相似度</h5>
<ol type="1">
<li><p>计算User相似度</p>
<p>把每个用户表示为一个稀疏向量，向量每个元素对应一个物品。相似度sim就是两个向量夹角的余弦。<span
class="math display">\[u_1\cdot u_2\]</span>结果就是<span
class="math display">\[|I|\]</span></p></li>
</ol>
<p><span class="math display">\[
sim(u_1,u_2) = \frac{|I|}{\sqrt{|J_1|\cdot|J_2|}}
\]</span></p>
<p><span class="math display">\[J_1\]</span>: 用户<span
class="math display">\[u_1\]</span>喜欢的物品集合</p>
<p><span class="math display">\[J_2\]</span>: 用户<span
class="math display">\[u_2\]</span>喜欢的物品集合</p>
<p><span class="math display">\[I\]</span>：<span
class="math display">\[J_1\cap J_2\]</span></p>
<p>|*|:集合的大小</p>
<p><span
class="math display">\[sim(u_1,u_2)\in[0,1]\]</span>,越大代表用户越相似</p>
<ol start="2" type="1">
<li>降低热门物品权重</li>
</ol>
<p>大家都喜欢哈利波特，哈利波特对用户相似度计算意义小,所以我们降低热门物品权重
<span class="math display">\[
sim(u_1,u_2) = \frac{\sum_{l\in I}weight(l)}{\sqrt{|J_1|\cdot|J_2|}}
\]</span></p>
<p><span class="math display">\[
weight(l) = \frac{1}{log(1+n_l)}
\]</span></p>
<p><span class="math display">\[n_l\]</span>:
喜欢物品l的用户数量，反应物品的热门程度。<span
class="math display">\[n_l\]</span>越大，<span
class="math display">\[log(1+n_l)\]</span>越大，权重越小</p>
<h4 id="运作基本流程-1">运作基本流程</h4>
<ol type="1">
<li><p>实现做离线计算，预先计算两个索引：</p>
<ol type="1">
<li><p>“user2item”：记录每个用户最近点击交互过的n个物品ID（lastN）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example 不一定是公司真实的保存方式</span></span><br><span class="line">user2item=&#123;</span><br><span class="line">    <span class="string">&#x27;u1&#x27;</span>:[[i1,like(u1,i1)],[i2,like(u1,i2)],...,[<span class="keyword">in</span>,like(u1,<span class="keyword">in</span>)]]</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>"user2user":计算用户之间两两相似度，记录每个用户最相似的k个用户。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">user2user=&#123;</span><br><span class="line">	#target user:[[similar user, similarity score]...]</span><br><span class="line">	&#x27;u1&#x27;:[[u2,0.9],[u6,0.88]...]</span><br><span class="line">	&#x27;u2&#x27;:...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol></li>
<li><p>线上做召回</p>
<ol type="1">
<li>给定用户ID，通过“user2user”找到top-k相似用户</li>
<li>对于top-k列表中每个用户，通过“user2item"找到用户近期感兴趣物品列表(last-n)。</li>
<li>对于召回的nk个相似物品，用公式预估用户对每个物品的兴趣分数</li>
<li>返回分数最高的100个物品，作为召回结果</li>
</ol></li>
</ol>
<h3 id="协同过滤缺点">协同过滤缺点</h3>
<p>。。。</p>
<h2 id="向量召回">向量召回</h2>
<h3 id="矩阵补充-matrix-completion">矩阵补充 Matrix Completion</h3>
<p>用于填充评分矩阵中无评分的部分，通过求user与item embedding的内积</p>
<p><img src="C:\Users\37523\AppData\Roaming\Typora\typora-user-images\image-20230626164840701.png" alt="image-20230626164840701" style="zoom:33%;" /></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626163645000.png"
alt="image-20230626163645000" />
<figcaption aria-hidden="true">image-20230626163645000</figcaption>
</figure>
<h4 id="数据集">数据集</h4>
<ol type="1">
<li><p>（用户ID,物品ID，兴趣分数）————》<span
class="math inline">\(dataset={(u,i,y)}\)</span></p></li>
<li><p>正负例子（0-4分）：</p>
<ol type="1">
<li>负例子：曝光没有点击-0分</li>
<li>正例子：点击、点赞、收藏、转发-各1分</li>
</ol></li>
</ol>
<h4 id="训练">训练</h4>
<p><span class="math display">\[
min_{A,B}\sum _{(u,i,y)\in dataset}(y-&lt;a_u,b_i&gt;)^2
\]</span></p>
<h4 id="缺点">缺点</h4>
<ol type="1">
<li>仅用ID embedding，没利用物品、用户的属性。</li>
<li>负样本选取方法不对。</li>
<li>做训练方法不好
<ol type="1">
<li>内积效果不如余弦相似度</li>
<li>用回归方法不如用分类方法。</li>
</ol></li>
</ol>
<h4 id="运作基本流程-2">运作基本流程</h4>
<ol type="1">
<li>离线计算
<ol type="1">
<li>训练矩阵A、B（embedding层的参数，A for user, B for item）</li>
<li>由于矩阵很大，为了快速读取使用hash方法：
<ol type="1">
<li>把矩阵A存储到key-value表{user_id: user_embedding}。</li>
<li>（加速最近邻查找）将item分区保存至key-value表</li>
</ol></li>
</ol></li>
<li>线上服务
<ol type="1">
<li>通过用户ID查询用户向量，记作A。</li>
<li>最近邻查找：查找用户最优可能感兴趣的k个物品作为召回结果。
<ol type="1">
<li>第i号物品的embedding向量记作<span
class="math inline">\(b_i\)</span></li>
<li>求<span class="math inline">\(&lt;a,b_i&gt;\)</span></li>
<li>返回内积最大的k个物品</li>
</ol></li>
</ol></li>
</ol>
<p><strong>加速最近邻查找方法</strong>：</p>
<p>一般item有几亿个，暴力计算内积并排序过慢</p>
<p>方法：</p>
<ol type="1">
<li><p>确定衡量最近邻标注：欧氏距离最小（L2距离），向量内积最大（内积相似度），向量夹角余弦最大（cosine相似度）</p></li>
<li><p>根据衡量标准将所有item
embedding分块，下面为根据余弦相似度分块的例子，每一个区域用一个向量E表示，通过key-value表保存区域向量E与区域中所有向量的embedding。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626171141459.png"
alt="image-20230626171141459" />
<figcaption aria-hidden="true">image-20230626171141459</figcaption>
</figure></li>
<li><p>求区域向量与user的余弦相似度，获取结构最大区域。再将区域中所有的item暴力枚举算相似度。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626171541263.png"
alt="image-20230626171541263" />
<figcaption aria-hidden="true">image-20230626171541263</figcaption>
</figure></li>
</ol>
<h3 id="双塔模型">双塔模型</h3>
<p>融合除了ID以为的别的特征</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626173816258.png"
alt="image-20230626173816258" />
<figcaption aria-hidden="true">image-20230626173816258</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626173835292.png"
alt="image-20230626173835292" />
<figcaption aria-hidden="true">image-20230626173835292</figcaption>
</figure>
<h4 id="数据集-1">数据集</h4>
<ol type="1">
<li><p>正样本</p>
<p>曝光且有点击的（user，item）组</p>
<p>问题：少部分物品占据大部分点击，导致正样品大多是热门物品，对冷门物品不公平。</p>
<p>解决：过采样冷门物品，或降采样热门物品</p>
<p>​ 过采样：一个样品出现多次</p>
<p>​ 降采样：一些样本被抛弃</p></li>
<li><p>负样本</p>
<p>混合几种负样本：50%的简单负样本，50%的困难负样本</p>
<p>我们分别讨论下面三种可以作为负样本的数据。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626202449765.png"
alt="image-20230626202449765" />
<figcaption aria-hidden="true">image-20230626202449765</figcaption>
</figure>
<ol type="1">
<li><p>简单负样本</p>
<p>没有被召回的数据: <strong>全体物品</strong></p>
<p>没被召回的数据，大概率是用户不感兴趣的，未被召回的样本约等于全体物品，所以在全体物品中做抽样作为负样本。</p>
<p><strong>均匀抽样</strong>：正样本大多是热门物品，负样本大多是冷门物品。（因为热门物品比例小），所以我们需要利用非均匀抽样打压热门物品。</p>
<p><strong>非均抽采样</strong>：负样本抽样概率与热门程度（点击次数）正相关，<span
class="math inline">\(抽样概率\propto (点击次数)^{0.75}\)</span></p>
<p><strong>Batch内负采样</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626203300364.png"
alt="image-20230626203300364" />
<figcaption aria-hidden="true">image-20230626203300364</figcaption>
</figure>
<p>一个batch有n个正样本对，一个用户和n-1个物品组成负样本，batch中一共有n（n-1）个负样本对。</p>
<p>此时，热门物品成为负样本的概率过大（热门物品成为正样本概率大）：<span
class="math inline">\(抽样概率\propto (点击次数)\)</span></p>
<p>所以做训练时，兴趣分数调整为：<span
class="math inline">\(cos(a,b_i)-logp_i\)</span>降低热门物品作为负样本的惩罚</p></li>
<li><p><strong>困难负样本</strong>：用户有一点兴趣，但兴趣不够，特别容易分错</p>
<p>被粗排淘汰的物品（比较困难）</p>
<p>精排分数靠后的物品（非常困难）</p></li>
</ol>
<p><strong>注意</strong>：不能用曝光但没有点击的样本，因为能通过精排（更复杂的模型）的样本已经是用户比较感兴趣的样本，可能只是机缘巧合没有点击，训练召回不能用这一类样本，但是训练排序可以</p></li>
</ol>
<h4 id="训练-1">训练</h4>
<h5 id="pointwise">Pointwise</h5>
<p>当做二分类任务，对于正样本，鼓励cos(a,b)接近+1；对于负样本，鼓励cos(a,b)接近-1</p>
<h5 id="pairwise">Pairwise</h5>
<p>鼓励<span class="math inline">\(cos(a,b^+)\)</span>大于<span
class="math inline">\(cos(a,b^-)\)</span></p>
<p>Triplet hinge loss: <span class="math display">\[
L(a,b^+,b^-) = max\{0,cos(a,b^-)+m-cos(a,b^+)\}
\]</span> m为超参数</p>
<p>Triplet logistic loss: <span class="math display">\[
L(a,b^+,b^-) = log(1+exp[\sigma(cos(a,b^-)-cos(a,b^+))])
\]</span></p>
<h5 id="listwise">Listwise</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626175637609.png"
alt="image-20230626175637609" />
<figcaption aria-hidden="true">image-20230626175637609</figcaption>
</figure>
<h4 id="运作基本流程-3">运作基本流程</h4>
<ol type="1">
<li>离线存储：把物品向量b存入向量数据库。</li>
<li>线上召回：查找用户最感兴趣的k个物品。
<ol type="1">
<li>给定用户ID和画像，线上用升级网络算用户向量A。</li>
<li>最近邻查找</li>
</ol></li>
</ol>
<p>为什么用户向量要在线计算：</p>
<ol type="1">
<li>没做一次召回只用到一个用户向量A，计算成本较小。</li>
<li>用户兴趣动态变化，物品较稳定。</li>
</ol>
<h4 id="模型更新">模型更新</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626205649864.png"
alt="image-20230626205649864" />
<figcaption aria-hidden="true">image-20230626205649864</figcaption>
</figure>
<p><strong>全量更新</strong>：</p>
<p>​
在昨天模型参数基础上做训练（不是随机初始化），用昨天的数据，shuffle后训练一个epoch后发布新的用户塔神经网络和物品向量，供线上召回使用。</p>
<p><strong>增量更新</strong>：</p>
<p>​ 用户兴趣随时发生变化，实时收集线上数据，对模型做online
learning，增量更新ID
Embedding参数(不更新神经网络其他部分参数)，发布用户ID
Embedding，供用户塔线上计算用户向量。</p>
<p><strong>不能只做增量更新，不做全量更新</strong></p>
<ol type="1">
<li>小时级数据有偏差，分钟级偏差更大。</li>
<li>全量更新：random shuffle一天数据，做
1epoch训练；增量更新按照数据从早到晚顺序做1epoch训练，全量更新效果更好。</li>
</ol>
<h4 id="自监督学习">自监督学习</h4>
<h5 id="背景">背景</h5>
<p>推荐系统头部效应严重：少部分物品占据大部分点击，大部分物品曝光、点击次数不高，导致高点击物品的表征学习的好，长尾物品的表征学的不好，用自监督学习做data
augmentation，更好的学习长尾物品的向量表征。</p>
<h5 id="method">Method</h5>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626212328043.png"
alt="image-20230626212328043" />
<figcaption aria-hidden="true">image-20230626212328043</figcaption>
</figure>
<h6 id="特征变换方法">特征变换方法</h6>
<ol type="1">
<li><p>Random Mask</p>
<p>随机选一些离散特征(例如类目特征)，把它们遮住</p>
<p>例子：<span class="math inline">\(U=\{数码，摄影\}\)</span>-&gt;<span
class="math inline">\(U&#39;-\{default\}\)</span></p></li>
<li><p>Dropout</p>
<p>一个物品可以有多个类目，那么类目是一个多值离散特征。Dropout会随机丢弃特征中50%的值。</p>
<p>例子：<span class="math inline">\(U=\{数码，摄影\}\)</span>-&gt;<span
class="math inline">\(U&#39;-\{数码\}\)</span></p></li>
<li><p>complementary互补特征</p>
<p>假设物品一共有四种特征：ID,类目，关键词，城市</p>
<p>随机分成两组：{ID,关键词}，{类目，城市}</p>
<p>{ID,default，关键词，default}作为表征i‘</p>
<p>{default，类目，default，城市}作为表征i‘’</p></li>
<li><p>Mask一组关联的特征</p>
<p>p(u): 某特征取值为u的概率</p>
<p>p(u,v):某特征取值为u，另一个特征取值为v同时发生的概率</p>
<p>离线计算特征的两两关系，用户信息(mutual information): <span
class="math display">\[
MI(U,V)=\sum_{u\in U}\sum_{v\in V}p(u,v)\cdot log\frac{p(u,v)}{p(u)\cdot
p(v)}
\]</span>
假设一共有k种特征。离线计算两两MI，得到kxk的矩阵，随机选一个特征为种子，找到种子最相关的k/2中特征Mask掉，保留其余的k/2中特征。</p>
<p>比random
mask、dropout、互补特征等方法效果更好，但方法复杂实现难度大不容易维护。</p></li>
</ol>
<h6 id="自监督训练">自监督训练</h6>
<p>从全体物品中均匀抽样得到m个物品，作为一个batch。</p>
<p>做两类特征变换，物品他输出两组向量。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626214137364.png"
alt="image-20230626214137364" />
<figcaption aria-hidden="true">image-20230626214137364</figcaption>
</figure>
<h6 id="自监督训练正常训练">自监督训练+正常训练</h6>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626214246267.png"
alt="image-20230626214246267" />
<figcaption aria-hidden="true">image-20230626214246267</figcaption>
</figure>
<h2 id="不适合召回的模型">不适合召回的模型</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230626175824199.png"
alt="image-20230626175824199" />
<figcaption aria-hidden="true">image-20230626175824199</figcaption>
</figure>
<p>召回需要计算的item量很大，所以我们一般只做后期融合（计算相似度的时候再融合user和item的embedding），因为融合步骤一般要在线计算不能离线计算完保存（需求内存量太大）。如果我们在召回阶段就要让user
embedding与上亿个item
embedding过神经网络模型，这样时间复杂度太高了。</p>
<h2 id="其他方式召回">其他方式召回</h2>
<p>地理召回</p>
<p>作者召回</p>
<p>缓存召回：复用前n次推荐精排的结果</p>
<h2 id="曝光过滤与链路">曝光过滤与链路</h2>
<ul>
<li>如果用户看过某个物品，则不再把该物品曝光给该用户</li>
<li>对于每个用户，记录已经曝光给他的物品。(小红书只召回1个月以内的笔记，因此只需要记录每个用户最近1个月的曝光历史。)</li>
<li>对于每个召回的物品，判断它是否已经给该用户曝光过排除掉曾经曝光过的物品。</li>
<li>一位用户看过n个物品，本次召回r个物品，如果暴力对比，需要O(nr)的时间。</li>
</ul>
<h3 id="bloom-filter">Bloom Filter</h3>
<ul>
<li>Bloom filter 判断一个物品ID是否在已曝光的物品集合中。</li>
<li>如果判断为no，那么该物品一定不在集合中</li>
<li>如果判断为yes，那么该物品很可能在集合中。(可能误伤错误判断未曝光物品为已曝光，将其过滤掉)</li>
<li>Bloom flter 把物品集合表征为一个m维二进制向量。</li>
<li>Bloom
filter有k个哈希函数，每个哈希函数把物品I映射成介于0和m-1之间的整数。</li>
<li>已曝光物品和召回物品都可以用这个m维向量表示。</li>
</ul>
<p>当k=1：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430102619856.png"
alt="image-20240430102619856" />
<figcaption aria-hidden="true">image-20240430102619856</figcaption>
</figure>
<p>当k=3：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430102711948.png"
alt="image-20240430102711948" />
<figcaption aria-hidden="true">image-20240430102711948</figcaption>
</figure>
<p>BloomFilter误伤概率：</p>
<ul>
<li>曝光物品集合大小为n，二进制向量维度为m，使用k个哈希函数。</li>
<li>误伤的概率为<span
class="math inline">\(δ≈(1-exp(-\frac{kn}{m}))^k\)</span>
<ul>
<li>n越大，向量中的1越多，误伤概率越大。</li>
<li>m越大，向量越长，越不容易发生哈希碰撞。但要求更多存储空间。</li>
<li>k太大、太小都不好，k有最优取值。</li>
</ul></li>
<li>计算k最优参数，设定可容忍误伤概率<span
class="math inline">\(δ\)</span>：</li>
<li><span class="math inline">\(k=1.44\cdot
ln(\frac{1}{δ})\)</span></li>
<li><span class="math inline">\(m=2n\cdot ln(\frac{1}{δ})\)</span></li>
</ul>
<p>优缺点</p>
<ul>
<li><p>Bloom filtcr
把物品的集合表示成一个二进制向量，节省存储空间和计算成本。</p></li>
<li><p>每往集合中添加一个物品，只需要把向量k个位置的元素置为1。(如果原本就是1，则不变)</p></li>
<li><p>Bloom filter只支持添加物品，不支持删除物品。</p></li>
<li><p>每天都需要从物品集合中移除年龄大于1个月的物品(超龄物品不可能被召回，没必要把它们记录在Bloom
filter，降低n可以降低误伤率)</p></li>
</ul>
<h1 id="排序">排序</h1>
<h2 id="排序模型特征">排序模型特征</h2>
<h3 id="用户画像">用户画像</h3>
<ul>
<li>用户ID</li>
<li>性别、年龄</li>
<li>新老、活跃度</li>
<li>感兴趣类目、关键词、品牌</li>
</ul>
<h3 id="物品画像">物品画像</h3>
<ul>
<li>物品ID</li>
<li>发布时间</li>
<li>GeoHash（经纬度编码）、所在城市</li>
<li>标题、类目、关键词、品牌</li>
<li>字数、图片数、视频清晰度、标签数</li>
<li>内容信息量、图片美学</li>
</ul>
<h3 id="用户统计特征">用户统计特征</h3>
<ul>
<li>用户最近30天天曝光数、点击数、点赞数、收藏数</li>
<li>按照笔记图文/视频分桶。(比如最近7天，该用户对图文笔记的点击率、对视频笔记的点击率。)</li>
<li>按照笔记类目分桶。(比如最近30天，用户对美妆笔记的点击率、对美食笔记的点击率、对科技数码笔记的点击率。)</li>
</ul>
<h3 id="笔记统计特征">笔记统计特征</h3>
<ul>
<li>笔记最近30天(7天、1天、1小时)的曝光数、点击数点赞数、收藏数…。</li>
<li>按照用户性别分桶、按照用户年龄分桶…</li>
<li>作者特征:
<ul>
<li>发布笔记数</li>
<li>粉丝数</li>
<li>消费指标(曝光数、点击数、点赞数、收藏数)</li>
</ul></li>
</ul>
<h3 id="场景特征">场景特征</h3>
<ul>
<li>用户定位GeoHash(经纬度编码)、城市。</li>
<li>当前时刻(分段，做embedding)</li>
<li>是否是周末、是否是节假日。</li>
<li>手机品牌、手机型号、操作系统。</li>
</ul>
<h3 id="特征处理">特征处理</h3>
<ul>
<li>离散特征:做embedding。
<ul>
<li>用户ID、笔记ID、作者ID。</li>
<li>类目、关键词、城市、手机品牌</li>
</ul></li>
<li>连续特征:做分桶，变成离散特征。
<ul>
<li>年龄、笔记字数、视频长度。</li>
<li>连续特征:其他变换。</li>
<li>曝光数、点击数、点赞数等数值做log(1+x)</li>
<li>转化为点击率、点赞率等值，并做平滑。</li>
</ul></li>
</ul>
<h2 id="粗排模型">粗排模型</h2>
<ul>
<li>给几千篇笔记打分</li>
<li>单次推理代价必须小（用户与物品特征后期融合）</li>
<li>预估的准确性不高</li>
</ul>
<h3 id="粗排的三塔模型">粗排的三塔模型</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425153102228.png"
alt="image-20240425153102228" />
<figcaption aria-hidden="true">image-20240425153102228</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425153151749.png"
alt="image-20240425153151749" />
<figcaption aria-hidden="true">image-20240425153151749</figcaption>
</figure>
<h2 id="精排模型">精排模型</h2>
<ul>
<li>给几百篇笔记打分</li>
<li>单次推理代价很大（用户与物品特征前期融合）</li>
<li>预估准确性更高</li>
</ul>
<h3 id="多目标模型">多目标模型</h3>
<h4 id="模型结构">模型结构</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145400996.png"
alt="image-20240425145400996" />
<figcaption aria-hidden="true">image-20240425145400996</figcaption>
</figure>
<p>loss： <span class="math display">\[
Loss=\sum_{i=1}^4\alpha_i \cdot CrossEntropy(y_i,p_i)
\]</span></p>
<h4 id="估值校准">估值校准：</h4>
<p>why：为了缩短训练时间会对负样本进行降采样，由于负样本变少，预估点击率大于真实点击率：</p>
<p>真实点击率:<span
class="math inline">\(p_{true}=\frac{n_+}{n_++n_-}\)</span></p>
<p>预估点击率：<span
class="math inline">\(p_{pred}=\frac{n_+}{n_++\alpha \cdot
n_-}\)</span></p>
<p>校准公式： <span class="math inline">\(p_{true}=\frac{\alpha \cdot
p_{pred} }{(1-p_{pred})+\alpha \cdot p_{pred}}\)</span></p>
<h3 id="multi-gate-mixture-of-experts-mmoe">Multi-gate
Mixture-of-Experts (MMoE)</h3>
<h4 id="模型结构-1">模型结构</h4>
<p>假设现在需要求点击率与点赞率两个指标</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145112596.png"
alt="image-20240425145112596" />
<figcaption aria-hidden="true">image-20240425145112596</figcaption>
</figure>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425145206437.png"
alt="image-20240425145206437" />
<figcaption aria-hidden="true">image-20240425145206437</figcaption>
</figure>
<h4 id="极化现象">极化现象</h4>
<p>softmax输出的权重接近与0,0,0...1，这样不能充分利用所有模型结构</p>
<p>解决方法：dropout</p>
<h2 id="预估分数融合">预估分数融合</h2>
<p>将点击率、点赞量等指标融合，计算出最终分数</p>
<ul>
<li><p>简单加权和</p>
<p><span class="math inline">\(p_{click}+w_1\cdot p_{like}+ w_2\cdot
p_{collect} + \cdots\)</span></p></li>
<li><p>点击率乘以其他项加权和</p>
<p><span class="math inline">\(p_{click}\cdot (w_1\cdot p_{like}+
w_2\cdot p_{collect} + \cdots)\)</span></p></li>
<li><p>海外某短视频app：</p>
<p><span class="math inline">\((1+w_1\cdot p_{time})^{\alpha_1}\cdot
(1+w_2\cdot p_{time})^{\alpha_2}\cdots\)</span></p>
<p><span class="math inline">\(p_{time}\)</span>是预估播放时长</p></li>
<li><p>国内某视频app：用排名计算</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425150136906.png"
alt="image-20240425150136906" />
<figcaption aria-hidden="true">image-20240425150136906</figcaption>
</figure></li>
<li><p>电商</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425150219933.png"
alt="image-20240425150219933" />
<figcaption aria-hidden="true">image-20240425150219933</figcaption>
</figure></li>
</ul>
<h2 id="视频播放时长建模">视频播放时长建模</h2>
<h3 id="播放时长建模">播放时长建模</h3>
<p>训练：最小化y与p的交叉熵函数</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430105536098.png"
alt="image-20240430105536098" />
<figcaption aria-hidden="true">image-20240430105536098</figcaption>
</figure>
<p>预测：直接求<span class="math inline">\(exp(z)\)</span></p>
<h3 id="视频完播">视频完播</h3>
<h4 id="建模方法">建模方法</h4>
<ul>
<li><p>回归方法</p>
<p>视频长度10分钟，实际播放4分钟，则实际播放率为y=0.4
让预估播放率p拟合y: <span
class="math inline">\(loss=y·logp+(1-y)·log(1-p)\)</span></p>
<p>线上预估完播率，模型输出p=0.73，意思是预计播放73%。</p></li>
<li><p>二元分类</p>
<p>定义完播指标，比如完播80%。 例:视频长度10分钟，播放$&gt;<span
class="math inline">\(8分钟作为正样本，播放\)</span>&lt;<span
class="math inline">\(8分钟作为负样本。
做二元分类训练模型:播放\)</span>&gt;<span class="math inline">\(80%vs
播放\)</span>&lt;$80%。线上预估完播率，模型输出p=0.73，意思是P(播放&gt;80%)=
0.73</p></li>
</ul>
<h4 id="融入融分公式">融入融分公式</h4>
<p>不可直接使用融分公式，因为视频越长完播率越低</p>
<p>需要做调整: <span class="math display">\[
p_{finish}=\frac{预估完播率}{f（视频时长）}
\]</span> "把<span
class="math inline">\(p_{finish}\)</span>作为融分公式中的一项。</p>
<h1 id="特征交叉">特征交叉</h1>
<h2 id="factorized-machine">Factorized Machine</h2>
<p>tbd</p>
<h2 id="dcn">DCN</h2>
<p>使用场景：</p>
<ul>
<li>双塔模型中用户塔和物品塔</li>
<li>排序模型</li>
<li>MMOE模型中专家网络</li>
</ul>
<h2 id="ppnet">PPNet</h2>
<p>语音识别中的LHUC</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425191526931.png"
alt="image-20240425191526931" />
<figcaption aria-hidden="true">image-20240425191526931</figcaption>
</figure>
<p>PPNET</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425191558660.png"
alt="image-20240425191558660" />
<figcaption aria-hidden="true">image-20240425191558660</figcaption>
</figure>
<h2 id="senet">SENet</h2>
<p>有点像autoencoder+全局注意力机制，中间缩小参数量m/r是避免过拟合</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240425192121242.png"
alt="image-20240425192121242" />
<figcaption aria-hidden="true">image-20240425192121242</figcaption>
</figure>
<h2 id="bilinear-cross">bilinear cross</h2>
<ul>
<li>内积 bilinear cross</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426103501935.png"
alt="image-20240426103501935" />
<figcaption aria-hidden="true">image-20240426103501935</figcaption>
</figure>
<ul>
<li>哈达玛bilinear cross</li>
</ul>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426103501935.png" /></p>
<h2 id="fibinet">FiBiNet</h2>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426110218217.png"
alt="image-20240426110218217" />
<figcaption aria-hidden="true">image-20240426110218217</figcaption>
</figure>
<h1 id="用户行为序列建模">用户行为序列建模</h1>
<h2 id="last-n">Last N</h2>
<ul>
<li>用户最近的n次交互(点击、点赞等)的物品 ID。</li>
<li>对Last N物品I做embedding，得到n个向量。</li>
<li>把几个向量取平均，作为用户的一种特征。</li>
</ul>
<h2 id="din模型注意力机制">DIN模型（注意力机制）</h2>
<ul>
<li>对于某候选物品，计算它与用户 Last N物品的相似度。</li>
<li>以相似度为权重，求用户Last N物品向量的加权和，结果是一个向量。</li>
<li>把得到的向量作为一种用户特征，输入排序模型，预估(用户，候选物品)的点击率、点赞率等指标。</li>
</ul>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240426110602597.png" /></p>
<p>简单平均和 注意力机制 都适用于精排模型。</p>
<ul>
<li>简单平均适用于双塔模型、三塔模型。
<ul>
<li>简单平均只需要用到LastN，属于用户自身的特征。</li>
<li>把LastN向量的平均作为用户塔的输入。</li>
</ul></li>
<li>注意力机制不适用于双塔模型、三塔模型。
<ul>
<li>注意力机制需要用到LastN+候选物品。</li>
<li>用户塔看不到候选物品，不能把注意力机制用在用户塔</li>
</ul></li>
</ul>
<h2 id="sim模型长序列建模">SIM模型（长序列建模）</h2>
<p>DIN模型缺点：</p>
<ul>
<li>注意力层计算量与n相关</li>
<li>只能记录最近几百个物品，否则计算量太大</li>
<li>关注短期兴趣，遗忘长期兴趣</li>
</ul>
<p>SIM模型目的：</p>
<ul>
<li>保留用户长期行为序列，而且计算量不会很大。</li>
</ul>
<p>改善DIN方法：DIN对Last N向量做加权平均，权重是相似度，如果某Last
N物品与候选物品差异很大，则权重接近零。可以提前快速排除掉与候选物品无关（相似度低，权重接近0）的Last
N物品，降低注意力层的计算量。</p>
<h3 id="模型架构">模型架构</h3>
<ul>
<li>保留用户长期行为记录，n的大小可以是几千。</li>
<li>对于每个候选物品，在用户Last
N记录中做快速查找，找到k个相似物品。</li>
<li>把LastN变成TopK，然后输入到注意力层</li>
<li>SIM 模型减小计算量(从n降到k)。</li>
</ul>
<h4 id="查找">查找</h4>
<ul>
<li>Hard Search（基于规则）
<ul>
<li>根据候选物品的类目，保留Last N物品中类目相同的。
·简单，快速，无需训练。</li>
</ul></li>
<li>Soft Search
<ul>
<li>把物品做embedding，变成向量。</li>
<li>把候选物品向量作为query，做k近邻查找，保留LastN物品中最接近的k个。</li>
<li>效果更好，编程实现更复杂。</li>
</ul></li>
</ul>
<h4 id="注意力机制">注意力机制</h4>
<ul>
<li>只使用挑出来的Top K计算权重</li>
<li>使用时间信息：SIM序列长，记录用户长期行为，时间越久远，重要性越低
<ul>
<li>用户与某个LastN物品的交互时刻距今为δ。</li>
<li>对δ做离散化，再做embedding，变成向量d</li>
<li>把两个向量做concatenation，表征一个LastN物品。
<ul>
<li>向量x是物品embedding。</li>
<li>向量d是时间的embedding</li>
</ul></li>
</ul></li>
</ul>
<h1 id="重排">重排</h1>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430142915426.png"
alt="image-20240430142915426" />
<figcaption aria-hidden="true">image-20240430142915426</figcaption>
</figure>
<p>粗排精排：</p>
<ul>
<li>粗排和精排用多目标模型对物品做 pointwise打分。</li>
<li>对于物品i，模型输出点击率、交互率的预估，融合成分数reward。<span
class="math inline">\(reward_i\)</span>表示用户对物品i的兴趣，即物品本身价值。</li>
</ul>
<p>后处理（精排的后处理称为重排）：</p>
<ul>
<li>从n个后序物品选出k个，既要她们总分高，也需要它们有多样性</li>
</ul>
<h2 id="相似性度量">相似性度量</h2>
<p>提高多样性意味着推荐的物品不可过于相似，首先需要度量物品之间相似度</p>
<h3 id="基于物品属性标签">基于物品属性标签。</h3>
<p>物品属性标签：类目、品牌、关键词………</p>
<p>根据一级类目、二级类目、品牌计算相似度</p>
<ul>
<li>物品i:美妆、彩妆、香奈儿</li>
<li>物品j:美妆、香水、香奈儿</li>
</ul>
<p>相似度:simi(i,j)=1，simz(i,j)=0，sim3(i,j)=1。在做加权</p>
<h3 id="基于物品向量表征">基于物品向量表征。</h3>
<ul>
<li><p>用召回的双塔模型学到的物品向量(不好)</p>
<p>召回双塔模型基于用户物品交互，冷门物品没办法学好表征，热门物品多交互也不代表相似</p></li>
<li><p>基于内容的向量表征(好)</p>
<p>用cv或nlp模型，提取特征</p>
<p>使用clip预训练方法：对于图片文字二元组，预测图文是否匹配，无需人工标注</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430142711097.png"
alt="image-20240430142711097" />
<figcaption aria-hidden="true">image-20240430142711097</figcaption>
</figure></li>
</ul>
<h2 id="maximal-margianl-relevancemmr">Maximal Margianl
Relevance（MMR）</h2>
<p>精排给n个候选物品打分，把第i和j个物品的相似度记作
sim(i,j)，从几个物品中选出k个，既要有高精排分数也要有多样性。</p>
<h3 id="原理">原理</h3>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430143624521.png"
alt="image-20240430143624521" />
<figcaption aria-hidden="true">image-20240430143624521</figcaption>
</figure>
<h3 id="流程">流程</h3>
<p>1.已选中的物品S初始化为空集，未选中的物品初始化为全集 {1,…,n}
2.选择精排分数rewardi最高的物品，从集合R移到S 3.做k-1轮循环:
a.计算集合见中所有物品的分数<span class="math inline">\(\{MR_i\}_{i\in
R}\)</span>。 b.选出分数最高的物品，将其从<span
class="math inline">\(R\)</span>移到<span
class="math inline">\(S\)</span>。</p>
<h3 id="trick滑动窗口">Trick：滑动窗口</h3>
<ul>
<li>已选中的物品越多(即集合S越大)，越难找出物品<span
class="math inline">\(i\in R\)</span>使得i与S中的物品都不相似。</li>
<li>设sim 的取值范围是「0,1]。当S很大时，多样性分数<span
class="math inline">\({max}_{j\in S}sim(i,j)\)</span>总是约等于1,导致
MMR 算法失效。</li>
<li>解决方案:设置一个滑动窗口W，比如最近选中的10个物品，用W代替MMR
公式中的S。</li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430144236363.png"
alt="image-20240430144236363" />
<figcaption aria-hidden="true">image-20240430144236363</figcaption>
</figure>
<h2 id="通过重排规则提高多样性">通过重排规则提高多样性</h2>
<h3 id="重排规则">重排规则</h3>
<ul>
<li><p>最多连续出现k篇某种笔记</p>
<p>小红书推荐系统的物品分为图文笔记、视频笔记。
最多连续出现k=5篇图文笔记，最多连续出现k-5篇视频笔记。
如果排i到i+4的全都是图文笔记，那么排在i+5的必须是视频笔记。</p></li>
<li><p>每k篇笔记最多出现1篇某种笔记
运营推广笔记的精排分会乘以大于1的系数(boost)帮助笔记获得更多曝光。
为了防止boost影响体验，限制每k-9篇笔记最多出现1篇运营推广笔记。
如果排第i位的是运营推广笔记，那么排i+1到i+8的不能是运营推广笔记。</p></li>
<li><p>每k篇笔记最多出现1篇某种笔记
运营推广笔记的精排分会乘以大于1的系数(boost)帮助笔记获得更多曝光。
为了防止boost影响体验，限制每k-9篇笔记最多出现1篇运营推广笔记。
如果排第i位的是运营推广笔记，那么排i+1到i+8的不能是运营推广笔记。</p></li>
</ul>
<h3 id="mmr重排规则">MMR+重排规则</h3>
<p>每一轮先用规则排除掉R中的部分物品，得到子集R'。</p>
<p>MMR 公式中的R替换成子集R'，选中的物品符合规则。</p>
<h2 id="dpp多样性算法">DPP多样性算法</h2>
<h3 id="数学基础-超平形体">数学基础-超平形体</h3>
<h4 id="二维">二维</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430155731053.png"
alt="image-20240430155731053" />
<figcaption aria-hidden="true">image-20240430155731053</figcaption>
</figure>
<p>2维空间的超平形体为平行四边形。</p>
<p>平行四边形中的点可以表示为 <span class="math display">\[
x=\alpha_1v_1+ \alpha_2v_2
\]</span> 系数<span class="math inline">\(\alpha_1\)</span>和<span
class="math inline">\(\alpha_2\)</span>的取值范围是[0,1]</p>
<h4 id="三维">三维</h4>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430155806892.png"
alt="image-20240430155806892" />
<figcaption aria-hidden="true">image-20240430155806892</figcaption>
</figure>
<p>2维空间的超平形体为平行六面体。</p>
<p>平行四边形中的点可以表示为 <span class="math display">\[
x=\alpha_1v_1+ \alpha_2v_2+ \alpha_3v_3
\]</span> 系数<span class="math inline">\(\alpha_1\)</span>和<span
class="math inline">\(\alpha_2\)</span>、<span
class="math inline">\(\alpha_3\)</span>的取值范围是[0,1]</p>
<h4 id="多维">多维</h4>
<p>一组向量<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>可以确定一个k维超平行体： <span class="math display">\[
P(v_1,\cdots, v_k) = \{\alpha_1v_1+\cdots+\alpha_kv_k|0\leqslant
\alpha_1,\cdots,\alpha_k \leqslant 1\}
\]</span> 要求<span class="math inline">\(k\le
d\)</span>,比如d=3维向量空间中有k=2维平行四边形。否则超平行体会跟拍扁了一样。</p>
<h4 id="超平形体体积">超平形体体积</h4>
<p>构成超平形体的向量正交时，超平行体体积最大，vol=1</p>
<p>如果<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>线性相关，体积<span
class="math inline">\(vol(p)=0\)</span></p>
<p>我们可以认为体积最大意味着多样性好，体积最小意味着多样性差。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430162451245.png"
alt="image-20240430162451245" />
<figcaption aria-hidden="true">image-20240430162451245</figcaption>
</figure>
<p>对于一组向量<span class="math inline">\(v_1,\cdots,v_k\in
R^d\)</span>，<span class="math inline">\(k\leq
d\)</span>,把它们作为矩阵的列，行列式与体积满足： <span
class="math display">\[
det(V^TV) = vol(p(v_1,\cdots,v_k))^2
\]</span></p>
<h3 id="dpp应用于多样性">DPP应用于多样性</h3>
<p>精排给n个物品打分:<span class="math inline">\(reward_1,\cdots,
reward_n\)</span></p>
<p>n 个物品的向量表征:<span class="math inline">\(v_1,\cdots , v_n \in
R^d\)</span></p>
<p>从n个物品中选出k个物品，组成集合S</p>
<ul>
<li><p>价值大:分数之和<span class="math inline">\(∑_{j\in
s}reward_j\)</span>越大越好</p></li>
<li><p>多样性好:S中k个向量组成的超平形体P(S)的体积越大越好。</p></li>
</ul>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20240430165104679.png"
alt="image-20240430165104679" />
<figcaption aria-hidden="true">image-20240430165104679</figcaption>
</figure>
<p>集合S中的k个物品的向量作为列，组成矩阵 <span
class="math inline">\(V_s\in R^{dxk}\)</span></p>
<p>以这k个向量作为边，组成超平形体P(S) <span class="math display">\[
det(V_s^TV_s) = vol(p(S))^2
\]</span> DPP是一种传统的统计学习方法 <span class="math display">\[
\mathop{\arg\min}\limits_{S:|S|=k} \space log det(V_s^TV_s)
\]</span> 应用于推荐系统 <span class="math display">\[
\mathop{\arg\min}\limits_{S:|S|=k}\space \theta\cdot (\sum_{j\in
S}reward_j)+(1-\theta)\cdot log det(V_s^TV_s)
\]</span> 我们构造一个nxn的矩阵<span
class="math inline">\(A\)</span>，它的(i,j)元素使<span
class="math inline">\(a_{ij}=v_i^Tv_j\)</span>，计算这个矩阵的时间复杂度是<span
class="math inline">\(O(n^2d)\)</span>。 <span class="math display">\[
A_s \in R^{(k\times k)}=V_s^TV_s
\]</span> 是矩阵<span
class="math inline">\(A\)</span>的子矩阵，如果<span
class="math inline">\(i,j\in S\)</span>,则<span
class="math inline">\(a_{ij}\)</span>是<span
class="math inline">\(A_s\)</span>的一个元素。</p>
<p>DPP是个组合优化问题，从集合{1…,n}中选出一个大小为k的子集S。</p>
<h4 id="暴力贪心算法">暴力贪心算法</h4>
<p>用S表示已选中的物品，用R表示未选中的物品，贪心算法求解 <span
class="math display">\[
\mathop{\arg\min}\limits_{i\in R}\space \theta\cdot
(reward_i)+(1-\theta)\cdot log det(A_{S\cup i})
\]</span> 对于单个i，计算 <span class="math inline">\(A_{S\or
i}\)</span>的行列式需要<span
class="math inline">\(O(|A|^3)\)</span>时间(求行列式就是需要<span
class="math inline">\(O(n^3)\)</span>)</p>
<p>对于所有的<span class="math inline">\(i\in
R\)</span>，计算行列式需要时间<span class="math inline">\(O(|A|^3\cdot
|R|)\)</span>。</p>
<p>需要求解上式k次才能选出k个物品。如果暴力计算行列式，那么总时间复杂度为
<span class="math display">\[
O(|A|^3\cdot |R|\cdot k)=O(nk^4)
\]</span> 再加上计算A的时间，暴力算法总时间复杂度是： <span
class="math display">\[
O(n^2d+nk^4)
\]</span></p>
<h4 id="hulu快速算法">Hulu快速算法</h4>
<p>给定向量<span class="math inline">\(v_1,\cdots , v_n \in
R^d\)</span>，需要<span
class="math inline">\(O(n^2d)\)</span>时间计算A</p>
<p>用<span
class="math inline">\(O(nk^2)\)</span>)时间计算所有的行列式(利用Cholesky分解)</p>
<ul>
<li><p>Cholesky 分解</p></li>
<li><p>Cholesky 分解<span
class="math inline">\(A_s=LL^T\)</span>，其中L是下三角矩阵(对角线以上的元素全零)</p>
<p>Cholesky 分解可供计算<span
class="math inline">\(A_s\)</span>的行列式。</p>
<ul>
<li>下三角矩阵L的行列式 det(L)等于L对角线元素乘积。</li>
<li>As 的行列式为 <span class="math inline">\(det(A_s)= det(L)^2=\prod_i
l_{ii}^2\)</span></li>
</ul></li>
<li><p>已知<span
class="math inline">\(A_s=LL^T\)</span>，则可以快速求出所有<span
class="math inline">\(A_{S\cup i}\)</span> 的
Cholesky分解(有方法可以快速算出增加一行一列的行列式)，因此可以快速算出所有
<span class="math inline">\(A_{S\cup i}\)</span> 的行列式。</p></li>
</ul>
<h3 id="dpp扩展-滑动窗口">DPP扩展-滑动窗口</h3>
<p>与MMR方法一样，随着<span
class="math inline">\(S\)</span>增大，其中相似物品越来越多，物品向量会趋近线性相关。</p>
<p>DPP失效</p>
<h1 id="冷启动">冷启动</h1>
<h1 id="涨指标方法">涨指标方法</h1>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/03/07/optimizer/" rel="prev" title="常见优化函数">
                  <i class="fa fa-chevron-left"></i> 常见优化函数
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/03/14/regularization/" rel="next" title="Regularization">
                  Regularization <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lory</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
