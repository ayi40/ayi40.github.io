<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content=".">
<meta property="og:type" content="article">
<meta property="og:title" content="Regularization">
<meta property="og:url" content="http://example.com/2023/03/14/regularization/index.html">
<meta property="og:site_name" content="Lory&#39;s Page">
<meta property="og:description" content=".">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-03-14T20:46:25.000Z">
<meta property="article:modified_time" content="2023-11-14T13:11:49.425Z">
<meta property="article:author" content="Lory">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/03/14/regularization/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/03/14/regularization/","path":"2023/03/14/regularization/","title":"Regularization"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Regularization | Lory's Page</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Lory's Page</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">1.</span> <span class="nav-text">什么是正则化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.</span> <span class="nav-text">常见正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#l1%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.1.</span> <span class="nav-text">l1正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A8%80%E7%96%8F%E5%8E%9F%E5%9B%A0"><span class="nav-number">2.1.1.</span> <span class="nav-text">稀疏原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">2.1.2.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#l2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">2.2.</span> <span class="nav-text">l2正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dropout"><span class="nav-number">2.3.</span> <span class="nav-text">Dropout</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#dropout%E8%AE%AD%E7%BB%83%E5%87%BA%E7%9A%84%E5%8F%82%E6%95%B0%E9%9C%80%E8%A6%81%E4%B9%98%E4%BB%A5keep-prib%E4%BD%BF%E7%94%A8"><span class="nav-number">2.3.1.</span> <span class="nav-text">dropout训练出的参数需要乘以keep-prib使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A9%E5%81%9C"><span class="nav-number">2.4.</span> <span class="nav-text">早停</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%A9%E5%85%85%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">2.5.</span> <span class="nav-text">扩充数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="nav-number">2.5.1.</span> <span class="nav-text">数据增强方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bnbatch-normalization"><span class="nav-number">2.6.</span> <span class="nav-text">BN（Batch Normalization）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%BA%E5%BA%A6%E5%8F%98%E6%8D%A2%E5%92%8C%E5%81%8F%E7%A7%BB%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">2.6.1.</span> <span class="nav-text">尺度变换和偏移的作用：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bn%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C"><span class="nav-number">2.6.2.</span> <span class="nav-text">BN训练和测试有什么不同</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bn%E5%92%8Cln%E7%9A%84%E5%B7%AE%E5%88%AB"><span class="nav-number">2.6.3.</span> <span class="nav-text">BN和LN的差别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8bn%E5%92%8Cdropout"><span class="nav-number">2.6.4.</span> <span class="nav-text">如何同时使用BN和dropout</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bagging-%E5%92%8Cbootstrap"><span class="nav-number">2.7.</span> <span class="nav-text">Bagging 和Bootstrap？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB"><span class="nav-number">2.8.</span> <span class="nav-text">参数共享</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">2.9.</span> <span class="nav-text">数据标准化</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Lory</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/14/regularization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Lory">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lory's Page">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Regularization | Lory's Page">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Regularization
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-03-14 20:46:25" itemprop="dateCreated datePublished" datetime="2023-03-14T20:46:25+00:00">2023-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-14 13:11:49" itemprop="dateModified" datetime="2023-11-14T13:11:49+00:00">2023-11-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/Basic/" itemprop="url" rel="index"><span itemprop="name">Basic</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>.</p>
<span id="more"></span>
<h1 id="什么是正则化">什么是正则化</h1>
<p>目的：防止模型过拟合</p>
<p>原理：正则化通过在损失函数中<strong>引入惩罚项来限制模型的复杂度</strong>，以防止模型过度拟合训练数据。惩罚项会在优化过程中对模型的参数进行调整，以平衡模型的拟合能力和泛化能力。</p>
<p>https://www.zhihu.com/question/20924039</p>
<p>最直接的防止过拟合的方法就是减少特征数量，就是减少0范数（向量中非零元素的个数），但是0范数很难求，所以就有了1范数，2范数。</p>
<p>作用：</p>
<ol type="1">
<li>防止过拟合</li>
<li>特征选择：l1正则化</li>
<li>改善模型稳定性</li>
</ol>
<h1 id="常见正则化">常见正则化</h1>
<h2 id="l1正则化">l1正则化</h2>
<p><span class="math display">\[
l1=\lambda||\vec{w}||_1=\sum_i|w_i|
\]</span></p>
<p><span class="math inline">\(\lambda\)</span>控制约束程度</p>
<p>l1不仅可以<strong>约束参数量</strong>，还可以使<strong>参数更稀疏</strong>。因为对目标函数经过优化后，一部分参数会变为0，另一部分参数为非零实值。<strong>非零实值说明这部分参数是最重要的特征</strong>。</p>
<p>假设参数分布是Laplace分布。</p>
<h3 id="稀疏原因">稀疏原因</h3>
<p>https://blog.csdn.net/b876144622/article/details/81276818</p>
<p>https://www.zhihu.com/question/37096933/answer/70426653</p>
<p>0处导数突变，如果此时0+导数为正，优化时放负方向跑，0-导数为负数，优化时往正方向跑，就很容易落入0</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230314211808962.png"
alt="image-20230314211808962" />
<figcaption aria-hidden="true">image-20230314211808962</figcaption>
</figure>
<h3 id="缺点">缺点</h3>
<ul>
<li>非光滑性：L1
正则化的正则化项是参数的绝对值之和，这导致目标函数在参数为零时不可导。这使得优化过程变得更加困难，特别是在使用梯度下降等基于梯度的优化算法时。在参数为零附近，梯度不连续，可能导致优化过程出现问题。</li>
<li>多重共线性：当特征之间存在高度相关性（多重共线性）时，L1
正则化倾向于选择其中一个特征，而忽略其他相关特征。这可能导致模型的解释性下降，因为被忽略的相关特征可能包含有用的信息。相比之下，L2
正则化对相关特征的惩罚更均衡，可以保留更多相关特征的权重。</li>
<li>不适用于高维问题：在高维问题中，特征数量远远大于样本数量时，L1
正则化可能不太适用。由于参数空间的维度过高，L1
正则化可能无法准确地选择特征，导致过拟合或选择不稳定的特征子集。</li>
</ul>
<h2 id="l2正则化">l2正则化</h2>
<p><span class="math display">\[
l2=\frac{1}{2}\lambda||\vec{w}||_2^2=\sum_i|w_i|^2
\]</span></p>
<p>l2正则化会使部分特征<strong>趋近于0</strong>，也就达到正则化的目的了。</p>
<p>此外，l1正则化和l2正则化也可以联合使用，这种形式也被称为“<strong>Elastic网络正则化</strong>”。</p>
<p>假设参数分布是正态分布</p>
<h2 id="dropout">Dropout</h2>
<p>在训练的时候让一定量的神经元失活，在该epoch中不参与网络训练</p>
<h3
id="dropout训练出的参数需要乘以keep-prib使用">dropout训练出的参数需要乘以keep-prib使用</h3>
<p>因为神经元预测的时候就不应该随机丢弃，一种”补偿“的方案就是每个dropout训练出的神经元的权重都乘以一个<strong>p</strong>，这样在“总体上”使得<strong>测试数据</strong>和<strong>训练数据</strong>是大致一样的。保证<strong>测试</strong>的时候把这个神经元的权重乘以<strong>p</strong>可以得到<strong>同样的期望</strong>。比如一个神经元的输出是<strong>x</strong>，那么在训练的时候它有<strong>p</strong>的概率参与训练，<strong>(1-p)</strong>的概率丢弃，那么它输出的期望是<img
src="https://www.nowcoder.com/equation?tex=p%20%5Ctimes%20x%2B(1-p)%20%5Ctimes%200%20%3D%20p%20%5Ctimes%20x&amp;preview=true"
alt="img" />。因此<strong>测试</strong>的时候把这个神经元的权重乘以<strong>p</strong>可以得到<strong>同样的期望</strong>。</p>
<p>注：目前主流是采用inverted dropout替代dropout，inverted
dropout不需要乘以keep-prib。它的做法是在训练阶段对执行了dropout操作的层，其输出激活值要<strong>除以keep_prib</strong>，而测试的模型不用再做任何改动。除以（1-p），让期望与不dropout相同。</p>
<h2 id="早停">早停</h2>
<p>每一个epoch训练结束后使用<strong>验证集</strong>验证模型效果，画出训练曲线，这样就可以判断是否过拟合了。当发现网络有点过拟合了，当然就是“<strong>早停</strong>”了，可以直接停止训练了。</p>
<h2 id="扩充数据集">扩充数据集</h2>
<p>Augmentation，增加变化增加多样性</p>
<h3 id="数据增强方法">数据增强方法</h3>
<p>数据集越大，网络泛化性能越好，所以努力扩充数据集，通过平移、翻转、旋转、放缩、随机截取、加噪声、色彩抖动等等方式。</p>
<h2 id="bnbatch-normalization">BN（Batch Normalization）</h2>
<p>目的：用于解决深度网络<strong>梯度消失</strong>和<strong>梯度爆炸</strong>的问题，加速网络收敛速度。</p>
<p>批规范化，即在模型每次随机梯度下降训练时，通过mini-batch来对每一层的输出做<strong>规范化操作</strong>，使得结果（各个维度）的<strong>均值为0</strong>，<strong>方差为1</strong>，然后在进行尺度变换和偏移。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230316191341497.png"
alt="image-20230316191341497" />
<figcaption aria-hidden="true">image-20230316191341497</figcaption>
</figure>
<p>m是mini-batch中的数据个数。前面的散步是对input数据进行白化操作（线性），<strong>最后的“尺度变换和偏移”操作是为了让BN能够在线性和非线性之间做一个权衡</strong>，而这个偏移的参数是神经网络在训练时学出来的。</p>
<p>经过BN操作，网络每一层的输出小值被“拉大”，大值被“缩小”，所以就有效避免了梯度消失和梯度爆炸。<strong>总而言之，BN是一个可学习、有参数（γ、β）的网络层</strong>。</p>
<h3 id="尺度变换和偏移的作用">尺度变换和偏移的作用：</h3>
<p>归一会影响到本层网络A所学习到的特征（比如网络中间某一层学习到特征数据本身就分布在S型激活函数的两侧，如果强制把它给归一化处理、标准差也限制在了1，把数据变换成分布于s函数的中间部分，这样就相当于这一层网络所学习到的特征分布<strong>被搞坏</strong>了）</p>
<p>于是<strong>BN</strong>最后的“<strong>尺度变换和偏移</strong>”操作，让我们的网络可以学习恢复出原始网络所要学习的特征分布（衡量线性和非线性）</p>
<h3 id="bn训练和测试有什么不同">BN训练和测试有什么不同</h3>
<p>训练时，均值和方差针对一个<strong>Batch</strong>。</p>
<p>测试时，均值和方差针对<strong>整个数据集</strong>而言。因此，在训练过程中除了正常的前向传播和反向求导之外，我们还要记录<strong>每一个Batch的均值和方差</strong>。</p>
<h3 id="bn和ln的差别">BN和LN的差别</h3>
<p>LN：Layer
Normalization，LN是“横”着来的，<strong>对一个样本，经过同一层的所有神经元</strong>做<strong>归一化</strong>。LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；LN不依赖于batch的大小和输入sequence的深度，因此可以用于<strong>batchsize为1</strong>和RNN中对边长的输入sequence的normalize操作。</p>
<p>BN：Batch
Normalization，BN是“竖”着来的，<strong>经过一个神经元的所有样本</strong>做<strong>归一化</strong>，所以与<strong>batch
size</strong>有关系。</p>
<p>二者提出的目的都是为了加快模型收敛，减少训练时间。</p>
<h3 id="如何同时使用bn和dropout">如何同时使用BN和dropout</h3>
<p>同时使用BN和Dropout会出现方差偏移的现象，原因：</p>
<p>使用Dropout：训练的时候以<strong>概率p</strong>
drop了一些节点，比如dropout设置为0.5，隐藏层共有6个节点，那训练的时候有3个节点的值被丢弃，而测试的时候这6个节点都被保留下来，这就导致了<strong>训练</strong>和<strong>测试</strong>的时候以该层节点为输入的下一层的神经网络节点获取的<strong>期望</strong>会有量级上的差异。为了解决这个问题，在训练时对当前dropout层的输出数据<strong>除以（1-p）</strong>，之后再输入到下一层的神经元节点，以作为失活神经元的补偿，以使得在训练时和测试时每一层的输入有大致相同的期望。</p>
<p>但是这样使得神经元输入期望大致相同，但是方差不一样，而BN是通过均值方差计算的，所以会导致输出不正确。</p>
<p>解决方法：</p>
<ol type="1">
<li>只<strong>在所有BN层的后面采用dropout层</strong>。</li>
<li>dropout原文提出了一种高斯dropout，论文再进一步对高斯dropout进行扩展，提出了一个<strong>均匀分布Dropout</strong>，这样做带来了一个好处就是这个形式的Dropout（又称为“Uout”）对方差的偏移的敏感度降低了</li>
</ol>
<h2 id="bagging-和bootstrap">Bagging 和Bootstrap？</h2>
<p><strong>Bootstrap</strong>是一种抽样方法，即随机抽取数据并将其放回。如一次抽取一个样本，然后放回样本集中，下次可能再抽取这个样本。接着将每轮未抽取的数据合并形成<strong>袋外数据集</strong>（Out
of Bag, OOB），用于模型中的测试集。</p>
<p><strong>Bagging算法</strong>使用<strong>Bootstrap方法</strong>从原始样本集中随机抽取样本。共提取K个轮次，得到K个独立的训练集，元素可以重复。用K个训练集训练K个模型。分类问题以结果中的多个值投票作为最终结果，回归问题以平均值作为最终结果。结果采用投票法，避免了决策树的过拟合问题。</p>
<p><strong>Boosting</strong>是为每个训练样本设置一个权重，在下一轮分类中，误分类的样本权重较大，即每轮样本相同，但样本权重不同；对于分类器来说，分类误差小的分类器权重较大，反之则小。</p>
<p><strong>采用模型融合的方式也可以避免过拟合</strong>。</p>
<h2 id="参数共享">参数共享</h2>
<p>参数共享是一种在神经网络中常用的正则化方法，特别适用于卷积神经网络（CNN）。通过在神经网络的不同层之间共享参数，可以减少模型的参数数量，提高模型的效率和泛化能力。</p>
<h2 id="数据标准化">数据标准化</h2>
<p>数据标准化是对数据进行预处理的一种方式，将数据按特征进行缩放，使得每个特征的均值为
0，标准差为
1。这有助于使不同特征之间的尺度一致，提高模型的收敛速度和性能。</p>
<ul>
<li>z-score</li>
<li>min-max</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/03/13/Recommendation-WangShusen/" rel="prev" title="王树森推荐系统公开课">
                  <i class="fa fa-chevron-left"></i> 王树森推荐系统公开课
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/03/20/DHT/" rel="next" title="DHT">
                  DHT <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lory</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
