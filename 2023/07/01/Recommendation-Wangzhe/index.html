<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="传统模型 协同过滤 User-CF适用于发现热点以及跟踪热点趋势。（user的爱好经常变动，相似度也会随之变动，而且容易受社交关系影响） Item-CF适用于兴趣变化较为稳定的应用。（item相似度比较稳定） 缺点：泛化能力弱：无法将两个物品相似这一信息推广到其他物品的相似性计算上。导致热门的物品有很强的头部效应，容易根大量物品产生相似性，尾部物品则因为特征向量稀疏很少与其他物品产生相似性。 Us">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习推荐系统-王喆">
<meta property="og:url" content="http://example.com/2023/07/01/Recommendation-Wangzhe/index.html">
<meta property="og:site_name" content="Lory&#39;s Page">
<meta property="og:description" content="传统模型 协同过滤 User-CF适用于发现热点以及跟踪热点趋势。（user的爱好经常变动，相似度也会随之变动，而且容易受社交关系影响） Item-CF适用于兴趣变化较为稳定的应用。（item相似度比较稳定） 缺点：泛化能力弱：无法将两个物品相似这一信息推广到其他物品的相似性计算上。导致热门的物品有很强的头部效应，容易根大量物品产生相似性，尾部物品则因为特征向量稀疏很少与其他物品产生相似性。 Us">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-07-01T20:46:26.000Z">
<meta property="article:modified_time" content="2024-04-22T07:40:46.300Z">
<meta property="article:author" content="Lory">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/07/01/Recommendation-Wangzhe/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/07/01/Recommendation-Wangzhe/","path":"2023/07/01/Recommendation-Wangzhe/","title":"深度学习推荐系统-王喆"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习推荐系统-王喆 | Lory's Page</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Lory's Page</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">传统模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4"><span class="nav-number">1.1.</span> <span class="nav-text">协同过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#user-cf"><span class="nav-number">1.1.1.</span> <span class="nav-text">User-CF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E7%94%A8%E6%88%B7%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">计算用户相似度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B9%E6%8D%AEtop-n%E7%9B%B8%E4%BC%BC%E7%94%A8%E6%88%B7%E7%94%9F%E6%88%90%E6%9C%80%E7%BB%88%E6%8E%A8%E8%8D%90%E7%BB%93%E6%9E%9C"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">根据top-n相似用户生成最终推荐结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#item-cf"><span class="nav-number">1.1.2.</span> <span class="nav-text">Item-CF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-number">1.2.</span> <span class="nav-text">矩阵分解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#definition"><span class="nav-number">1.2.1.</span> <span class="nav-text">Definition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%86%E8%A7%A3%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.2.</span> <span class="nav-text">如何分解矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">奇异值分解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">梯度下降</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">1.3.</span> <span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#poly2"><span class="nav-number">1.4.</span> <span class="nav-text">POLY2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fm-factorization-machines%E5%9B%A0%E5%BC%8F%E5%88%86%E8%A7%A3"><span class="nav-number">1.5.</span> <span class="nav-text">FM-Factorization
Machines因式分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ffm-field-aware-factorization-machines"><span class="nav-number">1.6.</span> <span class="nav-text">FFM-Field-aware
Factorization Machines</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gbdtlr"><span class="nav-number">1.7.</span> <span class="nav-text">GBDT+LR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gbdt%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89%E7%BB%84%E5%90%88"><span class="nav-number">1.7.1.</span> <span class="nav-text">GBDT进行特征筛选组合</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ls-plmctr"><span class="nav-number">1.8.</span> <span class="nav-text">LS-PLM（CTR）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#method"><span class="nav-number">1.8.1.</span> <span class="nav-text">METHOD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E7%82%B9"><span class="nav-number">1.8.2.</span> <span class="nav-text">特点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#non-linear"><span class="nav-number">1.8.2.1.</span> <span class="nav-text">Non-linear</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sparsityscalability"><span class="nav-number">1.8.2.2.</span> <span class="nav-text">Sparsity+Scalability</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.</span> <span class="nav-text">深度学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#autorec-%E5%88%A9%E7%94%A8%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E5%AF%B9%E5%85%B1%E7%8E%B0%E7%9F%A9%E9%98%B5%E6%B3%9B%E5%8C%96"><span class="nav-number">2.1.</span> <span class="nav-text">AutoRec-利用自编码器对共现矩阵泛化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#i-autorec"><span class="nav-number">2.1.1.</span> <span class="nav-text">I-AutoRec</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">预测</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#u-autorec"><span class="nav-number">2.1.2.</span> <span class="nav-text">U-AutoRec</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#neuralcf-%E5%9C%A8cf%E6%80%9D%E6%83%B3%E4%B8%8A%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">NeuralCF-在CF思想上使用深度学习方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#deep-crossing%E6%A8%A1%E5%9E%8B-%E5%88%A9%E7%94%A8dnn%E8%87%AA%E5%8A%A8%E5%AD%A6%E4%B9%A0%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89"><span class="nav-number">2.3.</span> <span class="nav-text">Deep
Crossing模型-利用DNN自动学习特征交叉</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pnn%E6%A8%A1%E5%9E%8B-%E5%8A%A0%E5%BC%BA%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E8%83%BD%E5%8A%9B"><span class="nav-number">2.4.</span> <span class="nav-text">PNN模型-加强特征交叉能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#widedeep-%E8%AE%B0%E5%BF%86%E8%83%BD%E5%8A%9B%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E7%9A%84%E7%BB%BC%E5%90%88"><span class="nav-number">2.5.</span> <span class="nav-text">Wide&amp;Deep-记忆能力与泛化能力的综合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#widecross%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.6.</span> <span class="nav-text">Wide&amp;Cross模型</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Lory</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/07/01/Recommendation-Wangzhe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Lory">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lory's Page">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="深度学习推荐系统-王喆 | Lory's Page">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习推荐系统-王喆
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-07-01 20:46:26" itemprop="dateCreated datePublished" datetime="2023-07-01T20:46:26+00:00">2023-07-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-22 07:40:46" itemprop="dateModified" datetime="2024-04-22T07:40:46+00:00">2024-04-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RecSys/" itemprop="url" rel="index"><span itemprop="name">RecSys</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RecSys/BasicTurtorial/" itemprop="url" rel="index"><span itemprop="name">BasicTurtorial</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="传统模型">传统模型</h1>
<h2 id="协同过滤">协同过滤</h2>
<p>User-CF适用于发现热点以及跟踪热点趋势。（user的爱好经常变动，相似度也会随之变动，而且容易受社交关系影响）</p>
<p>Item-CF适用于兴趣变化较为稳定的应用。（item相似度比较稳定）</p>
<p>缺点：泛化能力弱：无法将两个物品相似这一信息推广到其他物品的相似性计算上。导致热门的物品有很强的头部效应，容易根大量物品产生相似性，尾部物品则因为特征向量稀疏很少与其他物品产生相似性。</p>
<h3 id="user-cf">User-CF</h3>
<p>缺点：
用户数往往大于物品书，用户数的增长会导致用户相似度矩阵的存储空间以<span
class="math inline">\(n^2\)</span>的速度快速增长。</p>
<h4 id="计算用户相似度">计算用户相似度</h4>
<ol type="1">
<li>余弦相似度</li>
</ol>
<p><span class="math display">\[
similarity=cos(\theta) = \frac{A\cdot B}{||A||\space ||B||}
\]</span></p>
<ol start="2" type="1">
<li>皮尔逊系数-user <span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_i)(R_{j,p}-\bar
R_j)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_i)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_j)^2}}
\]</span></li>
</ol>
<p><span class="math inline">\(R_{i,p}\)</span>:
用户i对物品p的评分。</p>
<p><span class="math inline">\(\bar{R_i}\)</span>:
用户对所有物品的平均评分。</p>
<ol start="3" type="1">
<li>皮尔逊系数-item</li>
</ol>
<p><span class="math display">\[
sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\bar R_p)(R_{j,p}-\bar
R_p)}{\sqrt{\sum_{p\in P}(R_{i,p}-\bar R_p)^2}\sqrt{\sum_{p\in
P}(R_{j,p}-\bar R_p)^2}}
\]</span></p>
<p><span class="math inline">\(R_{i,p}\)</span>:
用户i对物品p的评分。</p>
<p><span class="math inline">\(\bar{R_p}\)</span>: 物品p的平均分。</p>
<h4
id="根据top-n相似用户生成最终推荐结果">根据top-n相似用户生成最终推荐结果</h4>
<p><span class="math display">\[
R_{u,s}=\frac{\sum_{s\in S}(w_{u,s}\cdot R_{s,p})}{\sum_{s\in S}w_(u,s)}
\]</span></p>
<p><span class="math inline">\(w_{u,s}\)</span>：
是用户u和用户s的相似度</p>
<p><span class="math inline">\(R_{s,p}\)</span>：
是用户s对物品p的评分。</p>
<h3 id="item-cf">Item-CF</h3>
<p>计算相似度后（计算方法与user相同），用下面式子计算： <span
class="math display">\[
R_{u,p}=\sum_{u\in H}(w_{p,h},\cdot R_{u,h})
\]</span> <span class="math inline">\(w_{p,h}\)</span>：
是物品p与物品h的相似程度。</p>
<p><span class="math inline">\(R_{u,h}\)</span>：
是用户u对物品h的已有评分。</p>
<h2 id="矩阵分解">矩阵分解</h2>
<p><strong>协同过滤的进化</strong></p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230706214331238.png"
alt="image-20230706214331238" />
<figcaption aria-hidden="true">image-20230706214331238</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>泛化能力强</li>
<li>空间复杂度低：不用保存用户或物品相似度矩阵，<span
class="math inline">\((m,m)or(n,n)-&gt;(n+m)\cdot k\)</span></li>
<li>更好的扩展性和灵活性。易于与其他特征拼接，易于与深度学习无缝联合。</li>
</ol>
<p>缺点：没有考虑用户与物品的其他特征。</p>
<h3 id="definition">Definition</h3>
<p>通过分解共现矩阵学习用户和物品的表示。</p>
<p>将（m,n)维的共现矩阵M分解为(m,k)维的用户矩阵和(k,n)维的物品矩阵，其中相应的行和列为特定用户与物品的表示，k是用户和物品表示的维度。</p>
<p>预测方法：用户表示与物品表示的内积。 <span class="math display">\[
r_{ui}=q_i^Tp_u
\]</span></p>
<h3 id="如何分解矩阵">如何分解矩阵</h3>
<h4 id="奇异值分解">奇异值分解</h4>
<p>特征值分解只能用于方阵，所以用特征值分解</p>
<p><a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/613284889">矩阵分解—特征值分解与奇异值分解
- 知乎 (zhihu.com)</a></p>
<p>通过奇异值分解求得<span class="math inline">\(M=U\sum
V^T\)</span>,其中<span class="math inline">\(U\in (m,m),\sum \in
(m,n),V^T\in (n,n)\)</span>,中间的为对角阵</p>
<p>取<span
class="math inline">\(\sum\)</span>中较大的k个元素为隐含特征，删除其他维度（U与V中的也删掉）</p>
<p>得到<span class="math inline">\(M=U_{m\times k}\sum_{k\times k}
V^T_{k\times n}\)</span></p>
<p><strong>缺点</strong>：</p>
<ol type="1">
<li><p>奇异值分解要求原始的共现矩阵是稠密的，如果要使用奇异值分解，就必须对确实的元素值进行填充。</p></li>
<li><p>复杂度高O(mn^2)</p></li>
</ol>
<h4 id="梯度下降">梯度下降</h4>
<p>主要方法</p>
<p>Loss： <span class="math display">\[
L=min_{q^*,p^*}\sum (r_{ui}-q_i^Tp_u)^2+\lambda(||q_i||^2+||p_u||^2)
\]</span> 由于不同用户打分标准不同，加入偏差 <span
class="math display">\[
r_{ui}=\mu +b_i+b_u+q^T_ip_u
\]</span> <span class="math inline">\(\mu\)</span>:
全局偏差常数,超参数，提前设置好</p>
<p><span class="math inline">\(b_i\)</span>:
物品偏差系数，可以使用物品i收到的所有评分的均值</p>
<p><span class="math inline">\(b_u\)</span>:
用户偏差系数，可以使用用户u给出的所有评分的均值 <span
class="math display">\[
L=min_{q^*,p^*}\sum
(r_{ui}-q_i^Tp_u-\mu-b_u-b_i)^2+\lambda(||q_i||^2+||p_u||^2+b_u^2+b_i^2)
\]</span></p>
<h2 id="逻辑回归">逻辑回归</h2>
<p><strong>独立于协同过滤的推荐模型方向</strong></p>
<p>将用户年龄、性别、物品属性等特征转为数值型向量输入回归或逻辑回归模型</p>
<p>优点：融合了特征</p>
<p>缺点：逻辑回归模型简单，表达能力不强</p>
<h2 id="poly2">POLY2</h2>
<p>逻辑回归只对单一特征做简单加权，不具备特征交叉生成高维组合特征的能力
<span class="math display">\[
POLY2(W,X)=\sum_{j_1=1}^{n-1}
\sum_{j_2=j_1+1}^nw_h(j_1,j_2)x_{j_1}x_{j_2}
\]</span> POLY2就是直接暴力组合特征,<span
class="math inline">\(x\)</span>是未经embedding处理的特征（one-hot 或
数值特征）</p>
<p>缺点：</p>
<ol type="1">
<li>常常用one-hot编码方式处理类别数据（就是大量<span
class="math inline">\(x_？\)</span>会为0），POLY2不进行特征选择，会让本来就稀疏的向量更稀疏</li>
<li>权重参数<span
class="math inline">\(n-&gt;n^2\)</span>，极大提高了训练复杂度。</li>
</ol>
<h2 id="fm-factorization-machines因式分解">FM-Factorization
Machines因式分解</h2>
<p>FM为给个特征学习了一个隐权重向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。下面是二阶的数学部分：
<span class="math display">\[
FM(w,x)=\sum_{j_i=1}^{n-1} \sum_{j_2=j_1+1}^n (w_{j_1}\cdot
w_{j_2})x_{j_1}x_{j_2}
\]</span> 优点：</p>
<ol type="1">
<li>计算复杂度<span
class="math inline">\(n^2-&gt;nk\)</span>,k是隐向量维度</li>
<li>泛化强，更好的解决数据稀疏性问题：POLY2只有在出现<span
class="math inline">\(x_{j_1},x_{j_2}\)</span>组合同时出现时才能学习到weight（不如梯度下降梯度为0），FM只要在组合中其中一个是<span
class="math inline">\(x_{j_1}\)</span>就能学到隐向量，能反推出没出现过组合的权重。</li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>丢失了某些具体特征组合的精确记忆能力。</li>
</ol>
<h2 id="ffm-field-aware-factorization-machines">FFM-Field-aware
Factorization Machines</h2>
<p>FFM每个特征对应的不是唯一一个隐向量，而是一组隐向量。特征作用于不同的特征域有不同的隐向量：特征1与特征2交叉，则是特征1作用于特征域2:<span
class="math inline">\(w_{j_1,f_2}\)</span>乘特征2作用于特征域1:<span
class="math inline">\(w_{j_2,f_1}\)</span> <span class="math display">\[
FFM(w,x)=\sum_{j_i=1}^{n-1} \sum_{j_2=j_1+1}^n (w_{j_1,f_2}\cdot
w_{j_2,f_1})x_{j_1}x_{j_2}
\]</span> <strong>与FM区别</strong>：</p>
<p>下图中，P，下面是特征值</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230706212714465.png"
alt="image-20230706212714465" />
<figcaption aria-hidden="true">image-20230706212714465</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th></th>
<th>ESPN特征与NIKE特征交叉</th>
<th>ESPN特征与MALE特征交叉</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>FM</td>
<td><span class="math inline">\(w_{ESPN}\cdot w_{NIKE}\)</span></td>
<td><span class="math inline">\(w_{ESPN}\cdot w_{MALE}\)</span></td>
</tr>
<tr class="even">
<td>FFM</td>
<td><span class="math inline">\(w_{ESPN,A}\cdot w_{NIKE,P}\)</span></td>
<td><span class="math inline">\(w_{ESPN,G}\cdot w_{MALE,P}\)</span></td>
</tr>
</tbody>
</table>
<p>计算复杂度：需要学习n个特征在f个特征域上的k维隐向量，参数数量：<span
class="math inline">\(n\cdot k\cdot
f\)</span>,二次项不能像FM一样简化，复杂度是<span
class="math inline">\(kn^2\)</span>。</p>
<p><strong>注意，n&gt;f,一个特征域有可能有多个特征，例如性别特征域有两种特征：男和女。我们只需要学习NIKE特征在性别特征域的1个隐向量，不需要具体学习NIKE对男性的隐向量或NIKE对女性的。这样参数量还是比POLY2少很多。</strong></p>
<h2 id="gbdtlr">GBDT+LR</h2>
<p>POLY2，再提高交叉维度会产生组合爆炸。</p>
<p>GBDT+LR：就是利用GBDT自动进行特征筛选和组合，生成新的离散特征向量，再把特征向量当做LR模型输入。</p>
<p>以前特征组合要么人工筛选，要么通过改造目标函数筛选，GBDT+LR实现了end2end用模型筛选。</p>
<h3 id="gbdt进行特征筛选组合">GBDT进行特征筛选组合</h3>
<p>决策树的每一层都在划分重要特征（划分后label纯度提高），如果决策树深度为2层则意味着抉择树挑选了两个重要特征进行特征交叉。</p>
<p>训练sample在输入GBDT的某一子树后会根据每个节点的规则落入叶子节点，把所有叶子节点组成的向量为该棵树的特征。</p>
<p>e.g.</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720173011264.png"
alt="image-20230720173011264" />
<figcaption aria-hidden="true">image-20230720173011264</figcaption>
</figure>
<h2 id="ls-plmctr">LS-PLM（CTR）</h2>
<p>参考：<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/406615820">经典推荐算法学习（四）|
阿里LS-PLM（MLR）模型原理解析 - 知乎 (zhihu.com)</a></p>
<p>在逻辑回归的基础上加入分片的思想，其灵感来自对广告推荐领域样本特点的观察。</p>
<p>举例来说，如果CTR模型要预估的是女性受众点击女装广告的CTR,那么显然，我们不希望把男性用户点击数码类产品的样本数据也考虑进来，因为这样的样本不仅与女性购买女装的广告场景毫无相关性，甚至会在模型训练过程中扰乱相关特征的权重。</p>
<h3 id="method">METHOD</h3>
<p>其实就是一个类似attention结构去捕捉用户的兴趣。</p>
<p>公式如下： <span class="math display">\[
p(y=1|x) = g(\sum_{j=1}^m\sigma(u_j^Tx)\eta(w_j^Tx))
\]</span></p>
<p><span class="math display">\[
p(y=1|x)=\sum_{i=1}^m\frac{exp(u_i^Tx)}{\sum_{j=1}^mexp(u_i^Tx)}\cdot
\frac{1}{1+exp(-w_i^Tx)}
\]</span></p>
<p>如上述公式所示，LS-PLM在表达上非常朴实，拆开来看就是常见的softmax和LR
。<span class="math inline">\(u^T,w^T\)</span>是可训练参数</p>
<p><span class="math inline">\(sigma(u_j^Tx)\)</span>
:SoftMax部分，负责将特征切分到m个不同的空间。</p>
<p><span class="math inline">\(\eta(w_j^Tx)\)</span>
:LR部分则负责对m个空间的特征分片的进行预测</p>
<p><span class="math inline">\(g(\cdot )\)</span>
:sigma函数，作用则是使得模型符合概率函数定义。</p>
<h3 id="特点">特点</h3>
<ol type="1">
<li><strong>Nonlinearity.</strong> 具备任意强非线性拟合能力；</li>
<li><strong>Sparsity.</strong>具备特征选择能力，使得模型具备稀疏性。</li>
<li><strong>Scalability.</strong>
具备从大规模稀疏数据中挖掘出具有推广性的非线性模式</li>
</ol>
<h4 id="non-linear">Non-linear</h4>
<p>通过控制分片数m，使得LS-PLM便具备拟合任意强度高维空间的非线性分类面能力。</p>
<p>如图1，假设训练数据是一个菱形分类面，基于LR的模型能做到的效果如图1.B)，LS-PLM则可以做到用4个分片完美的拟合训练集合，如图1.C)。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720180543134.png"
alt="image-20230720180543134" />
<figcaption aria-hidden="true">image-20230720180543134</figcaption>
</figure>
<p>可以简单理解为通过前面的softmax部分把sample分到不同的LR
function去进行计算，就可以拟合出上图结果</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720180730815.png"
alt="image-20230720180730815" />
<figcaption aria-hidden="true">image-20230720180730815</figcaption>
</figure>
<p>但m增加则容易过拟合，一般阿里选m=12.</p>
<h4 id="sparsityscalability">Sparsity+Scalability</h4>
<p>引入L1正则化进行得到稀疏解，引入L2,1正则化提高泛化能力避免过拟合</p>
<h1 id="深度学习">深度学习</h1>
<h2
id="autorec-利用自编码器对共现矩阵泛化">AutoRec-利用自编码器对共现矩阵泛化</h2>
<p>利用协同过滤中的共现矩阵，完成物品向量或者用户向量的<strong>自编码</strong>。</p>
<p>假设有m个用户n个物品，我们能得到一个（m,n)的评分矩阵。</p>
<h3 id="i-autorec">I-AutoRec</h3>
<h4 id="训练">训练</h4>
<p>对于物品i，所有m个用户对它的评分可以行程一个m维向量r，构建一个三层网络：</p>
<p><img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230720215757791.png"
alt="image-20230720215757791" /> <span class="math display">\[
h(r,\theta) = f(W\cdot g(Vr+\mu)+b)
\]</span> g,f为激活函数</p>
<p>Loss function： <span class="math display">\[
Loss=min_\theta^n||r^{(i)}-h(r^{(i)},\theta)||^2+\frac{\lambda}{2}(||W||_F^2+||V||_F^2)
\]</span></p>
<h4 id="预测">预测</h4>
<p>当输入物品i评分向量<span
class="math inline">\(r^{(i)}\)</span>时，模型输出<span
class="math inline">\(h(r^{(i)},\theta)\)</span>就是所有用户对物品i的评分，那么其中的第u维就是用户u对物品i的预测.
<span class="math display">\[
R_{ui} = (h(r,\theta))_u
\]</span> 其实就是一个泛化过程，重建函数<span
class="math inline">\(h(r,\theta)\)</span>中存储了所有数据向量的精华，经过自编码器生成的输出向量不会完全等同于输入向量，所以会具备了一定的缺失维度的预测能力。</p>
<h3 id="u-autorec">U-AutoRec</h3>
<p>把用户评分向量作为输入向量，但是用户向量稀疏性可能会影响模型效果。</p>
<h2
id="neuralcf-在cf思想上使用深度学习方法">NeuralCF-在CF思想上使用深度学习方法</h2>
<p>传统矩阵分解欠拟合，因为score层太简单</p>
<p>将矩阵分解（CF的扩展）中的scoring层用多层神经网络取代</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725215426788.png"
alt="image-20230725215426788" />
<figcaption aria-hidden="true">image-20230725215426788</figcaption>
</figure>
<p>NeuralCF还提出了将传统矩阵分解方法和深度学习方法融合的模型：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725220107980.png"
alt="image-20230725220107980" />
<figcaption aria-hidden="true">image-20230725220107980</figcaption>
</figure>
<p>左边MF为传统矩阵分解学习的向量，通过元素积让向量在各个维度上成分交叉（取代原来的直接内积）；</p>
<p>右边则是深度学习矩阵分解，最后将两个处理后向量连接再进行评分。</p>
<h2 id="deep-crossing模型-利用dnn自动学习特征交叉">Deep
Crossing模型-利用DNN自动学习特征交叉</h2>
<p>输入特征：</p>
<ol type="1">
<li><p>可以被处理为one-hot或者multi-hop的类别特征</p></li>
<li><p>数组特征</p></li>
<li><p>需要进一步处理的特征</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725112028369.png"
alt="image-20230725112028369" />
<figcaption aria-hidden="true">image-20230725112028369</figcaption>
</figure></li>
</ol>
<p>模型结构：</p>
<ol type="1">
<li>Embedding层：稀疏特征向量转稠密特征向量（有的特征需要，有的特征不需要e.g.数值特征）</li>
<li>Stacking层：把特征embedding拼接在一起（concatenate）</li>
<li>Multiple Residual Units层： 多层MLP＋残差网络</li>
<li>Scoring层：根据具体任务的评分层。CTR问题二分类用逻辑回归模型，多分类用Softmax。</li>
</ol>
<p>意义：</p>
<ol type="1">
<li>无人工参加特征筛选</li>
<li>模型能自动学习特征交叉，模型越深，交叉越深</li>
</ol>
<h2 id="pnn模型-加强特征交叉能力">PNN模型-加强特征交叉能力</h2>
<p>利用乘积层（Product Layer）取代了DeepCrossing中的Stacking层。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230725221009996.png"
alt="image-20230725221009996" />
<figcaption aria-hidden="true">image-20230725221009996</figcaption>
</figure>
<p>不同特征的Embedding不再是简单的拼接，而是在Product层进行两两交互，更有针对性的获取特征之间的交互信息。</p>
<p>乘积特征交叉部分又分为内积操作IPNN和外积OPNN操作，其中OPNN在进行外积后得到的是一个矩阵，PNN把所有两两特征Embedding向量外积互操作的结果叠加进行降维。IPNN则是内积得到一个值后concatenate后变成一个向量。</p>
<p>优点：</p>
<p>加强不同特征之间交叉交互。</p>
<p>缺点：</p>
<p>OPNN中粗暴的简化操作可能会丢失信息。</p>
<p>无差别价差特征一定程度上忽略原始特征向量中包含的有价值的信息。</p>
<h2
id="widedeep-记忆能力与泛化能力的综合">Wide&amp;Deep-记忆能力与泛化能力的综合</h2>
<p>wide-让模型更有记忆能力-模型结构简单，原始数据王位可以直接影响推荐结果。</p>
<p>记忆能力可以理解为模型直接学习并利用历史数据中物品或者特征的“共现频率”能力（哪些关键特征会直接导致什么必然结果，e.g.如果点击过A则大概率会点击B）</p>
<p>deep-让模型更有泛化能力</p>
<p>泛化能力可以理解为模型传递特征的相关性以及挖掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726214649249.png"
alt="image-20230726214649249" />
<figcaption aria-hidden="true">image-20230726214649249</figcaption>
</figure>
<p>什么特征输入到Deep什么输入到Wide需要深刻理解应用场景后人工设计，例子：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726214719704.png"
alt="image-20230726214719704" />
<figcaption aria-hidden="true">image-20230726214719704</figcaption>
</figure>
<p>所有特征都被输入到Deep去挖掘深层次关系，只有已安装应用和曝光应用这种直接粗暴对结论有重要直接影响的特征。</p>
<p>在Wide层，Geogle用的交叉积变换处理：</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230726215115342.png"
alt="image-20230726215115342" />
<figcaption aria-hidden="true">image-20230726215115342</figcaption>
</figure>
<p><span
class="math inline">\(c^{ki}\)</span>是一个布尔变量，当第i个特征属于第k
个组合特征时，c的值为1，否则为0;</p>
<p>x是第i个特征的值。</p>
<p>例如，对于“AND(user_installed app=netflix.impression
app=pandora)”这个组合特征来说只有当“user installed
app=netflix和“impression_app=pandora”这两个特征同时为1时，其对应的交叉积变换层的结果才为1，否则为0。</p>
<h2 id="widecross模型">Wide&amp;Cross模型</h2>
<p>用Cross网络取代Wide&amp;Deep中原来Wide部分，Deep部分没变。</p>
<p>Cross网络能增加特征之间的交互力度</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230727160456625.png"
alt="image-20230727160456625" />
<figcaption aria-hidden="true">image-20230727160456625</figcaption>
</figure>
<p>Cross网络使用多层交叉层，假设第l层输出为<span
class="math inline">\(x_l\)</span>，那么第l+1层输出为： <span
class="math display">\[
x_{l+1}=x_0x_l^TW_l+b_l+x_l
\]</span> 这里的<span
class="math inline">\(x_0\)</span>是将所有输入特征处理好之后concatenate起来的一个向量，不同的维度代表不同的特征。</p>
<figure>
<img
src="https://ayimd-pic.oss-cn-guangzhou.aliyuncs.com/image-20230727160827480.png"
alt="image-20230727160827480" />
<figcaption aria-hidden="true">image-20230727160827480</figcaption>
</figure>
<p>cross layer的每一层其实是将两个向量A、B矩阵相乘为一个矩阵M，<span
class="math inline">\(M_{ij}\)</span>代表A向量的第i维度与B向量第j维度相乘，这样就将两个向量的每个维度两两相乘，而向量<span
class="math inline">\(x_0\)</span>中的不同维度代表不同特征，也就是让不同特征充分交互。</p>
<p>交叉后过一个MLP层，最后再加上交叉前的l层输入，其实就是为了学习残差。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/24/MATHinDNN/" rel="prev" title="Math in DNN">
                  <i class="fa fa-chevron-left"></i> Math in DNN
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/07/10/TraditionalMachineLearning/" rel="next" title="Traditional Machine Learning">
                  Traditional Machine Learning <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lory</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
